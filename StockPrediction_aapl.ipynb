{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83ff98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb36c191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>145.139999</td>\n",
       "      <td>146.639999</td>\n",
       "      <td>143.380005</td>\n",
       "      <td>144.220001</td>\n",
       "      <td>143.418350</td>\n",
       "      <td>69246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>144.289993</td>\n",
       "      <td>144.809998</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>141.169998</td>\n",
       "      <td>140.385315</td>\n",
       "      <td>83763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>141.399994</td>\n",
       "      <td>148.720001</td>\n",
       "      <td>140.550003</td>\n",
       "      <td>148.029999</td>\n",
       "      <td>147.207169</td>\n",
       "      <td>111380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>148.210007</td>\n",
       "      <td>149.130005</td>\n",
       "      <td>146.610001</td>\n",
       "      <td>148.309998</td>\n",
       "      <td>147.485626</td>\n",
       "      <td>71250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>145.960007</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>145.649994</td>\n",
       "      <td>147.809998</td>\n",
       "      <td>146.988403</td>\n",
       "      <td>65447400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2022-11-28  145.139999  146.639999  143.380005  144.220001  143.418350   \n",
       "1  2022-11-29  144.289993  144.809998  140.350006  141.169998  140.385315   \n",
       "2  2022-11-30  141.399994  148.720001  140.550003  148.029999  147.207169   \n",
       "3  2022-12-01  148.210007  149.130005  146.610001  148.309998  147.485626   \n",
       "4  2022-12-02  145.960007  148.000000  145.649994  147.809998  146.988403   \n",
       "\n",
       "      Volume  \n",
       "0   69246000  \n",
       "1   83763800  \n",
       "2  111380900  \n",
       "3   71250400  \n",
       "4   65447400  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('AAPL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b402bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845dd607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>145.139999</td>\n",
       "      <td>146.639999</td>\n",
       "      <td>143.380005</td>\n",
       "      <td>144.220001</td>\n",
       "      <td>143.418350</td>\n",
       "      <td>69246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>144.289993</td>\n",
       "      <td>144.809998</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>141.169998</td>\n",
       "      <td>140.385315</td>\n",
       "      <td>83763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>141.399994</td>\n",
       "      <td>148.720001</td>\n",
       "      <td>140.550003</td>\n",
       "      <td>148.029999</td>\n",
       "      <td>147.207169</td>\n",
       "      <td>111380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>148.210007</td>\n",
       "      <td>149.130005</td>\n",
       "      <td>146.610001</td>\n",
       "      <td>148.309998</td>\n",
       "      <td>147.485626</td>\n",
       "      <td>71250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>145.960007</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>145.649994</td>\n",
       "      <td>147.809998</td>\n",
       "      <td>146.988403</td>\n",
       "      <td>65447400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2022-11-28  145.139999  146.639999  143.380005  144.220001  143.418350   \n",
       "1  2022-11-29  144.289993  144.809998  140.350006  141.169998  140.385315   \n",
       "2  2022-11-30  141.399994  148.720001  140.550003  148.029999  147.207169   \n",
       "3  2022-12-01  148.210007  149.130005  146.610001  148.309998  147.485626   \n",
       "4  2022-12-02  145.960007  148.000000  145.649994  147.809998  146.988403   \n",
       "\n",
       "      Volume  \n",
       "0   69246000  \n",
       "1   83763800  \n",
       "2  111380900  \n",
       "3   71250400  \n",
       "4   65447400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop(['Date '], axis=1)\n",
    "# df=df.drop(['series '], axis=1)\n",
    "# df=df.drop(['PREV. CLOSE '], axis=1)\n",
    "# df=df.drop(['ltp '], axis=1)\n",
    "# df=df.drop(['vwap '], axis=1)\n",
    "# df=df.drop(['VALUE '], axis=1)\n",
    "# df=df.drop(['No of trades '], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f235717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>145.139999</td>\n",
       "      <td>146.639999</td>\n",
       "      <td>143.380005</td>\n",
       "      <td>144.220001</td>\n",
       "      <td>143.418350</td>\n",
       "      <td>69246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>144.289993</td>\n",
       "      <td>144.809998</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>141.169998</td>\n",
       "      <td>140.385315</td>\n",
       "      <td>83763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>141.399994</td>\n",
       "      <td>148.720001</td>\n",
       "      <td>140.550003</td>\n",
       "      <td>148.029999</td>\n",
       "      <td>147.207169</td>\n",
       "      <td>111380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>148.210007</td>\n",
       "      <td>149.130005</td>\n",
       "      <td>146.610001</td>\n",
       "      <td>148.309998</td>\n",
       "      <td>147.485626</td>\n",
       "      <td>71250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>145.960007</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>145.649994</td>\n",
       "      <td>147.809998</td>\n",
       "      <td>146.988403</td>\n",
       "      <td>65447400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2022-11-28  145.139999  146.639999  143.380005  144.220001  143.418350   \n",
       "2022-11-29  144.289993  144.809998  140.350006  141.169998  140.385315   \n",
       "2022-11-30  141.399994  148.720001  140.550003  148.029999  147.207169   \n",
       "2022-12-01  148.210007  149.130005  146.610001  148.309998  147.485626   \n",
       "2022-12-02  145.960007  148.000000  145.649994  147.809998  146.988403   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2022-11-28   69246000  \n",
       "2022-11-29   83763800  \n",
       "2022-11-30  111380900  \n",
       "2022-12-01   71250400  \n",
       "2022-12-02   65447400  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57eb8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 252 entries, 2022-11-28 to 2023-11-28\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       252 non-null    float64\n",
      " 1   High       252 non-null    float64\n",
      " 2   Low        252 non-null    float64\n",
      " 3   Close      252 non-null    float64\n",
      " 4   Adj Close  252 non-null    float64\n",
      " 5   Volume     252 non-null    int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629206e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(dat):\n",
    "    d=dat.replace(\",\",\"\")\n",
    "    d=float(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acf6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int(dat):\n",
    "    d=dat.replace(\",\",\"\")\n",
    "    d=int(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1af026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['OPEN '] = df['OPEN '].apply(convert)\n",
    "# df['HIGH '] = df['HIGH '].apply(convert)\n",
    "# df['LOW '] = df['LOW '].apply(convert)\n",
    "# df['close '] = df['close '].apply(convert)\n",
    "# df['52W H '] = df['52W H '].apply(convert)\n",
    "# df['52W L '] = df['52W L '].apply(convert)\n",
    "#df['VOLUME '] = df['VOLUME '].apply(convert_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c2d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 252 entries, 2022-11-28 to 2023-11-28\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       252 non-null    float64\n",
      " 1   High       252 non-null    float64\n",
      " 2   Low        252 non-null    float64\n",
      " 3   Close      252 non-null    float64\n",
      " 4   Adj Close  252 non-null    float64\n",
      " 5   Volume     252 non-null    int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 13.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e798f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>2.520000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167.236152</td>\n",
       "      <td>168.886707</td>\n",
       "      <td>165.859643</td>\n",
       "      <td>167.462659</td>\n",
       "      <td>166.964740</td>\n",
       "      <td>6.186408e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.606256</td>\n",
       "      <td>18.420021</td>\n",
       "      <td>18.778494</td>\n",
       "      <td>18.588695</td>\n",
       "      <td>18.744212</td>\n",
       "      <td>1.877757e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>126.010002</td>\n",
       "      <td>127.769997</td>\n",
       "      <td>124.169998</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>124.325089</td>\n",
       "      <td>2.404830e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>151.909996</td>\n",
       "      <td>153.695003</td>\n",
       "      <td>150.584999</td>\n",
       "      <td>152.392502</td>\n",
       "      <td>151.719150</td>\n",
       "      <td>4.951145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>172.355004</td>\n",
       "      <td>173.875000</td>\n",
       "      <td>171.139999</td>\n",
       "      <td>172.785004</td>\n",
       "      <td>172.379822</td>\n",
       "      <td>5.733740e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>180.719997</td>\n",
       "      <td>182.004994</td>\n",
       "      <td>178.385002</td>\n",
       "      <td>180.605007</td>\n",
       "      <td>180.183979</td>\n",
       "      <td>6.906735e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>196.240005</td>\n",
       "      <td>198.229996</td>\n",
       "      <td>195.279999</td>\n",
       "      <td>196.449997</td>\n",
       "      <td>195.926956</td>\n",
       "      <td>1.601569e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close   Adj Close  \\\n",
       "count  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
       "mean   167.236152  168.886707  165.859643  167.462659  166.964740   \n",
       "std     18.606256   18.420021   18.778494   18.588695   18.744212   \n",
       "min    126.010002  127.769997  124.169998  125.019997  124.325089   \n",
       "25%    151.909996  153.695003  150.584999  152.392502  151.719150   \n",
       "50%    172.355004  173.875000  171.139999  172.785004  172.379822   \n",
       "75%    180.719997  182.004994  178.385002  180.605007  180.183979   \n",
       "max    196.240005  198.229996  195.279999  196.449997  195.926956   \n",
       "\n",
       "             Volume  \n",
       "count  2.520000e+02  \n",
       "mean   6.186408e+07  \n",
       "std    1.877757e+07  \n",
       "min    2.404830e+07  \n",
       "25%    4.951145e+07  \n",
       "50%    5.733740e+07  \n",
       "75%    6.906735e+07  \n",
       "max    1.601569e+08  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a98fa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007795d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Next_Day_Close'] = df['Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ed1ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Next_Day_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-21</th>\n",
       "      <td>191.410004</td>\n",
       "      <td>191.520004</td>\n",
       "      <td>189.740005</td>\n",
       "      <td>190.639999</td>\n",
       "      <td>190.639999</td>\n",
       "      <td>38134500</td>\n",
       "      <td>191.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-22</th>\n",
       "      <td>191.490005</td>\n",
       "      <td>192.929993</td>\n",
       "      <td>190.830002</td>\n",
       "      <td>191.309998</td>\n",
       "      <td>191.309998</td>\n",
       "      <td>39617700</td>\n",
       "      <td>189.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>190.869995</td>\n",
       "      <td>190.899994</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>189.970001</td>\n",
       "      <td>189.970001</td>\n",
       "      <td>24048300</td>\n",
       "      <td>189.789993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27</th>\n",
       "      <td>189.919998</td>\n",
       "      <td>190.669998</td>\n",
       "      <td>188.899994</td>\n",
       "      <td>189.789993</td>\n",
       "      <td>189.789993</td>\n",
       "      <td>40552600</td>\n",
       "      <td>190.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-28</th>\n",
       "      <td>189.779999</td>\n",
       "      <td>191.080002</td>\n",
       "      <td>189.399994</td>\n",
       "      <td>190.399994</td>\n",
       "      <td>190.399994</td>\n",
       "      <td>38368300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-11-21  191.410004  191.520004  189.740005  190.639999  190.639999   \n",
       "2023-11-22  191.490005  192.929993  190.830002  191.309998  191.309998   \n",
       "2023-11-24  190.869995  190.899994  189.250000  189.970001  189.970001   \n",
       "2023-11-27  189.919998  190.669998  188.899994  189.789993  189.789993   \n",
       "2023-11-28  189.779999  191.080002  189.399994  190.399994  190.399994   \n",
       "\n",
       "              Volume  Next_Day_Close  \n",
       "Date                                  \n",
       "2023-11-21  38134500      191.309998  \n",
       "2023-11-22  39617700      189.970001  \n",
       "2023-11-24  24048300      189.789993  \n",
       "2023-11-27  40552600      190.399994  \n",
       "2023-11-28  38368300             NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e6e618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b923334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop([df.shape[0]-1], axis=0, inplace=True)\n",
    "df = df.drop(index=\"2023-11-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ed3f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Next_Day_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-20</th>\n",
       "      <td>189.889999</td>\n",
       "      <td>191.910004</td>\n",
       "      <td>189.880005</td>\n",
       "      <td>191.449997</td>\n",
       "      <td>191.449997</td>\n",
       "      <td>46505100</td>\n",
       "      <td>190.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-21</th>\n",
       "      <td>191.410004</td>\n",
       "      <td>191.520004</td>\n",
       "      <td>189.740005</td>\n",
       "      <td>190.639999</td>\n",
       "      <td>190.639999</td>\n",
       "      <td>38134500</td>\n",
       "      <td>191.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-22</th>\n",
       "      <td>191.490005</td>\n",
       "      <td>192.929993</td>\n",
       "      <td>190.830002</td>\n",
       "      <td>191.309998</td>\n",
       "      <td>191.309998</td>\n",
       "      <td>39617700</td>\n",
       "      <td>189.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>190.869995</td>\n",
       "      <td>190.899994</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>189.970001</td>\n",
       "      <td>189.970001</td>\n",
       "      <td>24048300</td>\n",
       "      <td>189.789993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27</th>\n",
       "      <td>189.919998</td>\n",
       "      <td>190.669998</td>\n",
       "      <td>188.899994</td>\n",
       "      <td>189.789993</td>\n",
       "      <td>189.789993</td>\n",
       "      <td>40552600</td>\n",
       "      <td>190.399994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-11-20  189.889999  191.910004  189.880005  191.449997  191.449997   \n",
       "2023-11-21  191.410004  191.520004  189.740005  190.639999  190.639999   \n",
       "2023-11-22  191.490005  192.929993  190.830002  191.309998  191.309998   \n",
       "2023-11-24  190.869995  190.899994  189.250000  189.970001  189.970001   \n",
       "2023-11-27  189.919998  190.669998  188.899994  189.789993  189.789993   \n",
       "\n",
       "              Volume  Next_Day_Close  \n",
       "Date                                  \n",
       "2023-11-20  46505100      190.639999  \n",
       "2023-11-21  38134500      191.309998  \n",
       "2023-11-22  39617700      189.970001  \n",
       "2023-11-24  24048300      189.789993  \n",
       "2023-11-27  40552600      190.399994  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6baeec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df[0:int(len(df) * 0.8)]\n",
    "test_data=df[int(len(df) * 0.8):]\n",
    "train_ar = train_data['Next_Day_Close'].values\n",
    "test_ar = test_data['Next_Day_Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9cb2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data.drop(['Next_Day_Close'], axis=1)\n",
    "X_test=test_data.drop(['Next_Day_Close'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64809120",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.expand_dims(X_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0125fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.expand_dims(X_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a1089c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data['Next_Day_Close']\n",
    "y_test=test_data['Next_Day_Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e0bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d8cf932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m11,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,651</span> (123.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,651\u001b[0m (123.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,651</span> (123.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,651\u001b[0m (123.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape = (1,X_train.shape[2],)))\n",
    "\n",
    "model.add(Dropout(0.1)) \n",
    "model.add(LSTM(units=50))\n",
    "\n",
    "model.add(Dense(1,activation=\"linear\"))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b72b9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'model_aapl.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
    "ES = EarlyStopping(monitor='loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ed196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 26326.6348 - mean_absolute_error: 161.0823\n",
      "Epoch 1: loss improved from inf to 27616.67188, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 27193.8203 - mean_absolute_error: 163.6395 - val_loss: 32318.2363 - val_mean_absolute_error: 178.2334\n",
      "Epoch 2/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27860.9414 - mean_absolute_error: 165.7522\n",
      "Epoch 2: loss improved from 27616.67188 to 27425.47266, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27266.3125 - mean_absolute_error: 163.9067 - val_loss: 32227.5352 - val_mean_absolute_error: 177.9808\n",
      "Epoch 3/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 28577.7441 - mean_absolute_error: 168.1612\n",
      "Epoch 3: loss improved from 27425.47266 to 26781.22266, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 27501.5234 - mean_absolute_error: 165.1461 - val_loss: 32125.9805 - val_mean_absolute_error: 177.6975\n",
      "Epoch 4/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 25532.2656 - mean_absolute_error: 158.5135\n",
      "Epoch 4: loss did not improve from 26781.22266\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26732.6660 - mean_absolute_error: 162.4116 - val_loss: 32009.8242 - val_mean_absolute_error: 177.3729\n",
      "Epoch 5/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 28002.3770 - mean_absolute_error: 166.2607\n",
      "Epoch 5: loss did not improve from 26781.22266\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27393.9297 - mean_absolute_error: 164.2653 - val_loss: 31874.8203 - val_mean_absolute_error: 176.9949\n",
      "Epoch 6/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 25982.1484 - mean_absolute_error: 159.9879\n",
      "Epoch 6: loss improved from 26781.22266 to 26752.87109, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26804.1367 - mean_absolute_error: 162.7133 - val_loss: 31720.5078 - val_mean_absolute_error: 176.5619\n",
      "Epoch 7/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25955.0312 - mean_absolute_error: 159.6531\n",
      "Epoch 7: loss improved from 26752.87109 to 26518.80078, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26611.6152 - mean_absolute_error: 162.0824 - val_loss: 31547.1465 - val_mean_absolute_error: 176.0741\n",
      "Epoch 8/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 25764.7305 - mean_absolute_error: 159.3205\n",
      "Epoch 8: loss did not improve from 26518.80078\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26622.4141 - mean_absolute_error: 162.0572 - val_loss: 31355.7773 - val_mean_absolute_error: 175.5342\n",
      "Epoch 9/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 26377.5391 - mean_absolute_error: 161.4889\n",
      "Epoch 9: loss improved from 26518.80078 to 25913.15234, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 26535.4082 - mean_absolute_error: 162.2406 - val_loss: 31148.7109 - val_mean_absolute_error: 174.9480\n",
      "Epoch 10/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 26840.7305 - mean_absolute_error: 162.4790\n",
      "Epoch 10: loss did not improve from 25913.15234\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26469.7656 - mean_absolute_error: 161.5130 - val_loss: 30929.7383 - val_mean_absolute_error: 174.3261\n",
      "Epoch 11/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 25955.7891 - mean_absolute_error: 159.8580\n",
      "Epoch 11: loss did not improve from 25913.15234\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25944.4551 - mean_absolute_error: 159.7545 - val_loss: 30701.9805 - val_mean_absolute_error: 173.6768\n",
      "Epoch 12/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 26074.8457 - mean_absolute_error: 160.3399\n",
      "Epoch 12: loss did not improve from 25913.15234\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26038.7422 - mean_absolute_error: 160.0796 - val_loss: 30469.0547 - val_mean_absolute_error: 173.0103\n",
      "Epoch 13/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24980.7891 - mean_absolute_error: 156.8661\n",
      "Epoch 13: loss improved from 25913.15234 to 25494.60352, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25550.0410 - mean_absolute_error: 158.7481 - val_loss: 30234.4395 - val_mean_absolute_error: 172.3364\n",
      "Epoch 14/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 26406.6426 - mean_absolute_error: 161.4490\n",
      "Epoch 14: loss improved from 25494.60352 to 25366.62695, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25663.1484 - mean_absolute_error: 159.0295 - val_loss: 30001.3457 - val_mean_absolute_error: 171.6643\n",
      "Epoch 15/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 23262.5293 - mean_absolute_error: 151.5941\n",
      "Epoch 15: loss did not improve from 25366.62695\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24742.1758 - mean_absolute_error: 155.8840 - val_loss: 29772.6328 - val_mean_absolute_error: 171.0023\n",
      "Epoch 16/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25694.3379 - mean_absolute_error: 158.9913\n",
      "Epoch 16: loss improved from 25366.62695 to 25073.29492, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 25285.9453 - mean_absolute_error: 157.7667 - val_loss: 29547.8711 - val_mean_absolute_error: 170.3492\n",
      "Epoch 17/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 24522.0547 - mean_absolute_error: 155.5055\n",
      "Epoch 17: loss improved from 25073.29492 to 24656.76758, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24824.7422 - mean_absolute_error: 156.4724 - val_loss: 29329.4492 - val_mean_absolute_error: 169.7121\n",
      "Epoch 18/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 26402.8008 - mean_absolute_error: 161.1090\n",
      "Epoch 18: loss did not improve from 24656.76758\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25032.1777 - mean_absolute_error: 156.8251 - val_loss: 29117.7832 - val_mean_absolute_error: 169.0925\n",
      "Epoch 19/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 24779.5742 - mean_absolute_error: 156.0994\n",
      "Epoch 19: loss improved from 24656.76758 to 24289.36523, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 24559.2422 - mean_absolute_error: 155.5739 - val_loss: 28912.7422 - val_mean_absolute_error: 168.4901\n",
      "Epoch 20/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 25604.6250 - mean_absolute_error: 158.9368\n",
      "Epoch 20: loss did not improve from 24289.36523\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24663.7539 - mean_absolute_error: 155.7447 - val_loss: 28714.8457 - val_mean_absolute_error: 167.9066\n",
      "Epoch 21/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 25203.3184 - mean_absolute_error: 157.7179\n",
      "Epoch 21: loss improved from 24289.36523 to 24093.84570, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24352.4023 - mean_absolute_error: 154.7610 - val_loss: 28523.5742 - val_mean_absolute_error: 167.3408\n",
      "Epoch 22/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 23263.7148 - mean_absolute_error: 151.1532\n",
      "Epoch 22: loss improved from 24093.84570 to 24000.91992, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23702.9375 - mean_absolute_error: 152.5700 - val_loss: 28339.0352 - val_mean_absolute_error: 166.7931\n",
      "Epoch 23/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 23734.5820 - mean_absolute_error: 152.7942\n",
      "Epoch 23: loss improved from 24000.91992 to 23823.38477, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23697.0059 - mean_absolute_error: 152.6129 - val_loss: 28160.1719 - val_mean_absolute_error: 166.2605\n",
      "Epoch 24/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 23666.0781 - mean_absolute_error: 152.5060\n",
      "Epoch 24: loss improved from 23823.38477 to 23617.84375, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23581.3301 - mean_absolute_error: 152.2495 - val_loss: 27987.0312 - val_mean_absolute_error: 165.7434\n",
      "Epoch 25/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 24484.0820 - mean_absolute_error: 155.5281\n",
      "Epoch 25: loss improved from 23617.84375 to 23459.29102, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23466.4766 - mean_absolute_error: 151.9303 - val_loss: 27819.2891 - val_mean_absolute_error: 165.2409\n",
      "Epoch 26/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 22848.9941 - mean_absolute_error: 149.7746\n",
      "Epoch 26: loss improved from 23459.29102 to 23128.14648, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23259.3711 - mean_absolute_error: 151.3448 - val_loss: 27656.4609 - val_mean_absolute_error: 164.7516\n",
      "Epoch 27/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 21369.3984 - mean_absolute_error: 144.8541\n",
      "Epoch 27: loss improved from 23128.14648 to 23050.97266, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22526.0332 - mean_absolute_error: 148.8902 - val_loss: 27498.8711 - val_mean_absolute_error: 164.2767\n",
      "Epoch 28/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 23492.7969 - mean_absolute_error: 152.0885\n",
      "Epoch 28: loss improved from 23050.97266 to 22498.15625, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23024.8145 - mean_absolute_error: 150.9021 - val_loss: 27345.1055 - val_mean_absolute_error: 163.8120\n",
      "Epoch 29/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 23630.1934 - mean_absolute_error: 152.5920\n",
      "Epoch 29: loss did not improve from 22498.15625\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22929.0039 - mean_absolute_error: 150.1983 - val_loss: 27195.9023 - val_mean_absolute_error: 163.3598\n",
      "Epoch 30/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 22933.5352 - mean_absolute_error: 150.2296\n",
      "Epoch 30: loss did not improve from 22498.15625\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22698.1797 - mean_absolute_error: 149.2993 - val_loss: 27049.9277 - val_mean_absolute_error: 162.9162\n",
      "Epoch 31/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 23570.6836 - mean_absolute_error: 152.0665\n",
      "Epoch 31: loss improved from 22498.15625 to 22184.68555, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22713.5586 - mean_absolute_error: 149.7644 - val_loss: 26906.8008 - val_mean_absolute_error: 162.4801\n",
      "Epoch 32/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 22915.5742 - mean_absolute_error: 149.8261\n",
      "Epoch 32: loss did not improve from 22184.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22368.4355 - mean_absolute_error: 148.3630 - val_loss: 26767.5039 - val_mean_absolute_error: 162.0545\n",
      "Epoch 33/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22045.5527 - mean_absolute_error: 147.3492\n",
      "Epoch 33: loss did not improve from 22184.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22188.6680 - mean_absolute_error: 147.7920 - val_loss: 26631.0059 - val_mean_absolute_error: 161.6364\n",
      "Epoch 34/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 22055.3984 - mean_absolute_error: 147.1153\n",
      "Epoch 34: loss did not improve from 22184.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22250.8125 - mean_absolute_error: 147.7388 - val_loss: 26496.8926 - val_mean_absolute_error: 161.2246\n",
      "Epoch 35/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 23054.2676 - mean_absolute_error: 150.3509\n",
      "Epoch 35: loss did not improve from 22184.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22425.4043 - mean_absolute_error: 148.1166 - val_loss: 26364.8555 - val_mean_absolute_error: 160.8181\n",
      "Epoch 36/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 21657.2695 - mean_absolute_error: 145.4893\n",
      "Epoch 36: loss did not improve from 22184.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22025.6602 - mean_absolute_error: 146.7641 - val_loss: 26234.7070 - val_mean_absolute_error: 160.4165\n",
      "Epoch 37/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22501.9453 - mean_absolute_error: 148.5204\n",
      "Epoch 37: loss improved from 22184.68555 to 21291.54102, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21704.5215 - mean_absolute_error: 146.4147 - val_loss: 26106.8438 - val_mean_absolute_error: 160.0209\n",
      "Epoch 38/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 21727.8027 - mean_absolute_error: 146.1056\n",
      "Epoch 38: loss did not improve from 21291.54102\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21842.1465 - mean_absolute_error: 146.5987 - val_loss: 25981.9141 - val_mean_absolute_error: 159.6335\n",
      "Epoch 39/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 21432.8379 - mean_absolute_error: 145.1664\n",
      "Epoch 39: loss did not improve from 21291.54102\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21626.9707 - mean_absolute_error: 145.7189 - val_loss: 25859.0508 - val_mean_absolute_error: 159.2515\n",
      "Epoch 40/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 22642.6016 - mean_absolute_error: 149.2375\n",
      "Epoch 40: loss did not improve from 21291.54102\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21854.2637 - mean_absolute_error: 146.5707 - val_loss: 25737.5273 - val_mean_absolute_error: 158.8728\n",
      "Epoch 41/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 22512.3789 - mean_absolute_error: 148.9647\n",
      "Epoch 41: loss improved from 21291.54102 to 21127.76367, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 21688.5527 - mean_absolute_error: 146.2439 - val_loss: 25617.9238 - val_mean_absolute_error: 158.4993\n",
      "Epoch 42/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 20381.6406 - mean_absolute_error: 141.6606\n",
      "Epoch 42: loss improved from 21127.76367 to 21073.78516, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 21347.2090 - mean_absolute_error: 145.0136 - val_loss: 25500.2227 - val_mean_absolute_error: 158.1308\n",
      "Epoch 43/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18902.3223 - mean_absolute_error: 136.2806\n",
      "Epoch 43: loss improved from 21073.78516 to 21064.08984, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20694.3359 - mean_absolute_error: 142.6222 - val_loss: 25384.3945 - val_mean_absolute_error: 157.7674\n",
      "Epoch 44/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 20568.6855 - mean_absolute_error: 142.0436\n",
      "Epoch 44: loss did not improve from 21064.08984\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21090.3340 - mean_absolute_error: 143.8217 - val_loss: 25269.5918 - val_mean_absolute_error: 157.4063\n",
      "Epoch 45/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 21714.9453 - mean_absolute_error: 146.4105\n",
      "Epoch 45: loss improved from 21064.08984 to 20971.86328, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21102.3145 - mean_absolute_error: 143.9933 - val_loss: 25156.0469 - val_mean_absolute_error: 157.0484\n",
      "Epoch 46/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 20459.8359 - mean_absolute_error: 141.5713\n",
      "Epoch 46: loss improved from 20971.86328 to 20954.88086, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20733.0098 - mean_absolute_error: 142.5830 - val_loss: 25043.8555 - val_mean_absolute_error: 156.6940\n",
      "Epoch 47/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 21221.2539 - mean_absolute_error: 144.1587\n",
      "Epoch 47: loss improved from 20954.88086 to 20951.35547, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20983.9473 - mean_absolute_error: 143.3345 - val_loss: 24932.5039 - val_mean_absolute_error: 156.3414\n",
      "Epoch 48/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 21138.1914 - mean_absolute_error: 144.2202\n",
      "Epoch 48: loss improved from 20951.35547 to 20732.05078, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 20887.9648 - mean_absolute_error: 143.1348 - val_loss: 24822.3145 - val_mean_absolute_error: 155.9918\n",
      "Epoch 49/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 19814.1016 - mean_absolute_error: 139.3658\n",
      "Epoch 49: loss improved from 20732.05078 to 20557.89258, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20350.0625 - mean_absolute_error: 141.3200 - val_loss: 24713.5625 - val_mean_absolute_error: 155.6459\n",
      "Epoch 50/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 20612.1094 - mean_absolute_error: 142.6014\n",
      "Epoch 50: loss improved from 20557.89258 to 20483.05664, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20514.1289 - mean_absolute_error: 141.9882 - val_loss: 24605.7656 - val_mean_absolute_error: 155.3023\n",
      "Epoch 51/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 20344.0352 - mean_absolute_error: 141.0779\n",
      "Epoch 51: loss improved from 20483.05664 to 20399.36133, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20247.2930 - mean_absolute_error: 140.8505 - val_loss: 24499.1914 - val_mean_absolute_error: 154.9619\n",
      "Epoch 52/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 19302.1348 - mean_absolute_error: 137.7325\n",
      "Epoch 52: loss improved from 20399.36133 to 20020.81445, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19978.1387 - mean_absolute_error: 140.2910 - val_loss: 24393.6270 - val_mean_absolute_error: 154.6240\n",
      "Epoch 53/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 20474.4004 - mean_absolute_error: 141.7915\n",
      "Epoch 53: loss did not improve from 20020.81445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20279.8340 - mean_absolute_error: 140.8660 - val_loss: 24289.2500 - val_mean_absolute_error: 154.2891\n",
      "Epoch 54/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 21106.9883 - mean_absolute_error: 144.0158\n",
      "Epoch 54: loss did not improve from 20020.81445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20251.6719 - mean_absolute_error: 140.8096 - val_loss: 24185.5410 - val_mean_absolute_error: 153.9557\n",
      "Epoch 55/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 20471.3613 - mean_absolute_error: 141.8269\n",
      "Epoch 55: loss improved from 20020.81445 to 19912.34375, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20338.9805 - mean_absolute_error: 141.3757 - val_loss: 24082.4414 - val_mean_absolute_error: 153.6235\n",
      "Epoch 56/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 19763.4023 - mean_absolute_error: 139.1342\n",
      "Epoch 56: loss did not improve from 19912.34375\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19983.7246 - mean_absolute_error: 139.8593 - val_loss: 23980.7715 - val_mean_absolute_error: 153.2952\n",
      "Epoch 57/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17703.9102 - mean_absolute_error: 131.7477\n",
      "Epoch 57: loss improved from 19912.34375 to 19728.08008, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19214.4473 - mean_absolute_error: 137.3333 - val_loss: 23879.9219 - val_mean_absolute_error: 152.9689\n",
      "Epoch 58/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 20435.3242 - mean_absolute_error: 141.6578\n",
      "Epoch 58: loss improved from 19728.08008 to 19704.72070, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19963.9141 - mean_absolute_error: 139.9649 - val_loss: 23779.6816 - val_mean_absolute_error: 152.6439\n",
      "Epoch 59/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18361.1680 - mean_absolute_error: 133.7683\n",
      "Epoch 59: loss did not improve from 19704.72070\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19455.8711 - mean_absolute_error: 137.8674 - val_loss: 23680.4883 - val_mean_absolute_error: 152.3216\n",
      "Epoch 60/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 19052.4941 - mean_absolute_error: 136.1924\n",
      "Epoch 60: loss improved from 19704.72070 to 19461.14453, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19602.2305 - mean_absolute_error: 138.6222 - val_loss: 23581.6445 - val_mean_absolute_error: 151.9998\n",
      "Epoch 61/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 19072.7812 - mean_absolute_error: 136.9395\n",
      "Epoch 61: loss improved from 19461.14453 to 19251.62891, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19220.6738 - mean_absolute_error: 137.4751 - val_loss: 23484.0391 - val_mean_absolute_error: 151.6813\n",
      "Epoch 62/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 20219.3711 - mean_absolute_error: 141.0638\n",
      "Epoch 62: loss improved from 19251.62891 to 18884.08203, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19742.5664 - mean_absolute_error: 139.5957 - val_loss: 23387.0723 - val_mean_absolute_error: 151.3642\n",
      "Epoch 63/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 19727.3828 - mean_absolute_error: 138.8189\n",
      "Epoch 63: loss did not improve from 18884.08203\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 19337.8730 - mean_absolute_error: 137.5847 - val_loss: 23291.4766 - val_mean_absolute_error: 151.0510\n",
      "Epoch 64/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 20069.3945 - mean_absolute_error: 140.4043\n",
      "Epoch 64: loss did not improve from 18884.08203\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19392.0938 - mean_absolute_error: 137.9906 - val_loss: 23195.9727 - val_mean_absolute_error: 150.7375\n",
      "Epoch 65/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 19018.8457 - mean_absolute_error: 136.4636\n",
      "Epoch 65: loss did not improve from 18884.08203\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19061.5273 - mean_absolute_error: 136.8137 - val_loss: 23101.2930 - val_mean_absolute_error: 150.4260\n",
      "Epoch 66/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18370.8320 - mean_absolute_error: 133.9957\n",
      "Epoch 66: loss did not improve from 18884.08203\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18920.7129 - mean_absolute_error: 136.2046 - val_loss: 23007.2441 - val_mean_absolute_error: 150.1159\n",
      "Epoch 67/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 19890.2422 - mean_absolute_error: 139.9852\n",
      "Epoch 67: loss improved from 18884.08203 to 18758.16016, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 19200.7734 - mean_absolute_error: 137.4038 - val_loss: 22913.6504 - val_mean_absolute_error: 149.8068\n",
      "Epoch 68/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 19797.6250 - mean_absolute_error: 139.4051\n",
      "Epoch 68: loss improved from 18758.16016 to 18634.34570, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 19046.2051 - mean_absolute_error: 136.7894 - val_loss: 22820.7969 - val_mean_absolute_error: 149.4994\n",
      "Epoch 69/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 19248.4160 - mean_absolute_error: 136.8688\n",
      "Epoch 69: loss did not improve from 18634.34570\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19005.0684 - mean_absolute_error: 136.3063 - val_loss: 22728.6250 - val_mean_absolute_error: 149.1937\n",
      "Epoch 70/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 19018.7012 - mean_absolute_error: 136.9182\n",
      "Epoch 70: loss improved from 18634.34570 to 18603.11914, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18827.5488 - mean_absolute_error: 135.9397 - val_loss: 22636.6797 - val_mean_absolute_error: 148.8881\n",
      "Epoch 71/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 18224.3105 - mean_absolute_error: 133.5031\n",
      "Epoch 71: loss improved from 18603.11914 to 18494.25781, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18456.2598 - mean_absolute_error: 134.5110 - val_loss: 22545.5508 - val_mean_absolute_error: 148.5846\n",
      "Epoch 72/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 19112.4375 - mean_absolute_error: 136.8620\n",
      "Epoch 72: loss improved from 18494.25781 to 18347.37695, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18554.1602 - mean_absolute_error: 134.9754 - val_loss: 22454.9062 - val_mean_absolute_error: 148.2821\n",
      "Epoch 73/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18646.0391 - mean_absolute_error: 135.1548\n",
      "Epoch 73: loss improved from 18347.37695 to 18182.99414, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18554.2812 - mean_absolute_error: 135.0459 - val_loss: 22364.8125 - val_mean_absolute_error: 147.9809\n",
      "Epoch 74/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17210.1621 - mean_absolute_error: 129.5968\n",
      "Epoch 74: loss did not improve from 18182.99414\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18014.6055 - mean_absolute_error: 132.6396 - val_loss: 22275.6758 - val_mean_absolute_error: 147.6822\n",
      "Epoch 75/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18667.6016 - mean_absolute_error: 135.0455\n",
      "Epoch 75: loss did not improve from 18182.99414\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18425.8105 - mean_absolute_error: 133.9937 - val_loss: 22186.3789 - val_mean_absolute_error: 147.3824\n",
      "Epoch 76/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17745.5820 - mean_absolute_error: 131.9260\n",
      "Epoch 76: loss did not improve from 18182.99414\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18209.5996 - mean_absolute_error: 133.3990 - val_loss: 22097.2168 - val_mean_absolute_error: 147.0825\n",
      "Epoch 77/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 18152.7500 - mean_absolute_error: 133.3627\n",
      "Epoch 77: loss improved from 18182.99414 to 17932.44336, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18165.1172 - mean_absolute_error: 133.5254 - val_loss: 22008.5273 - val_mean_absolute_error: 146.7835\n",
      "Epoch 78/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17971.9434 - mean_absolute_error: 132.8440\n",
      "Epoch 78: loss improved from 17932.44336 to 17767.53711, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17909.5312 - mean_absolute_error: 132.6814 - val_loss: 21920.8320 - val_mean_absolute_error: 146.4873\n",
      "Epoch 79/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 19303.9863 - mean_absolute_error: 137.7790\n",
      "Epoch 79: loss did not improve from 17767.53711\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18237.9551 - mean_absolute_error: 133.7751 - val_loss: 21833.7422 - val_mean_absolute_error: 146.1926\n",
      "Epoch 80/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 19963.1543 - mean_absolute_error: 140.1244\n",
      "Epoch 80: loss improved from 17767.53711 to 17600.60352, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18459.6152 - mean_absolute_error: 134.7212 - val_loss: 21747.0234 - val_mean_absolute_error: 145.8985\n",
      "Epoch 81/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 16312.7012 - mean_absolute_error: 126.4760\n",
      "Epoch 81: loss improved from 17600.60352 to 17420.66992, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17459.8379 - mean_absolute_error: 131.1126 - val_loss: 21661.3359 - val_mean_absolute_error: 145.6073\n",
      "Epoch 82/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16983.3789 - mean_absolute_error: 128.9688\n",
      "Epoch 82: loss did not improve from 17420.66992\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17796.7188 - mean_absolute_error: 131.8963 - val_loss: 21575.9570 - val_mean_absolute_error: 145.3166\n",
      "Epoch 83/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17959.6992 - mean_absolute_error: 132.7664\n",
      "Epoch 83: loss did not improve from 17420.66992\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17741.5625 - mean_absolute_error: 131.7434 - val_loss: 21490.6797 - val_mean_absolute_error: 145.0257\n",
      "Epoch 84/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17156.9258 - mean_absolute_error: 129.5514\n",
      "Epoch 84: loss did not improve from 17420.66992\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17467.0137 - mean_absolute_error: 130.8169 - val_loss: 21405.6562 - val_mean_absolute_error: 144.7351\n",
      "Epoch 85/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17000.2500 - mean_absolute_error: 129.0495\n",
      "Epoch 85: loss improved from 17420.66992 to 17230.73242, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17393.4434 - mean_absolute_error: 130.6906 - val_loss: 21321.1250 - val_mean_absolute_error: 144.4456\n",
      "Epoch 86/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18274.0078 - mean_absolute_error: 133.5695\n",
      "Epoch 86: loss did not improve from 17230.73242\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17496.5859 - mean_absolute_error: 130.7298 - val_loss: 21237.2578 - val_mean_absolute_error: 144.1578\n",
      "Epoch 87/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17530.7031 - mean_absolute_error: 130.8933\n",
      "Epoch 87: loss improved from 17230.73242 to 17221.17383, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17256.9922 - mean_absolute_error: 129.9334 - val_loss: 21153.6641 - val_mean_absolute_error: 143.8703\n",
      "Epoch 88/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17564.9648 - mean_absolute_error: 130.8740\n",
      "Epoch 88: loss did not improve from 17221.17383\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16951.7617 - mean_absolute_error: 128.5549 - val_loss: 21070.6250 - val_mean_absolute_error: 143.5843\n",
      "Epoch 89/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 18723.1680 - mean_absolute_error: 135.6366\n",
      "Epoch 89: loss improved from 17221.17383 to 16992.26172, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 17483.3457 - mean_absolute_error: 131.0007 - val_loss: 20987.2891 - val_mean_absolute_error: 143.2966\n",
      "Epoch 90/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16040.1289 - mean_absolute_error: 125.1641\n",
      "Epoch 90: loss did not improve from 16992.26172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16751.4844 - mean_absolute_error: 127.6411 - val_loss: 20904.9648 - val_mean_absolute_error: 143.0118\n",
      "Epoch 91/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 15139.9043 - mean_absolute_error: 121.3507\n",
      "Epoch 91: loss improved from 16992.26172 to 16940.32422, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16641.4297 - mean_absolute_error: 127.5460 - val_loss: 20822.4961 - val_mean_absolute_error: 142.7260\n",
      "Epoch 92/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 17145.9043 - mean_absolute_error: 129.9289\n",
      "Epoch 92: loss did not improve from 16940.32422\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16880.8574 - mean_absolute_error: 128.5465 - val_loss: 20740.5723 - val_mean_absolute_error: 142.4415\n",
      "Epoch 93/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17875.2051 - mean_absolute_error: 132.1746\n",
      "Epoch 93: loss improved from 16940.32422 to 16883.48438, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16946.8457 - mean_absolute_error: 128.6854 - val_loss: 20659.0742 - val_mean_absolute_error: 142.1579\n",
      "Epoch 94/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15967.3193 - mean_absolute_error: 124.7738\n",
      "Epoch 94: loss did not improve from 16883.48438\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16473.7832 - mean_absolute_error: 126.6556 - val_loss: 20578.0898 - val_mean_absolute_error: 141.8756\n",
      "Epoch 95/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16683.6973 - mean_absolute_error: 127.8428\n",
      "Epoch 95: loss did not improve from 16883.48438\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16726.7578 - mean_absolute_error: 127.8043 - val_loss: 20496.9609 - val_mean_absolute_error: 141.5922\n",
      "Epoch 96/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 16897.6250 - mean_absolute_error: 128.7247\n",
      "Epoch 96: loss improved from 16883.48438 to 16480.31445, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16701.4668 - mean_absolute_error: 127.9259 - val_loss: 20416.2734 - val_mean_absolute_error: 141.3098\n",
      "Epoch 97/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17590.4102 - mean_absolute_error: 131.3388\n",
      "Epoch 97: loss did not improve from 16480.31445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17008.2930 - mean_absolute_error: 128.9517 - val_loss: 20336.1797 - val_mean_absolute_error: 141.0289\n",
      "Epoch 98/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17430.3320 - mean_absolute_error: 130.8124\n",
      "Epoch 98: loss improved from 16480.31445 to 16447.92383, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16634.4141 - mean_absolute_error: 127.6294 - val_loss: 20256.6094 - val_mean_absolute_error: 140.7493\n",
      "Epoch 99/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15549.7363 - mean_absolute_error: 123.5024\n",
      "Epoch 99: loss did not improve from 16447.92383\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16266.6953 - mean_absolute_error: 125.9429 - val_loss: 20177.5547 - val_mean_absolute_error: 140.4709\n",
      "Epoch 100/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16155.2314 - mean_absolute_error: 125.5350\n",
      "Epoch 100: loss improved from 16447.92383 to 16202.54785, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16555.2305 - mean_absolute_error: 127.3634 - val_loss: 20098.4141 - val_mean_absolute_error: 140.1917\n",
      "Epoch 101/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17017.4570 - mean_absolute_error: 129.2223\n",
      "Epoch 101: loss improved from 16202.54785 to 16049.51465, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16412.9258 - mean_absolute_error: 126.8994 - val_loss: 20020.1094 - val_mean_absolute_error: 139.9149\n",
      "Epoch 102/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15387.8848 - mean_absolute_error: 122.5548\n",
      "Epoch 102: loss did not improve from 16049.51465\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16195.0801 - mean_absolute_error: 125.7569 - val_loss: 19942.2930 - val_mean_absolute_error: 139.6393\n",
      "Epoch 103/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 14977.0830 - mean_absolute_error: 121.2115\n",
      "Epoch 103: loss did not improve from 16049.51465\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15739.8398 - mean_absolute_error: 123.9695 - val_loss: 19864.7363 - val_mean_absolute_error: 139.3641\n",
      "Epoch 104/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16615.8047 - mean_absolute_error: 127.4051\n",
      "Epoch 104: loss did not improve from 16049.51465\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16333.8350 - mean_absolute_error: 126.3320 - val_loss: 19787.0273 - val_mean_absolute_error: 139.0878\n",
      "Epoch 105/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 16406.7246 - mean_absolute_error: 126.2519\n",
      "Epoch 105: loss did not improve from 16049.51465\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16112.6348 - mean_absolute_error: 125.2024 - val_loss: 19709.7969 - val_mean_absolute_error: 138.8127\n",
      "Epoch 106/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14986.8809 - mean_absolute_error: 121.0335\n",
      "Epoch 106: loss improved from 16049.51465 to 15890.19238, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15748.0244 - mean_absolute_error: 124.0236 - val_loss: 19632.7148 - val_mean_absolute_error: 138.5375\n",
      "Epoch 107/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15718.6289 - mean_absolute_error: 123.9309\n",
      "Epoch 107: loss improved from 15890.19238 to 15777.63770, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15730.9180 - mean_absolute_error: 124.1119 - val_loss: 19556.0918 - val_mean_absolute_error: 138.2635\n",
      "Epoch 108/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16189.1602 - mean_absolute_error: 125.9162\n",
      "Epoch 108: loss did not improve from 15777.63770\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16016.1582 - mean_absolute_error: 124.9167 - val_loss: 19479.7578 - val_mean_absolute_error: 137.9899\n",
      "Epoch 109/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16435.8691 - mean_absolute_error: 126.4167\n",
      "Epoch 109: loss did not improve from 15777.63770\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15832.7559 - mean_absolute_error: 124.0571 - val_loss: 19403.6133 - val_mean_absolute_error: 137.7165\n",
      "Epoch 110/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16069.7969 - mean_absolute_error: 125.3034\n",
      "Epoch 110: loss did not improve from 15777.63770\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15625.9434 - mean_absolute_error: 123.2674 - val_loss: 19327.6484 - val_mean_absolute_error: 137.4432\n",
      "Epoch 111/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 14952.5996 - mean_absolute_error: 121.1110\n",
      "Epoch 111: loss improved from 15777.63770 to 15723.09863, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15588.0732 - mean_absolute_error: 123.3698 - val_loss: 19251.7812 - val_mean_absolute_error: 137.1697\n",
      "Epoch 112/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 15967.4951 - mean_absolute_error: 124.6835\n",
      "Epoch 112: loss improved from 15723.09863 to 15633.24316, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15615.3125 - mean_absolute_error: 123.3067 - val_loss: 19176.3281 - val_mean_absolute_error: 136.8972\n",
      "Epoch 113/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 14949.3867 - mean_absolute_error: 120.5696\n",
      "Epoch 113: loss improved from 15633.24316 to 15423.35156, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15357.9355 - mean_absolute_error: 122.3945 - val_loss: 19101.3320 - val_mean_absolute_error: 136.6258\n",
      "Epoch 114/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16211.1582 - mean_absolute_error: 126.0762\n",
      "Epoch 114: loss did not improve from 15423.35156\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15478.1953 - mean_absolute_error: 122.6315 - val_loss: 19026.7598 - val_mean_absolute_error: 136.3554\n",
      "Epoch 115/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14812.2090 - mean_absolute_error: 119.8838\n",
      "Epoch 115: loss improved from 15423.35156 to 15082.81055, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14984.5527 - mean_absolute_error: 121.1618 - val_loss: 18952.3574 - val_mean_absolute_error: 136.0851\n",
      "Epoch 116/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 15027.4482 - mean_absolute_error: 121.1022\n",
      "Epoch 116: loss did not improve from 15082.81055\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15284.2852 - mean_absolute_error: 122.0343 - val_loss: 18878.5391 - val_mean_absolute_error: 135.8163\n",
      "Epoch 117/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16460.6504 - mean_absolute_error: 127.0864\n",
      "Epoch 117: loss improved from 15082.81055 to 15001.06348, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15482.3760 - mean_absolute_error: 123.1484 - val_loss: 18804.8887 - val_mean_absolute_error: 135.5477\n",
      "Epoch 118/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16419.8633 - mean_absolute_error: 126.6032\n",
      "Epoch 118: loss did not improve from 15001.06348\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15260.1562 - mean_absolute_error: 122.0980 - val_loss: 18731.8984 - val_mean_absolute_error: 135.2810\n",
      "Epoch 119/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 15750.4658 - mean_absolute_error: 124.2294\n",
      "Epoch 119: loss improved from 15001.06348 to 14941.90820, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15312.5898 - mean_absolute_error: 122.4102 - val_loss: 18659.0293 - val_mean_absolute_error: 135.0141\n",
      "Epoch 120/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14442.1973 - mean_absolute_error: 118.1889\n",
      "Epoch 120: loss improved from 14941.90820 to 14780.35156, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14879.6025 - mean_absolute_error: 120.5892 - val_loss: 18586.6523 - val_mean_absolute_error: 134.7486\n",
      "Epoch 121/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14594.4414 - mean_absolute_error: 119.4393\n",
      "Epoch 121: loss improved from 14780.35156 to 14674.27930, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14958.1787 - mean_absolute_error: 121.1313 - val_loss: 18514.5781 - val_mean_absolute_error: 134.4836\n",
      "Epoch 122/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14298.9297 - mean_absolute_error: 118.1623\n",
      "Epoch 122: loss did not improve from 14674.27930\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14961.9209 - mean_absolute_error: 121.0612 - val_loss: 18442.8672 - val_mean_absolute_error: 134.2195\n",
      "Epoch 123/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14558.6865 - mean_absolute_error: 118.7895\n",
      "Epoch 123: loss did not improve from 14674.27930\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14686.0684 - mean_absolute_error: 119.5914 - val_loss: 18371.5508 - val_mean_absolute_error: 133.9563\n",
      "Epoch 124/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 15428.9424 - mean_absolute_error: 122.6657\n",
      "Epoch 124: loss improved from 14674.27930 to 14642.93457, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14749.8359 - mean_absolute_error: 120.0392 - val_loss: 18300.1680 - val_mean_absolute_error: 133.6923\n",
      "Epoch 125/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14705.9297 - mean_absolute_error: 119.7716\n",
      "Epoch 125: loss improved from 14642.93457 to 14624.73535, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14672.6250 - mean_absolute_error: 119.6509 - val_loss: 18228.9492 - val_mean_absolute_error: 133.4285\n",
      "Epoch 126/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14391.8594 - mean_absolute_error: 118.4665\n",
      "Epoch 126: loss improved from 14624.73535 to 14518.27930, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14694.7812 - mean_absolute_error: 119.8116 - val_loss: 18157.9141 - val_mean_absolute_error: 133.1648\n",
      "Epoch 127/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13729.2031 - mean_absolute_error: 115.7356\n",
      "Epoch 127: loss improved from 14518.27930 to 14499.71973, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14356.4531 - mean_absolute_error: 118.4159 - val_loss: 18087.3242 - val_mean_absolute_error: 132.9023\n",
      "Epoch 128/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 14313.6035 - mean_absolute_error: 118.0079\n",
      "Epoch 128: loss improved from 14499.71973 to 14409.15039, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14542.7725 - mean_absolute_error: 119.2032 - val_loss: 18016.8809 - val_mean_absolute_error: 132.6398\n",
      "Epoch 129/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14022.1416 - mean_absolute_error: 117.2390\n",
      "Epoch 129: loss improved from 14409.15039 to 14372.90820, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14352.8750 - mean_absolute_error: 118.4595 - val_loss: 17946.7852 - val_mean_absolute_error: 132.3780\n",
      "Epoch 130/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13416.8994 - mean_absolute_error: 114.3623\n",
      "Epoch 130: loss did not improve from 14372.90820\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14201.2236 - mean_absolute_error: 117.3196 - val_loss: 17876.9102 - val_mean_absolute_error: 132.1166\n",
      "Epoch 131/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15371.4375 - mean_absolute_error: 122.8551\n",
      "Epoch 131: loss improved from 14372.90820 to 14269.76758, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14431.3340 - mean_absolute_error: 118.6803 - val_loss: 17806.8672 - val_mean_absolute_error: 131.8540\n",
      "Epoch 132/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14394.3926 - mean_absolute_error: 118.3125\n",
      "Epoch 132: loss improved from 14269.76758 to 13893.96582, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 14473.3672 - mean_absolute_error: 119.0995 - val_loss: 17737.1055 - val_mean_absolute_error: 131.5920\n",
      "Epoch 133/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15571.0605 - mean_absolute_error: 123.1899\n",
      "Epoch 133: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14502.8457 - mean_absolute_error: 118.6964 - val_loss: 17668.1719 - val_mean_absolute_error: 131.3326\n",
      "Epoch 134/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13848.5508 - mean_absolute_error: 116.2192\n",
      "Epoch 134: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13998.4473 - mean_absolute_error: 116.7281 - val_loss: 17599.3047 - val_mean_absolute_error: 131.0729\n",
      "Epoch 135/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 13118.0244 - mean_absolute_error: 112.8083\n",
      "Epoch 135: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13906.2637 - mean_absolute_error: 115.9995 - val_loss: 17530.4375 - val_mean_absolute_error: 130.8127\n",
      "Epoch 136/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14371.2852 - mean_absolute_error: 118.6151\n",
      "Epoch 136: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 14214.5684 - mean_absolute_error: 117.4729 - val_loss: 17461.3125 - val_mean_absolute_error: 130.5511\n",
      "Epoch 137/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15508.9180 - mean_absolute_error: 123.1212\n",
      "Epoch 137: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14306.6465 - mean_absolute_error: 118.0909 - val_loss: 17392.2969 - val_mean_absolute_error: 130.2893\n",
      "Epoch 138/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13556.4238 - mean_absolute_error: 114.9670\n",
      "Epoch 138: loss did not improve from 13893.96582\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13796.3154 - mean_absolute_error: 115.7007 - val_loss: 17323.9609 - val_mean_absolute_error: 130.0295\n",
      "Epoch 139/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14454.0557 - mean_absolute_error: 118.5725\n",
      "Epoch 139: loss improved from 13893.96582 to 13777.75781, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14127.5469 - mean_absolute_error: 117.3201 - val_loss: 17255.5586 - val_mean_absolute_error: 129.7691\n",
      "Epoch 140/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15196.9844 - mean_absolute_error: 121.9941\n",
      "Epoch 140: loss did not improve from 13777.75781\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14310.6064 - mean_absolute_error: 117.9300 - val_loss: 17187.6211 - val_mean_absolute_error: 129.5098\n",
      "Epoch 141/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13919.9385 - mean_absolute_error: 116.5507\n",
      "Epoch 141: loss improved from 13777.75781 to 13738.53711, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13806.3213 - mean_absolute_error: 115.8477 - val_loss: 17120.1211 - val_mean_absolute_error: 129.2518\n",
      "Epoch 142/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14284.9795 - mean_absolute_error: 117.9293\n",
      "Epoch 142: loss improved from 13738.53711 to 13262.55957, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13768.2539 - mean_absolute_error: 116.1254 - val_loss: 17052.9180 - val_mean_absolute_error: 128.9943\n",
      "Epoch 143/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12851.2217 - mean_absolute_error: 111.9975\n",
      "Epoch 143: loss did not improve from 13262.55957\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13509.0469 - mean_absolute_error: 114.3412 - val_loss: 16986.5195 - val_mean_absolute_error: 128.7395\n",
      "Epoch 144/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12986.7061 - mean_absolute_error: 112.3950\n",
      "Epoch 144: loss did not improve from 13262.55957\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13555.6172 - mean_absolute_error: 114.7682 - val_loss: 16919.6562 - val_mean_absolute_error: 128.4823\n",
      "Epoch 145/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11916.0273 - mean_absolute_error: 107.6347\n",
      "Epoch 145: loss did not improve from 13262.55957\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13300.9912 - mean_absolute_error: 113.6440 - val_loss: 16853.1641 - val_mean_absolute_error: 128.2261\n",
      "Epoch 146/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14301.7344 - mean_absolute_error: 118.0228\n",
      "Epoch 146: loss did not improve from 13262.55957\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13484.9395 - mean_absolute_error: 114.5384 - val_loss: 16786.8203 - val_mean_absolute_error: 127.9699\n",
      "Epoch 147/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14005.0605 - mean_absolute_error: 116.9224\n",
      "Epoch 147: loss improved from 13262.55957 to 13160.46777, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 13446.1582 - mean_absolute_error: 114.6008 - val_loss: 16720.7070 - val_mean_absolute_error: 127.7141\n",
      "Epoch 148/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14262.2676 - mean_absolute_error: 117.5935\n",
      "Epoch 148: loss did not improve from 13160.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13751.6582 - mean_absolute_error: 115.5612 - val_loss: 16654.9375 - val_mean_absolute_error: 127.4592\n",
      "Epoch 149/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13234.7920 - mean_absolute_error: 114.1134\n",
      "Epoch 149: loss did not improve from 13160.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13444.8691 - mean_absolute_error: 114.4435 - val_loss: 16589.4453 - val_mean_absolute_error: 127.2048\n",
      "Epoch 150/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12058.2861 - mean_absolute_error: 108.3619\n",
      "Epoch 150: loss did not improve from 13160.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12846.6094 - mean_absolute_error: 111.4606 - val_loss: 16524.3340 - val_mean_absolute_error: 126.9514\n",
      "Epoch 151/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13168.4883 - mean_absolute_error: 113.5527\n",
      "Epoch 151: loss did not improve from 13160.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13237.5020 - mean_absolute_error: 113.2897 - val_loss: 16458.8203 - val_mean_absolute_error: 126.6959\n",
      "Epoch 152/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13790.1855 - mean_absolute_error: 115.4534\n",
      "Epoch 152: loss did not improve from 13160.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13121.5840 - mean_absolute_error: 112.6888 - val_loss: 16393.4922 - val_mean_absolute_error: 126.4407\n",
      "Epoch 153/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12615.5664 - mean_absolute_error: 110.7657\n",
      "Epoch 153: loss improved from 13160.46777 to 12992.97559, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13069.0811 - mean_absolute_error: 112.7686 - val_loss: 16328.3916 - val_mean_absolute_error: 126.1858\n",
      "Epoch 154/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 13079.8926 - mean_absolute_error: 112.5516\n",
      "Epoch 154: loss did not improve from 12992.97559\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12983.3984 - mean_absolute_error: 112.0198 - val_loss: 16263.8271 - val_mean_absolute_error: 125.9325\n",
      "Epoch 155/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12983.9434 - mean_absolute_error: 112.0985\n",
      "Epoch 155: loss improved from 12992.97559 to 12798.93164, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12724.6914 - mean_absolute_error: 111.1846 - val_loss: 16199.4082 - val_mean_absolute_error: 125.6793\n",
      "Epoch 156/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12121.7637 - mean_absolute_error: 108.4567\n",
      "Epoch 156: loss did not improve from 12798.93164\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12837.2402 - mean_absolute_error: 111.3667 - val_loss: 16135.2715 - val_mean_absolute_error: 125.4267\n",
      "Epoch 157/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 12866.7266 - mean_absolute_error: 111.8112\n",
      "Epoch 157: loss did not improve from 12798.93164\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12918.0547 - mean_absolute_error: 111.9502 - val_loss: 16071.0781 - val_mean_absolute_error: 125.1734\n",
      "Epoch 158/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12987.7910 - mean_absolute_error: 112.8974\n",
      "Epoch 158: loss improved from 12798.93164 to 12553.05664, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12782.8955 - mean_absolute_error: 111.7140 - val_loss: 16007.3125 - val_mean_absolute_error: 124.9213\n",
      "Epoch 159/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14014.6807 - mean_absolute_error: 116.9145\n",
      "Epoch 159: loss did not improve from 12553.05664\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12970.8066 - mean_absolute_error: 112.1216 - val_loss: 15944.0195 - val_mean_absolute_error: 124.6705\n",
      "Epoch 160/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11972.1523 - mean_absolute_error: 107.5357\n",
      "Epoch 160: loss did not improve from 12553.05664\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12368.7070 - mean_absolute_error: 109.4246 - val_loss: 15881.0205 - val_mean_absolute_error: 124.4204\n",
      "Epoch 161/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13014.1191 - mean_absolute_error: 112.2944\n",
      "Epoch 161: loss did not improve from 12553.05664\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12720.5107 - mean_absolute_error: 111.0593 - val_loss: 15817.9023 - val_mean_absolute_error: 124.1693\n",
      "Epoch 162/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 14053.3086 - mean_absolute_error: 116.6156\n",
      "Epoch 162: loss improved from 12553.05664 to 12366.43652, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12946.8691 - mean_absolute_error: 112.1812 - val_loss: 15754.9258 - val_mean_absolute_error: 123.9183\n",
      "Epoch 163/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12143.9336 - mean_absolute_error: 108.4538\n",
      "Epoch 163: loss improved from 12366.43652 to 12245.51367, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12312.8467 - mean_absolute_error: 109.5222 - val_loss: 15692.7891 - val_mean_absolute_error: 123.6701\n",
      "Epoch 164/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12570.8623 - mean_absolute_error: 110.4568\n",
      "Epoch 164: loss did not improve from 12245.51367\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12317.2930 - mean_absolute_error: 109.2388 - val_loss: 15630.9736 - val_mean_absolute_error: 123.4227\n",
      "Epoch 165/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11847.5518 - mean_absolute_error: 107.2711\n",
      "Epoch 165: loss improved from 12245.51367 to 12235.07617, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12119.2227 - mean_absolute_error: 108.4795 - val_loss: 15569.0820 - val_mean_absolute_error: 123.1746\n",
      "Epoch 166/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12626.1348 - mean_absolute_error: 110.5745\n",
      "Epoch 166: loss did not improve from 12235.07617\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12460.3496 - mean_absolute_error: 109.8217 - val_loss: 15507.2666 - val_mean_absolute_error: 122.9262\n",
      "Epoch 167/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13481.1982 - mean_absolute_error: 114.5387\n",
      "Epoch 167: loss did not improve from 12235.07617\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12436.4600 - mean_absolute_error: 109.6385 - val_loss: 15445.6445 - val_mean_absolute_error: 122.6781\n",
      "Epoch 168/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11976.5156 - mean_absolute_error: 107.9847\n",
      "Epoch 168: loss improved from 12235.07617 to 12182.92383, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12168.2188 - mean_absolute_error: 108.6513 - val_loss: 15384.0967 - val_mean_absolute_error: 122.4299\n",
      "Epoch 169/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12340.0938 - mean_absolute_error: 109.8720\n",
      "Epoch 169: loss improved from 12182.92383 to 12050.15723, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12240.3340 - mean_absolute_error: 109.1642 - val_loss: 15322.7842 - val_mean_absolute_error: 122.1820\n",
      "Epoch 170/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10248.3340 - mean_absolute_error: 99.4908\n",
      "Epoch 170: loss did not improve from 12050.15723\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11568.3184 - mean_absolute_error: 105.6785 - val_loss: 15262.1064 - val_mean_absolute_error: 121.9363\n",
      "Epoch 171/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12218.3818 - mean_absolute_error: 109.0970\n",
      "Epoch 171: loss improved from 12050.15723 to 12045.82129, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12210.1318 - mean_absolute_error: 108.8799 - val_loss: 15201.0801 - val_mean_absolute_error: 121.6887\n",
      "Epoch 172/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11727.7158 - mean_absolute_error: 106.5118\n",
      "Epoch 172: loss improved from 12045.82129 to 11814.41406, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11954.8516 - mean_absolute_error: 107.7642 - val_loss: 15140.4619 - val_mean_absolute_error: 121.4422\n",
      "Epoch 173/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12435.5693 - mean_absolute_error: 109.7703\n",
      "Epoch 173: loss did not improve from 11814.41406\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12114.9824 - mean_absolute_error: 108.2696 - val_loss: 15080.1943 - val_mean_absolute_error: 121.1966\n",
      "Epoch 174/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11576.6455 - mean_absolute_error: 106.1065\n",
      "Epoch 174: loss improved from 11814.41406 to 11744.00684, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11722.5420 - mean_absolute_error: 106.7874 - val_loss: 15020.1211 - val_mean_absolute_error: 120.9514\n",
      "Epoch 175/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11701.0615 - mean_absolute_error: 106.7165\n",
      "Epoch 175: loss improved from 11744.00684 to 11723.04980, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11822.8477 - mean_absolute_error: 107.1378 - val_loss: 14960.2402 - val_mean_absolute_error: 120.7064\n",
      "Epoch 176/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12171.6758 - mean_absolute_error: 108.8064\n",
      "Epoch 176: loss did not improve from 11723.04980\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11857.2598 - mean_absolute_error: 107.1140 - val_loss: 14900.5488 - val_mean_absolute_error: 120.4617\n",
      "Epoch 177/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13410.6885 - mean_absolute_error: 114.5374\n",
      "Epoch 177: loss did not improve from 11723.04980\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12090.2646 - mean_absolute_error: 108.1165 - val_loss: 14840.8154 - val_mean_absolute_error: 120.2164\n",
      "Epoch 178/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11148.9824 - mean_absolute_error: 103.3082\n",
      "Epoch 178: loss did not improve from 11723.04980\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11623.0361 - mean_absolute_error: 105.7713 - val_loss: 14781.2959 - val_mean_absolute_error: 119.9714\n",
      "Epoch 179/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12927.9141 - mean_absolute_error: 112.0470\n",
      "Epoch 179: loss improved from 11723.04980 to 11440.13379, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11887.7969 - mean_absolute_error: 107.5478 - val_loss: 14721.6729 - val_mean_absolute_error: 119.7256\n",
      "Epoch 180/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11696.0889 - mean_absolute_error: 106.5517\n",
      "Epoch 180: loss did not improve from 11440.13379\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11737.2158 - mean_absolute_error: 106.7546 - val_loss: 14662.7168 - val_mean_absolute_error: 119.4820\n",
      "Epoch 181/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11909.1504 - mean_absolute_error: 107.9338\n",
      "Epoch 181: loss improved from 11440.13379 to 11293.91406, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11441.0234 - mean_absolute_error: 105.5471 - val_loss: 14604.1953 - val_mean_absolute_error: 119.2396\n",
      "Epoch 182/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 10167.8496 - mean_absolute_error: 98.9874\n",
      "Epoch 182: loss did not improve from 11293.91406\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11224.2676 - mean_absolute_error: 103.9070 - val_loss: 14545.9238 - val_mean_absolute_error: 118.9979\n",
      "Epoch 183/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11577.6309 - mean_absolute_error: 106.2234\n",
      "Epoch 183: loss improved from 11293.91406 to 11180.09570, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11581.0947 - mean_absolute_error: 106.1955 - val_loss: 14487.2051 - val_mean_absolute_error: 118.7538\n",
      "Epoch 184/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12188.1543 - mean_absolute_error: 108.7725\n",
      "Epoch 184: loss did not improve from 11180.09570\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11541.0596 - mean_absolute_error: 105.6327 - val_loss: 14429.1309 - val_mean_absolute_error: 118.5119\n",
      "Epoch 185/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10181.8496 - mean_absolute_error: 98.6639\n",
      "Epoch 185: loss did not improve from 11180.09570\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11054.8340 - mean_absolute_error: 103.3474 - val_loss: 14371.1348 - val_mean_absolute_error: 118.2698\n",
      "Epoch 186/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11846.6367 - mean_absolute_error: 107.4087\n",
      "Epoch 186: loss did not improve from 11180.09570\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11419.0889 - mean_absolute_error: 105.1714 - val_loss: 14313.2363 - val_mean_absolute_error: 118.0276\n",
      "Epoch 187/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11112.7598 - mean_absolute_error: 103.7579\n",
      "Epoch 187: loss did not improve from 11180.09570\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11243.3457 - mean_absolute_error: 104.1628 - val_loss: 14255.5410 - val_mean_absolute_error: 117.7858\n",
      "Epoch 188/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 10038.5117 - mean_absolute_error: 97.8878\n",
      "Epoch 188: loss improved from 11180.09570 to 11157.55566, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10896.9883 - mean_absolute_error: 102.3841 - val_loss: 14198.0645 - val_mean_absolute_error: 117.5445\n",
      "Epoch 189/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11714.0293 - mean_absolute_error: 105.9065\n",
      "Epoch 189: loss improved from 11157.55566 to 11066.46777, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11192.0127 - mean_absolute_error: 103.9485 - val_loss: 14140.6191 - val_mean_absolute_error: 117.3027\n",
      "Epoch 190/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10610.4697 - mean_absolute_error: 101.1337\n",
      "Epoch 190: loss did not improve from 11066.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10966.1973 - mean_absolute_error: 102.6032 - val_loss: 14083.5078 - val_mean_absolute_error: 117.0619\n",
      "Epoch 191/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11657.7871 - mean_absolute_error: 106.4991\n",
      "Epoch 191: loss did not improve from 11066.46777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11301.3164 - mean_absolute_error: 104.3417 - val_loss: 14026.0664 - val_mean_absolute_error: 116.8192\n",
      "Epoch 192/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11193.6621 - mean_absolute_error: 103.9658\n",
      "Epoch 192: loss improved from 11066.46777 to 10838.74121, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10977.2246 - mean_absolute_error: 103.0614 - val_loss: 13968.8945 - val_mean_absolute_error: 116.5772\n",
      "Epoch 193/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11102.7871 - mean_absolute_error: 103.8171\n",
      "Epoch 193: loss did not improve from 10838.74121\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10856.4551 - mean_absolute_error: 102.3705 - val_loss: 13912.2520 - val_mean_absolute_error: 116.3369\n",
      "Epoch 194/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 10425.6035 - mean_absolute_error: 100.1902\n",
      "Epoch 194: loss did not improve from 10838.74121\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10955.7822 - mean_absolute_error: 102.6861 - val_loss: 13855.6348 - val_mean_absolute_error: 116.0962\n",
      "Epoch 195/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10054.7578 - mean_absolute_error: 98.6274\n",
      "Epoch 195: loss improved from 10838.74121 to 10800.46094, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10697.1846 - mean_absolute_error: 101.6416 - val_loss: 13799.2275 - val_mean_absolute_error: 115.8559\n",
      "Epoch 196/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11049.4404 - mean_absolute_error: 103.5592\n",
      "Epoch 196: loss improved from 10800.46094 to 10685.71777, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10754.3711 - mean_absolute_error: 101.9741 - val_loss: 13743.0703 - val_mean_absolute_error: 115.6162\n",
      "Epoch 197/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11242.5771 - mean_absolute_error: 104.1323\n",
      "Epoch 197: loss did not improve from 10685.71777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10628.3906 - mean_absolute_error: 101.2240 - val_loss: 13687.3535 - val_mean_absolute_error: 115.3779\n",
      "Epoch 198/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9844.6914 - mean_absolute_error: 97.2443\n",
      "Epoch 198: loss improved from 10685.71777 to 10411.09180, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10726.9102 - mean_absolute_error: 102.0801 - val_loss: 13631.5527 - val_mean_absolute_error: 115.1387\n",
      "Epoch 199/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11486.5625 - mean_absolute_error: 105.2844\n",
      "Epoch 199: loss did not improve from 10411.09180\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10994.9746 - mean_absolute_error: 102.9030 - val_loss: 13576.3145 - val_mean_absolute_error: 114.9015\n",
      "Epoch 200/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10460.1699 - mean_absolute_error: 99.9450\n",
      "Epoch 200: loss did not improve from 10411.09180\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10590.6699 - mean_absolute_error: 101.0967 - val_loss: 13521.2266 - val_mean_absolute_error: 114.6644\n",
      "Epoch 201/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11350.3750 - mean_absolute_error: 104.9537\n",
      "Epoch 201: loss did not improve from 10411.09180\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10795.3623 - mean_absolute_error: 101.8519 - val_loss: 13466.1992 - val_mean_absolute_error: 114.4271\n",
      "Epoch 202/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9781.3301 - mean_absolute_error: 96.8860\n",
      "Epoch 202: loss improved from 10411.09180 to 10218.27637, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10383.9219 - mean_absolute_error: 100.3056 - val_loss: 13411.1172 - val_mean_absolute_error: 114.1890\n",
      "Epoch 203/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10373.5996 - mean_absolute_error: 99.5088\n",
      "Epoch 203: loss did not improve from 10218.27637\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10422.2461 - mean_absolute_error: 100.0672 - val_loss: 13356.6191 - val_mean_absolute_error: 113.9531\n",
      "Epoch 204/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10520.1123 - mean_absolute_error: 99.6929\n",
      "Epoch 204: loss did not improve from 10218.27637\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10306.3330 - mean_absolute_error: 99.2776 - val_loss: 13302.1602 - val_mean_absolute_error: 113.7168\n",
      "Epoch 205/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10602.6602 - mean_absolute_error: 101.0919\n",
      "Epoch 205: loss did not improve from 10218.27637\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10352.1572 - mean_absolute_error: 99.6984 - val_loss: 13247.5928 - val_mean_absolute_error: 113.4795\n",
      "Epoch 206/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11194.3906 - mean_absolute_error: 104.0456\n",
      "Epoch 206: loss improved from 10218.27637 to 10085.44531, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10452.0879 - mean_absolute_error: 100.7507 - val_loss: 13192.9912 - val_mean_absolute_error: 113.2416\n",
      "Epoch 207/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11044.0449 - mean_absolute_error: 103.5399\n",
      "Epoch 207: loss did not improve from 10085.44531\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10407.5840 - mean_absolute_error: 100.1900 - val_loss: 13139.0527 - val_mean_absolute_error: 113.0061\n",
      "Epoch 208/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9744.4688 - mean_absolute_error: 97.2526\n",
      "Epoch 208: loss did not improve from 10085.44531\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10150.2676 - mean_absolute_error: 98.7021 - val_loss: 13085.2275 - val_mean_absolute_error: 112.7706\n",
      "Epoch 209/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9041.1191 - mean_absolute_error: 93.0374\n",
      "Epoch 209: loss improved from 10085.44531 to 10047.89844, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9912.4053 - mean_absolute_error: 97.7812 - val_loss: 13031.3604 - val_mean_absolute_error: 112.5345\n",
      "Epoch 210/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9543.4814 - mean_absolute_error: 95.5456\n",
      "Epoch 210: loss improved from 10047.89844 to 10016.52344, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10096.1445 - mean_absolute_error: 98.6566 - val_loss: 12977.7871 - val_mean_absolute_error: 112.2991\n",
      "Epoch 211/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10162.8086 - mean_absolute_error: 98.7469\n",
      "Epoch 211: loss improved from 10016.52344 to 9893.82324, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10104.2949 - mean_absolute_error: 98.7619 - val_loss: 12924.5205 - val_mean_absolute_error: 112.0646\n",
      "Epoch 212/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9802.4561 - mean_absolute_error: 96.8891\n",
      "Epoch 212: loss did not improve from 9893.82324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9863.7539 - mean_absolute_error: 97.3101 - val_loss: 12871.6914 - val_mean_absolute_error: 111.8316\n",
      "Epoch 213/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 10078.6074 - mean_absolute_error: 98.2640\n",
      "Epoch 213: loss did not improve from 9893.82324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9894.8145 - mean_absolute_error: 97.3508 - val_loss: 12818.7266 - val_mean_absolute_error: 111.5975\n",
      "Epoch 214/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8799.2852 - mean_absolute_error: 91.9788\n",
      "Epoch 214: loss did not improve from 9893.82324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9978.1670 - mean_absolute_error: 97.7514 - val_loss: 12765.5664 - val_mean_absolute_error: 111.3620\n",
      "Epoch 215/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10330.6797 - mean_absolute_error: 100.0561\n",
      "Epoch 215: loss improved from 9893.82324 to 9607.31934, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9832.2402 - mean_absolute_error: 97.6595 - val_loss: 12712.6123 - val_mean_absolute_error: 111.1269\n",
      "Epoch 216/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10253.3662 - mean_absolute_error: 99.4435\n",
      "Epoch 216: loss did not improve from 9607.31934\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10020.2549 - mean_absolute_error: 97.8728 - val_loss: 12660.1377 - val_mean_absolute_error: 110.8935\n",
      "Epoch 217/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9206.9189 - mean_absolute_error: 93.5987\n",
      "Epoch 217: loss did not improve from 9607.31934\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9551.5723 - mean_absolute_error: 95.4209 - val_loss: 12607.6582 - val_mean_absolute_error: 110.6596\n",
      "Epoch 218/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10678.3594 - mean_absolute_error: 101.2417\n",
      "Epoch 218: loss improved from 9607.31934 to 9532.12598, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9922.8047 - mean_absolute_error: 97.9426 - val_loss: 12554.9531 - val_mean_absolute_error: 110.4242\n",
      "Epoch 219/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9855.3115 - mean_absolute_error: 97.4003\n",
      "Epoch 219: loss did not improve from 9532.12598\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9651.2852 - mean_absolute_error: 96.3037 - val_loss: 12503.0703 - val_mean_absolute_error: 110.1920\n",
      "Epoch 220/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10363.4434 - mean_absolute_error: 100.3798\n",
      "Epoch 220: loss did not improve from 9532.12598\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9842.1436 - mean_absolute_error: 97.2329 - val_loss: 12451.1816 - val_mean_absolute_error: 109.9592\n",
      "Epoch 221/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9146.8750 - mean_absolute_error: 93.7336\n",
      "Epoch 221: loss did not improve from 9532.12598\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9416.9043 - mean_absolute_error: 95.0900 - val_loss: 12399.6074 - val_mean_absolute_error: 109.7274\n",
      "Epoch 222/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9410.7227 - mean_absolute_error: 94.5766\n",
      "Epoch 222: loss did not improve from 9532.12598\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9428.1367 - mean_absolute_error: 94.8568 - val_loss: 12348.1699 - val_mean_absolute_error: 109.4957\n",
      "Epoch 223/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10175.6729 - mean_absolute_error: 98.8607\n",
      "Epoch 223: loss did not improve from 9532.12598\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9702.0293 - mean_absolute_error: 96.3898 - val_loss: 12296.5488 - val_mean_absolute_error: 109.2627\n",
      "Epoch 224/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9005.6914 - mean_absolute_error: 93.0214\n",
      "Epoch 224: loss improved from 9532.12598 to 9501.19727, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9209.9004 - mean_absolute_error: 93.9638 - val_loss: 12245.3516 - val_mean_absolute_error: 109.0312\n",
      "Epoch 225/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9260.9922 - mean_absolute_error: 93.6511\n",
      "Epoch 225: loss improved from 9501.19727 to 9400.19629, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9399.1240 - mean_absolute_error: 94.8289 - val_loss: 12194.1523 - val_mean_absolute_error: 108.7991\n",
      "Epoch 226/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10519.8271 - mean_absolute_error: 99.8655\n",
      "Epoch 226: loss did not improve from 9400.19629\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9663.9180 - mean_absolute_error: 96.1647 - val_loss: 12143.1250 - val_mean_absolute_error: 108.5673\n",
      "Epoch 227/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8639.6543 - mean_absolute_error: 91.1393\n",
      "Epoch 227: loss improved from 9400.19629 to 9338.18066, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9096.3486 - mean_absolute_error: 93.4346 - val_loss: 12092.5498 - val_mean_absolute_error: 108.3371\n",
      "Epoch 228/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9498.2334 - mean_absolute_error: 95.9176\n",
      "Epoch 228: loss improved from 9338.18066 to 8922.06445, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9235.4619 - mean_absolute_error: 94.6568 - val_loss: 12042.0371 - val_mean_absolute_error: 108.1067\n",
      "Epoch 229/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9153.7461 - mean_absolute_error: 93.5167\n",
      "Epoch 229: loss did not improve from 8922.06445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9088.0322 - mean_absolute_error: 93.4045 - val_loss: 11992.2852 - val_mean_absolute_error: 107.8793\n",
      "Epoch 230/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9744.2510 - mean_absolute_error: 97.0211\n",
      "Epoch 230: loss did not improve from 8922.06445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9337.6152 - mean_absolute_error: 94.9275 - val_loss: 11942.3232 - val_mean_absolute_error: 107.6505\n",
      "Epoch 231/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8950.2598 - mean_absolute_error: 92.6645\n",
      "Epoch 231: loss did not improve from 8922.06445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9025.0264 - mean_absolute_error: 92.9147 - val_loss: 11892.7607 - val_mean_absolute_error: 107.4230\n",
      "Epoch 232/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8436.9453 - mean_absolute_error: 90.0949\n",
      "Epoch 232: loss did not improve from 8922.06445\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9080.9238 - mean_absolute_error: 93.1827 - val_loss: 11842.8740 - val_mean_absolute_error: 107.1936\n",
      "Epoch 233/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9830.0547 - mean_absolute_error: 98.0397\n",
      "Epoch 233: loss improved from 8922.06445 to 8755.55371, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9252.9443 - mean_absolute_error: 94.7576 - val_loss: 11792.9844 - val_mean_absolute_error: 106.9636\n",
      "Epoch 234/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9961.4570 - mean_absolute_error: 98.1155\n",
      "Epoch 234: loss did not improve from 8755.55371\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9165.9834 - mean_absolute_error: 94.0204 - val_loss: 11743.8350 - val_mean_absolute_error: 106.7366\n",
      "Epoch 235/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9465.0635 - mean_absolute_error: 94.9074\n",
      "Epoch 235: loss did not improve from 8755.55371\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9022.5439 - mean_absolute_error: 92.8066 - val_loss: 11694.9424 - val_mean_absolute_error: 106.5103\n",
      "Epoch 236/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9572.3477 - mean_absolute_error: 96.0248\n",
      "Epoch 236: loss did not improve from 8755.55371\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9121.4336 - mean_absolute_error: 93.3525 - val_loss: 11645.7559 - val_mean_absolute_error: 106.2821\n",
      "Epoch 237/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9754.7910 - mean_absolute_error: 96.8217\n",
      "Epoch 237: loss improved from 8755.55371 to 8632.70312, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9147.4512 - mean_absolute_error: 94.0282 - val_loss: 11596.4297 - val_mean_absolute_error: 106.0528\n",
      "Epoch 238/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8689.9102 - mean_absolute_error: 90.9437\n",
      "Epoch 238: loss did not improve from 8632.70312\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8721.1387 - mean_absolute_error: 91.5047 - val_loss: 11548.0215 - val_mean_absolute_error: 105.8273\n",
      "Epoch 239/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8861.2734 - mean_absolute_error: 92.2137\n",
      "Epoch 239: loss did not improve from 8632.70312\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8768.6152 - mean_absolute_error: 91.8262 - val_loss: 11499.5918 - val_mean_absolute_error: 105.6013\n",
      "Epoch 240/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8472.0156 - mean_absolute_error: 89.6741\n",
      "Epoch 240: loss did not improve from 8632.70312\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8725.6221 - mean_absolute_error: 91.2153 - val_loss: 11451.3105 - val_mean_absolute_error: 105.3754\n",
      "Epoch 241/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9333.8965 - mean_absolute_error: 95.1096\n",
      "Epoch 241: loss did not improve from 8632.70312\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8860.4355 - mean_absolute_error: 92.1695 - val_loss: 11402.7734 - val_mean_absolute_error: 105.1479\n",
      "Epoch 242/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9080.3125 - mean_absolute_error: 93.5254\n",
      "Epoch 242: loss improved from 8632.70312 to 8538.98242, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8775.3828 - mean_absolute_error: 91.8715 - val_loss: 11354.5020 - val_mean_absolute_error: 104.9211\n",
      "Epoch 243/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9101.2344 - mean_absolute_error: 93.0437\n",
      "Epoch 243: loss did not improve from 8538.98242\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8717.1631 - mean_absolute_error: 91.1895 - val_loss: 11306.5605 - val_mean_absolute_error: 104.6954\n",
      "Epoch 244/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8371.5918 - mean_absolute_error: 88.8138\n",
      "Epoch 244: loss did not improve from 8538.98242\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8581.3174 - mean_absolute_error: 90.4860 - val_loss: 11258.5762 - val_mean_absolute_error: 104.4690\n",
      "Epoch 245/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7587.4990 - mean_absolute_error: 85.4605\n",
      "Epoch 245: loss did not improve from 8538.98242\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8476.8516 - mean_absolute_error: 89.8979 - val_loss: 11210.7754 - val_mean_absolute_error: 104.2430\n",
      "Epoch 246/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9167.9326 - mean_absolute_error: 93.9426\n",
      "Epoch 246: loss improved from 8538.98242 to 8464.60254, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8675.6670 - mean_absolute_error: 91.2370 - val_loss: 11162.9434 - val_mean_absolute_error: 104.0164\n",
      "Epoch 247/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8222.9365 - mean_absolute_error: 88.0590\n",
      "Epoch 247: loss did not improve from 8464.60254\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8515.8535 - mean_absolute_error: 90.1034 - val_loss: 11115.4785 - val_mean_absolute_error: 103.7910\n",
      "Epoch 248/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8559.4541 - mean_absolute_error: 90.1487\n",
      "Epoch 248: loss did not improve from 8464.60254\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8432.5781 - mean_absolute_error: 89.5741 - val_loss: 11068.1699 - val_mean_absolute_error: 103.5659\n",
      "Epoch 249/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7326.5537 - mean_absolute_error: 83.7999\n",
      "Epoch 249: loss did not improve from 8464.60254\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8126.4512 - mean_absolute_error: 87.7670 - val_loss: 11021.0215 - val_mean_absolute_error: 103.3411\n",
      "Epoch 250/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8155.6865 - mean_absolute_error: 88.8431\n",
      "Epoch 250: loss improved from 8464.60254 to 8108.96777, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8287.0869 - mean_absolute_error: 89.5406 - val_loss: 10973.5420 - val_mean_absolute_error: 103.1142\n",
      "Epoch 251/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8299.0596 - mean_absolute_error: 88.7260\n",
      "Epoch 251: loss did not improve from 8108.96777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8229.6689 - mean_absolute_error: 88.5669 - val_loss: 10926.8926 - val_mean_absolute_error: 102.8908\n",
      "Epoch 252/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7799.5039 - mean_absolute_error: 86.0843\n",
      "Epoch 252: loss did not improve from 8108.96777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8200.3936 - mean_absolute_error: 88.3787 - val_loss: 10880.2793 - val_mean_absolute_error: 102.6671\n",
      "Epoch 253/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7563.8213 - mean_absolute_error: 85.1076\n",
      "Epoch 253: loss did not improve from 8108.96777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7996.4771 - mean_absolute_error: 87.2280 - val_loss: 10833.8252 - val_mean_absolute_error: 102.4436\n",
      "Epoch 254/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8400.6807 - mean_absolute_error: 89.4436\n",
      "Epoch 254: loss did not improve from 8108.96777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8157.0786 - mean_absolute_error: 88.0868 - val_loss: 10787.2617 - val_mean_absolute_error: 102.2192\n",
      "Epoch 255/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7268.7930 - mean_absolute_error: 83.1683\n",
      "Epoch 255: loss did not improve from 8108.96777\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7985.6172 - mean_absolute_error: 87.1845 - val_loss: 10740.8545 - val_mean_absolute_error: 101.9950\n",
      "Epoch 256/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7982.5464 - mean_absolute_error: 87.1871\n",
      "Epoch 256: loss improved from 8108.96777 to 8080.79688, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8120.3066 - mean_absolute_error: 88.0628 - val_loss: 10694.5469 - val_mean_absolute_error: 101.7708\n",
      "Epoch 257/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8017.6836 - mean_absolute_error: 87.5115\n",
      "Epoch 257: loss improved from 8080.79688 to 7900.32764, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8184.1934 - mean_absolute_error: 88.6356 - val_loss: 10648.4941 - val_mean_absolute_error: 101.5474\n",
      "Epoch 258/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8395.9590 - mean_absolute_error: 89.7209\n",
      "Epoch 258: loss did not improve from 7900.32764\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8084.9878 - mean_absolute_error: 87.8319 - val_loss: 10602.9980 - val_mean_absolute_error: 101.3262\n",
      "Epoch 259/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8349.5166 - mean_absolute_error: 88.8730\n",
      "Epoch 259: loss did not improve from 7900.32764\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8087.6519 - mean_absolute_error: 87.4729 - val_loss: 10557.4883 - val_mean_absolute_error: 101.1044\n",
      "Epoch 260/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8296.5371 - mean_absolute_error: 88.5330\n",
      "Epoch 260: loss improved from 7900.32764 to 7849.40967, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8048.3711 - mean_absolute_error: 87.6924 - val_loss: 10511.7451 - val_mean_absolute_error: 100.8810\n",
      "Epoch 261/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6275.2803 - mean_absolute_error: 76.7673\n",
      "Epoch 261: loss improved from 7849.40967 to 7683.11377, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7584.2329 - mean_absolute_error: 85.2141 - val_loss: 10466.6104 - val_mean_absolute_error: 100.6601\n",
      "Epoch 262/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7246.4727 - mean_absolute_error: 83.0840\n",
      "Epoch 262: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7708.3140 - mean_absolute_error: 85.6596 - val_loss: 10421.8594 - val_mean_absolute_error: 100.4407\n",
      "Epoch 263/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8113.2681 - mean_absolute_error: 88.0332\n",
      "Epoch 263: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7881.4077 - mean_absolute_error: 86.5012 - val_loss: 10376.9180 - val_mean_absolute_error: 100.2198\n",
      "Epoch 264/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7756.7617 - mean_absolute_error: 86.0960\n",
      "Epoch 264: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7833.4878 - mean_absolute_error: 86.3324 - val_loss: 10331.9199 - val_mean_absolute_error: 99.9981\n",
      "Epoch 265/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 7143.9189 - mean_absolute_error: 81.9900\n",
      "Epoch 265: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7710.2754 - mean_absolute_error: 85.6881 - val_loss: 10287.0205 - val_mean_absolute_error: 99.7765\n",
      "Epoch 266/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7791.5391 - mean_absolute_error: 85.5244\n",
      "Epoch 266: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7781.6167 - mean_absolute_error: 85.9942 - val_loss: 10242.4141 - val_mean_absolute_error: 99.5558\n",
      "Epoch 267/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6771.8882 - mean_absolute_error: 80.7223\n",
      "Epoch 267: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7543.6484 - mean_absolute_error: 84.5710 - val_loss: 10198.0391 - val_mean_absolute_error: 99.3358\n",
      "Epoch 268/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8347.6699 - mean_absolute_error: 89.6929\n",
      "Epoch 268: loss did not improve from 7683.11377\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8020.4414 - mean_absolute_error: 87.1481 - val_loss: 10153.2559 - val_mean_absolute_error: 99.1133\n",
      "Epoch 269/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7572.3281 - mean_absolute_error: 84.4784\n",
      "Epoch 269: loss improved from 7683.11377 to 7485.90576, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7697.0166 - mean_absolute_error: 85.5950 - val_loss: 10108.6152 - val_mean_absolute_error: 98.8910\n",
      "Epoch 270/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7270.0791 - mean_absolute_error: 83.0091\n",
      "Epoch 270: loss did not improve from 7485.90576\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7599.4604 - mean_absolute_error: 84.8890 - val_loss: 10064.5762 - val_mean_absolute_error: 98.6712\n",
      "Epoch 271/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7164.9429 - mean_absolute_error: 82.4018\n",
      "Epoch 271: loss did not improve from 7485.90576\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7366.6323 - mean_absolute_error: 83.6711 - val_loss: 10020.7676 - val_mean_absolute_error: 98.4520\n",
      "Epoch 272/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7806.2100 - mean_absolute_error: 86.1417\n",
      "Epoch 272: loss improved from 7485.90576 to 7376.05859, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7653.6221 - mean_absolute_error: 85.4913 - val_loss: 9976.9082 - val_mean_absolute_error: 98.2321\n",
      "Epoch 273/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7491.0210 - mean_absolute_error: 84.3695\n",
      "Epoch 273: loss did not improve from 7376.05859\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7462.8149 - mean_absolute_error: 84.1428 - val_loss: 9933.5352 - val_mean_absolute_error: 98.0142\n",
      "Epoch 274/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7103.2915 - mean_absolute_error: 82.2116\n",
      "Epoch 274: loss improved from 7376.05859 to 7193.38770, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7410.7949 - mean_absolute_error: 84.3662 - val_loss: 9890.1055 - val_mean_absolute_error: 97.7956\n",
      "Epoch 275/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7621.2505 - mean_absolute_error: 85.0168\n",
      "Epoch 275: loss did not improve from 7193.38770\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7360.2861 - mean_absolute_error: 83.5915 - val_loss: 9847.3145 - val_mean_absolute_error: 97.5796\n",
      "Epoch 276/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7646.2178 - mean_absolute_error: 84.6802\n",
      "Epoch 276: loss improved from 7193.38770 to 7125.80127, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7443.4443 - mean_absolute_error: 84.2616 - val_loss: 9804.3936 - val_mean_absolute_error: 97.3626\n",
      "Epoch 277/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7201.6865 - mean_absolute_error: 82.4440\n",
      "Epoch 277: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7481.8325 - mean_absolute_error: 84.2854 - val_loss: 9761.7324 - val_mean_absolute_error: 97.1464\n",
      "Epoch 278/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6602.9429 - mean_absolute_error: 79.1227\n",
      "Epoch 278: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7311.4644 - mean_absolute_error: 83.3838 - val_loss: 9719.0215 - val_mean_absolute_error: 96.9294\n",
      "Epoch 279/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7010.8691 - mean_absolute_error: 81.6277\n",
      "Epoch 279: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7285.8984 - mean_absolute_error: 83.2042 - val_loss: 9676.3936 - val_mean_absolute_error: 96.7124\n",
      "Epoch 280/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6002.0879 - mean_absolute_error: 75.1792\n",
      "Epoch 280: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7036.6572 - mean_absolute_error: 81.4077 - val_loss: 9633.9258 - val_mean_absolute_error: 96.4957\n",
      "Epoch 281/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6787.3701 - mean_absolute_error: 80.4925\n",
      "Epoch 281: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7086.0601 - mean_absolute_error: 81.7582 - val_loss: 9591.3730 - val_mean_absolute_error: 96.2782\n",
      "Epoch 282/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6723.1655 - mean_absolute_error: 79.1081\n",
      "Epoch 282: loss did not improve from 7125.80127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6999.6255 - mean_absolute_error: 81.0284 - val_loss: 9548.7344 - val_mean_absolute_error: 96.0597\n",
      "Epoch 283/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5587.9912 - mean_absolute_error: 72.3921\n",
      "Epoch 283: loss improved from 7125.80127 to 7079.51221, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6823.1187 - mean_absolute_error: 80.3281 - val_loss: 9506.2148 - val_mean_absolute_error: 95.8413\n",
      "Epoch 284/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5842.6455 - mean_absolute_error: 74.2116\n",
      "Epoch 284: loss improved from 7079.51221 to 6963.32324, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6720.6909 - mean_absolute_error: 79.8312 - val_loss: 9464.1719 - val_mean_absolute_error: 95.6248\n",
      "Epoch 285/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8285.6299 - mean_absolute_error: 89.6440\n",
      "Epoch 285: loss did not improve from 6963.32324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7303.7812 - mean_absolute_error: 83.2480 - val_loss: 9422.1836 - val_mean_absolute_error: 95.4082\n",
      "Epoch 286/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7829.4590 - mean_absolute_error: 87.3990\n",
      "Epoch 286: loss did not improve from 6963.32324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7204.6548 - mean_absolute_error: 82.4938 - val_loss: 9380.2812 - val_mean_absolute_error: 95.1916\n",
      "Epoch 287/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7057.6113 - mean_absolute_error: 81.5150\n",
      "Epoch 287: loss did not improve from 6963.32324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6972.2637 - mean_absolute_error: 80.7675 - val_loss: 9338.3027 - val_mean_absolute_error: 94.9740\n",
      "Epoch 288/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6762.7104 - mean_absolute_error: 79.6987\n",
      "Epoch 288: loss did not improve from 6963.32324\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6763.4766 - mean_absolute_error: 79.8094 - val_loss: 9296.3906 - val_mean_absolute_error: 94.7563\n",
      "Epoch 289/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7219.5054 - mean_absolute_error: 82.5723\n",
      "Epoch 289: loss improved from 6963.32324 to 6851.91846, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6996.2241 - mean_absolute_error: 81.4589 - val_loss: 9254.6084 - val_mean_absolute_error: 94.5388\n",
      "Epoch 290/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6290.6338 - mean_absolute_error: 76.9769\n",
      "Epoch 290: loss improved from 6851.91846 to 6844.89795, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6688.6709 - mean_absolute_error: 79.4671 - val_loss: 9213.3857 - val_mean_absolute_error: 94.3237\n",
      "Epoch 291/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6841.5293 - mean_absolute_error: 80.2282\n",
      "Epoch 291: loss did not improve from 6844.89795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6957.4771 - mean_absolute_error: 80.9352 - val_loss: 9172.2285 - val_mean_absolute_error: 94.1085\n",
      "Epoch 292/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8435.0000 - mean_absolute_error: 90.0183\n",
      "Epoch 292: loss improved from 6844.89795 to 6640.40186, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7101.6812 - mean_absolute_error: 82.1316 - val_loss: 9131.1846 - val_mean_absolute_error: 93.8934\n",
      "Epoch 293/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6214.5205 - mean_absolute_error: 75.9251\n",
      "Epoch 293: loss improved from 6640.40186 to 6579.76172, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6728.2329 - mean_absolute_error: 79.8969 - val_loss: 9090.6309 - val_mean_absolute_error: 93.6803\n",
      "Epoch 294/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6692.1035 - mean_absolute_error: 79.6075\n",
      "Epoch 294: loss did not improve from 6579.76172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6855.7798 - mean_absolute_error: 80.3962 - val_loss: 9050.3145 - val_mean_absolute_error: 93.4681\n",
      "Epoch 295/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6324.1787 - mean_absolute_error: 76.8637\n",
      "Epoch 295: loss did not improve from 6579.76172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6723.1948 - mean_absolute_error: 79.5655 - val_loss: 9009.8945 - val_mean_absolute_error: 93.2548\n",
      "Epoch 296/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7200.3257 - mean_absolute_error: 82.8474\n",
      "Epoch 296: loss did not improve from 6579.76172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6776.8618 - mean_absolute_error: 80.0511 - val_loss: 8969.5029 - val_mean_absolute_error: 93.0412\n",
      "Epoch 297/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5859.6816 - mean_absolute_error: 73.3554\n",
      "Epoch 297: loss did not improve from 6579.76172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6497.1816 - mean_absolute_error: 77.9334 - val_loss: 8929.3438 - val_mean_absolute_error: 92.8283\n",
      "Epoch 298/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6338.0400 - mean_absolute_error: 77.6189\n",
      "Epoch 298: loss did not improve from 6579.76172\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6601.1240 - mean_absolute_error: 78.8715 - val_loss: 8889.1211 - val_mean_absolute_error: 92.6147\n",
      "Epoch 299/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6832.2432 - mean_absolute_error: 79.8969\n",
      "Epoch 299: loss improved from 6579.76172 to 6572.98438, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6607.0107 - mean_absolute_error: 78.8001 - val_loss: 8849.0508 - val_mean_absolute_error: 92.4013\n",
      "Epoch 300/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6581.8843 - mean_absolute_error: 78.6767\n",
      "Epoch 300: loss improved from 6572.98438 to 6434.30225, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6411.2261 - mean_absolute_error: 77.8272 - val_loss: 8809.2939 - val_mean_absolute_error: 92.1892\n",
      "Epoch 301/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7449.4307 - mean_absolute_error: 84.5286\n",
      "Epoch 301: loss did not improve from 6434.30225\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6779.4731 - mean_absolute_error: 80.1885 - val_loss: 8769.5078 - val_mean_absolute_error: 91.9763\n",
      "Epoch 302/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5838.2891 - mean_absolute_error: 73.9016\n",
      "Epoch 302: loss did not improve from 6434.30225\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6325.9727 - mean_absolute_error: 77.1315 - val_loss: 8730.1553 - val_mean_absolute_error: 91.7654\n",
      "Epoch 303/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5986.1113 - mean_absolute_error: 75.2147\n",
      "Epoch 303: loss did not improve from 6434.30225\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6358.6470 - mean_absolute_error: 77.1896 - val_loss: 8690.7441 - val_mean_absolute_error: 91.5536\n",
      "Epoch 304/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6792.7646 - mean_absolute_error: 79.6772\n",
      "Epoch 304: loss improved from 6434.30225 to 6247.06250, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6545.3179 - mean_absolute_error: 78.6729 - val_loss: 8651.0879 - val_mean_absolute_error: 91.3401\n",
      "Epoch 305/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7690.1953 - mean_absolute_error: 85.4729\n",
      "Epoch 305: loss did not improve from 6247.06250\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6776.3320 - mean_absolute_error: 80.2791 - val_loss: 8611.8203 - val_mean_absolute_error: 91.1281\n",
      "Epoch 306/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7028.2373 - mean_absolute_error: 81.6158\n",
      "Epoch 306: loss did not improve from 6247.06250\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6475.5928 - mean_absolute_error: 77.7690 - val_loss: 8573.0820 - val_mean_absolute_error: 90.9185\n",
      "Epoch 307/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5591.3413 - mean_absolute_error: 72.6015\n",
      "Epoch 307: loss did not improve from 6247.06250\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6136.6357 - mean_absolute_error: 76.0018 - val_loss: 8534.0742 - val_mean_absolute_error: 90.7070\n",
      "Epoch 308/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6996.1162 - mean_absolute_error: 80.5311\n",
      "Epoch 308: loss improved from 6247.06250 to 6225.00684, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6560.7153 - mean_absolute_error: 78.5212 - val_loss: 8495.0322 - val_mean_absolute_error: 90.4948\n",
      "Epoch 309/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6390.9248 - mean_absolute_error: 77.5226\n",
      "Epoch 309: loss did not improve from 6225.00684\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6315.6523 - mean_absolute_error: 76.9781 - val_loss: 8456.4473 - val_mean_absolute_error: 90.2847\n",
      "Epoch 310/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6350.8828 - mean_absolute_error: 76.8550\n",
      "Epoch 310: loss improved from 6225.00684 to 6131.98438, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6111.3726 - mean_absolute_error: 75.7990 - val_loss: 8418.0186 - val_mean_absolute_error: 90.0748\n",
      "Epoch 311/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5360.8193 - mean_absolute_error: 70.9428\n",
      "Epoch 311: loss did not improve from 6131.98438\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5981.0781 - mean_absolute_error: 74.8759 - val_loss: 8379.7725 - val_mean_absolute_error: 89.8655\n",
      "Epoch 312/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5939.8408 - mean_absolute_error: 74.9530\n",
      "Epoch 312: loss improved from 6131.98438 to 6109.89893, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6046.8745 - mean_absolute_error: 75.4337 - val_loss: 8341.4316 - val_mean_absolute_error: 89.6552\n",
      "Epoch 313/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5988.2607 - mean_absolute_error: 74.6531\n",
      "Epoch 313: loss did not improve from 6109.89893\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5974.2783 - mean_absolute_error: 74.5716 - val_loss: 8303.3486 - val_mean_absolute_error: 89.4459\n",
      "Epoch 314/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6265.5176 - mean_absolute_error: 76.6712\n",
      "Epoch 314: loss did not improve from 6109.89893\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6054.6992 - mean_absolute_error: 75.1010 - val_loss: 8265.1289 - val_mean_absolute_error: 89.2353\n",
      "Epoch 315/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6907.8301 - mean_absolute_error: 80.9679\n",
      "Epoch 315: loss did not improve from 6109.89893\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6218.4971 - mean_absolute_error: 76.2951 - val_loss: 8226.8447 - val_mean_absolute_error: 89.0238\n",
      "Epoch 316/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5395.7598 - mean_absolute_error: 71.4497\n",
      "Epoch 316: loss improved from 6109.89893 to 5932.51416, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5909.9888 - mean_absolute_error: 74.6458 - val_loss: 8188.8887 - val_mean_absolute_error: 88.8137\n",
      "Epoch 317/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 6835.9775 - mean_absolute_error: 79.8166\n",
      "Epoch 317: loss improved from 5932.51416 to 5873.50635, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6161.8726 - mean_absolute_error: 76.1641 - val_loss: 8151.1870 - val_mean_absolute_error: 88.6045\n",
      "Epoch 318/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 6407.8403 - mean_absolute_error: 77.4374\n",
      "Epoch 318: loss did not improve from 5873.50635\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6102.7686 - mean_absolute_error: 75.4898 - val_loss: 8113.8174 - val_mean_absolute_error: 88.3967\n",
      "Epoch 319/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6039.4932 - mean_absolute_error: 75.0760\n",
      "Epoch 319: loss did not improve from 5873.50635\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6020.6768 - mean_absolute_error: 75.0865 - val_loss: 8076.3545 - val_mean_absolute_error: 88.1878\n",
      "Epoch 320/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6091.8159 - mean_absolute_error: 75.6917\n",
      "Epoch 320: loss improved from 5873.50635 to 5684.89404, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5825.6445 - mean_absolute_error: 74.1543 - val_loss: 8039.1436 - val_mean_absolute_error: 87.9799\n",
      "Epoch 321/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5544.3809 - mean_absolute_error: 72.0526\n",
      "Epoch 321: loss did not improve from 5684.89404\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5898.3647 - mean_absolute_error: 74.4669 - val_loss: 8002.2402 - val_mean_absolute_error: 87.7732\n",
      "Epoch 322/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6162.1069 - mean_absolute_error: 76.0043\n",
      "Epoch 322: loss did not improve from 5684.89404\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5922.0352 - mean_absolute_error: 74.3752 - val_loss: 7965.5010 - val_mean_absolute_error: 87.5670\n",
      "Epoch 323/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5099.8682 - mean_absolute_error: 68.8773\n",
      "Epoch 323: loss did not improve from 5684.89404\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5618.6304 - mean_absolute_error: 72.5569 - val_loss: 7928.8301 - val_mean_absolute_error: 87.3606\n",
      "Epoch 324/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6019.8135 - mean_absolute_error: 75.2599\n",
      "Epoch 324: loss did not improve from 5684.89404\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5942.3916 - mean_absolute_error: 74.7358 - val_loss: 7892.1177 - val_mean_absolute_error: 87.1536\n",
      "Epoch 325/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5779.9893 - mean_absolute_error: 73.7718\n",
      "Epoch 325: loss did not improve from 5684.89404\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5725.3481 - mean_absolute_error: 73.1091 - val_loss: 7855.7241 - val_mean_absolute_error: 86.9478\n",
      "Epoch 326/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5675.1543 - mean_absolute_error: 72.9719\n",
      "Epoch 326: loss improved from 5684.89404 to 5661.29932, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5819.4082 - mean_absolute_error: 73.8336 - val_loss: 7819.1870 - val_mean_absolute_error: 86.7408\n",
      "Epoch 327/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5276.0566 - mean_absolute_error: 69.3786\n",
      "Epoch 327: loss improved from 5661.29932 to 5620.89453, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5550.4316 - mean_absolute_error: 71.7904 - val_loss: 7783.0640 - val_mean_absolute_error: 86.5357\n",
      "Epoch 328/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5723.2939 - mean_absolute_error: 72.4893\n",
      "Epoch 328: loss improved from 5620.89453 to 5537.10254, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5583.0972 - mean_absolute_error: 72.1584 - val_loss: 7747.0176 - val_mean_absolute_error: 86.3305\n",
      "Epoch 329/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5777.4878 - mean_absolute_error: 74.0341\n",
      "Epoch 329: loss improved from 5537.10254 to 5511.59814, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5700.0723 - mean_absolute_error: 73.2550 - val_loss: 7711.0757 - val_mean_absolute_error: 86.1254\n",
      "Epoch 330/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5232.2622 - mean_absolute_error: 69.4873\n",
      "Epoch 330: loss did not improve from 5511.59814\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5494.9136 - mean_absolute_error: 71.1343 - val_loss: 7675.4839 - val_mean_absolute_error: 85.9218\n",
      "Epoch 331/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5235.7998 - mean_absolute_error: 69.4431\n",
      "Epoch 331: loss did not improve from 5511.59814\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5502.2368 - mean_absolute_error: 71.5785 - val_loss: 7639.5527 - val_mean_absolute_error: 85.7158\n",
      "Epoch 332/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5937.5332 - mean_absolute_error: 74.7429\n",
      "Epoch 332: loss did not improve from 5511.59814\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5497.4380 - mean_absolute_error: 71.6261 - val_loss: 7603.8940 - val_mean_absolute_error: 85.5109\n",
      "Epoch 333/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6267.2700 - mean_absolute_error: 76.3331\n",
      "Epoch 333: loss did not improve from 5511.59814\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5660.4106 - mean_absolute_error: 72.4055 - val_loss: 7568.1763 - val_mean_absolute_error: 85.3052\n",
      "Epoch 334/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5472.5352 - mean_absolute_error: 70.9188\n",
      "Epoch 334: loss improved from 5511.59814 to 5489.26904, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5422.7041 - mean_absolute_error: 70.9250 - val_loss: 7532.5869 - val_mean_absolute_error: 85.0997\n",
      "Epoch 335/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5731.5483 - mean_absolute_error: 73.6060\n",
      "Epoch 335: loss did not improve from 5489.26904\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5564.2275 - mean_absolute_error: 71.9265 - val_loss: 7497.0249 - val_mean_absolute_error: 84.8939\n",
      "Epoch 336/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5723.7319 - mean_absolute_error: 73.7113\n",
      "Epoch 336: loss improved from 5489.26904 to 5375.36963, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5526.0679 - mean_absolute_error: 71.9326 - val_loss: 7461.5933 - val_mean_absolute_error: 84.6883\n",
      "Epoch 337/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5977.3867 - mean_absolute_error: 75.3947\n",
      "Epoch 337: loss improved from 5375.36963 to 5333.67676, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5513.8628 - mean_absolute_error: 71.8233 - val_loss: 7426.4678 - val_mean_absolute_error: 84.4841\n",
      "Epoch 338/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5021.0000 - mean_absolute_error: 67.0065\n",
      "Epoch 338: loss did not improve from 5333.67676\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5263.7051 - mean_absolute_error: 69.6068 - val_loss: 7391.6787 - val_mean_absolute_error: 84.2813\n",
      "Epoch 339/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5697.9902 - mean_absolute_error: 72.8887\n",
      "Epoch 339: loss improved from 5333.67676 to 5300.15576, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5387.5820 - mean_absolute_error: 70.6930 - val_loss: 7356.8525 - val_mean_absolute_error: 84.0778\n",
      "Epoch 340/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5238.6309 - mean_absolute_error: 69.3939\n",
      "Epoch 340: loss did not improve from 5300.15576\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5202.7295 - mean_absolute_error: 69.1974 - val_loss: 7322.2666 - val_mean_absolute_error: 83.8753\n",
      "Epoch 341/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5504.5513 - mean_absolute_error: 71.6128\n",
      "Epoch 341: loss improved from 5300.15576 to 5282.71436, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5257.2051 - mean_absolute_error: 69.7984 - val_loss: 7287.4678 - val_mean_absolute_error: 83.6710\n",
      "Epoch 342/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4950.0566 - mean_absolute_error: 68.0271\n",
      "Epoch 342: loss did not improve from 5282.71436\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5252.2822 - mean_absolute_error: 69.7345 - val_loss: 7252.7832 - val_mean_absolute_error: 83.4669\n",
      "Epoch 343/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4771.5430 - mean_absolute_error: 66.8249\n",
      "Epoch 343: loss improved from 5282.71436 to 5250.46240, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5145.3394 - mean_absolute_error: 69.0178 - val_loss: 7218.2627 - val_mean_absolute_error: 83.2633\n",
      "Epoch 344/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5162.4668 - mean_absolute_error: 68.9247\n",
      "Epoch 344: loss did not improve from 5250.46240\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5224.8174 - mean_absolute_error: 69.3118 - val_loss: 7183.8174 - val_mean_absolute_error: 83.0596\n",
      "Epoch 345/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5552.6270 - mean_absolute_error: 72.0804\n",
      "Epoch 345: loss improved from 5250.46240 to 5122.81104, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5209.3516 - mean_absolute_error: 69.5897 - val_loss: 7149.4497 - val_mean_absolute_error: 82.8559\n",
      "Epoch 346/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5454.8052 - mean_absolute_error: 71.7331\n",
      "Epoch 346: loss improved from 5122.81104 to 4960.40527, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5253.4365 - mean_absolute_error: 70.2553 - val_loss: 7115.2959 - val_mean_absolute_error: 82.6530\n",
      "Epoch 347/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5472.4775 - mean_absolute_error: 71.8211\n",
      "Epoch 347: loss did not improve from 4960.40527\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5215.3154 - mean_absolute_error: 69.7199 - val_loss: 7081.6826 - val_mean_absolute_error: 82.4528\n",
      "Epoch 348/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5813.3447 - mean_absolute_error: 73.9212\n",
      "Epoch 348: loss did not improve from 4960.40527\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5196.9038 - mean_absolute_error: 69.4869 - val_loss: 7048.0757 - val_mean_absolute_error: 82.2521\n",
      "Epoch 349/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5043.0381 - mean_absolute_error: 68.2174\n",
      "Epoch 349: loss did not improve from 4960.40527\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5053.4653 - mean_absolute_error: 68.3295 - val_loss: 7014.5908 - val_mean_absolute_error: 82.0517\n",
      "Epoch 350/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4704.2031 - mean_absolute_error: 64.9463\n",
      "Epoch 350: loss did not improve from 4960.40527\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4891.9722 - mean_absolute_error: 67.1219 - val_loss: 6981.2842 - val_mean_absolute_error: 81.8519\n",
      "Epoch 351/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5522.9453 - mean_absolute_error: 71.7984\n",
      "Epoch 351: loss did not improve from 4960.40527\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5120.2764 - mean_absolute_error: 68.7882 - val_loss: 6947.9287 - val_mean_absolute_error: 81.6514\n",
      "Epoch 352/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5246.2495 - mean_absolute_error: 69.4277\n",
      "Epoch 352: loss improved from 4960.40527 to 4897.65527, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5048.5986 - mean_absolute_error: 68.4385 - val_loss: 6914.5420 - val_mean_absolute_error: 81.4501\n",
      "Epoch 353/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4543.3032 - mean_absolute_error: 64.3485\n",
      "Epoch 353: loss improved from 4897.65527 to 4880.96436, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4821.3906 - mean_absolute_error: 66.6969 - val_loss: 6881.5430 - val_mean_absolute_error: 81.2507\n",
      "Epoch 354/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5145.9248 - mean_absolute_error: 69.7666\n",
      "Epoch 354: loss improved from 4880.96436 to 4785.43408, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4957.5830 - mean_absolute_error: 68.0688 - val_loss: 6848.5986 - val_mean_absolute_error: 81.0512\n",
      "Epoch 355/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4213.9385 - mean_absolute_error: 62.6876\n",
      "Epoch 355: loss did not improve from 4785.43408\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4806.1758 - mean_absolute_error: 66.9077 - val_loss: 6815.9971 - val_mean_absolute_error: 80.8532\n",
      "Epoch 356/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5067.6230 - mean_absolute_error: 68.3542\n",
      "Epoch 356: loss did not improve from 4785.43408\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4847.2480 - mean_absolute_error: 66.8419 - val_loss: 6783.6084 - val_mean_absolute_error: 80.6561\n",
      "Epoch 357/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5487.7363 - mean_absolute_error: 72.0151\n",
      "Epoch 357: loss did not improve from 4785.43408\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4911.3828 - mean_absolute_error: 67.3181 - val_loss: 6751.0918 - val_mean_absolute_error: 80.4577\n",
      "Epoch 358/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5068.8481 - mean_absolute_error: 68.3957\n",
      "Epoch 358: loss improved from 4785.43408 to 4774.63623, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4904.2866 - mean_absolute_error: 67.2895 - val_loss: 6718.5166 - val_mean_absolute_error: 80.2585\n",
      "Epoch 359/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4490.7734 - mean_absolute_error: 63.9046\n",
      "Epoch 359: loss improved from 4774.63623 to 4677.15186, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4800.3164 - mean_absolute_error: 66.6598 - val_loss: 6686.0762 - val_mean_absolute_error: 80.0596\n",
      "Epoch 360/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4741.6562 - mean_absolute_error: 65.1447\n",
      "Epoch 360: loss improved from 4677.15186 to 4653.18750, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4710.1191 - mean_absolute_error: 65.6945 - val_loss: 6654.0488 - val_mean_absolute_error: 79.8628\n",
      "Epoch 361/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4346.1953 - mean_absolute_error: 63.1354\n",
      "Epoch 361: loss did not improve from 4653.18750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4549.8164 - mean_absolute_error: 64.6399 - val_loss: 6622.1719 - val_mean_absolute_error: 79.6664\n",
      "Epoch 362/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4308.1221 - mean_absolute_error: 63.3282\n",
      "Epoch 362: loss did not improve from 4653.18750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4617.3389 - mean_absolute_error: 65.2005 - val_loss: 6590.1309 - val_mean_absolute_error: 79.4686\n",
      "Epoch 363/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4105.4111 - mean_absolute_error: 60.9908\n",
      "Epoch 363: loss did not improve from 4653.18750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4600.1475 - mean_absolute_error: 64.9118 - val_loss: 6558.2129 - val_mean_absolute_error: 79.2710\n",
      "Epoch 364/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4970.2803 - mean_absolute_error: 67.2853\n",
      "Epoch 364: loss did not improve from 4653.18750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4708.4248 - mean_absolute_error: 65.4985 - val_loss: 6526.4058 - val_mean_absolute_error: 79.0736\n",
      "Epoch 365/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4667.7383 - mean_absolute_error: 65.4337\n",
      "Epoch 365: loss did not improve from 4653.18750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4608.2041 - mean_absolute_error: 64.7448 - val_loss: 6494.5869 - val_mean_absolute_error: 78.8756\n",
      "Epoch 366/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4518.9062 - mean_absolute_error: 64.6336\n",
      "Epoch 366: loss improved from 4653.18750 to 4549.07617, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4603.3789 - mean_absolute_error: 65.1820 - val_loss: 6462.6816 - val_mean_absolute_error: 78.6767\n",
      "Epoch 367/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5261.3818 - mean_absolute_error: 69.6667\n",
      "Epoch 367: loss did not improve from 4549.07617\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4816.8203 - mean_absolute_error: 66.3964 - val_loss: 6431.0391 - val_mean_absolute_error: 78.4788\n",
      "Epoch 368/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4123.3359 - mean_absolute_error: 61.3616\n",
      "Epoch 368: loss did not improve from 4549.07617\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4407.6694 - mean_absolute_error: 63.1866 - val_loss: 6399.5806 - val_mean_absolute_error: 78.2817\n",
      "Epoch 369/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4755.8506 - mean_absolute_error: 66.6572\n",
      "Epoch 369: loss improved from 4549.07617 to 4355.11621, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4463.9722 - mean_absolute_error: 64.2977 - val_loss: 6368.0278 - val_mean_absolute_error: 78.0834\n",
      "Epoch 370/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4775.8540 - mean_absolute_error: 66.3127\n",
      "Epoch 370: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4550.4238 - mean_absolute_error: 64.4142 - val_loss: 6336.9092 - val_mean_absolute_error: 77.8874\n",
      "Epoch 371/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4450.4966 - mean_absolute_error: 63.4744\n",
      "Epoch 371: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4472.9893 - mean_absolute_error: 63.8027 - val_loss: 6305.7710 - val_mean_absolute_error: 77.6908\n",
      "Epoch 372/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4336.3359 - mean_absolute_error: 62.3199\n",
      "Epoch 372: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4406.2363 - mean_absolute_error: 63.2109 - val_loss: 6274.8594 - val_mean_absolute_error: 77.4951\n",
      "Epoch 373/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 3952.7991 - mean_absolute_error: 60.0864\n",
      "Epoch 373: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4307.8672 - mean_absolute_error: 62.7468 - val_loss: 6244.0352 - val_mean_absolute_error: 77.2996\n",
      "Epoch 374/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4974.0688 - mean_absolute_error: 67.7790\n",
      "Epoch 374: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4551.5566 - mean_absolute_error: 64.5371 - val_loss: 6213.2588 - val_mean_absolute_error: 77.1038\n",
      "Epoch 375/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 4324.7383 - mean_absolute_error: 62.9133\n",
      "Epoch 375: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4380.4463 - mean_absolute_error: 63.2005 - val_loss: 6182.6602 - val_mean_absolute_error: 76.9086\n",
      "Epoch 376/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4850.1978 - mean_absolute_error: 67.3704\n",
      "Epoch 376: loss did not improve from 4355.11621\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4402.4199 - mean_absolute_error: 63.5394 - val_loss: 6152.1123 - val_mean_absolute_error: 76.7133\n",
      "Epoch 377/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4265.0586 - mean_absolute_error: 62.0448\n",
      "Epoch 377: loss improved from 4355.11621 to 4345.50537, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4248.0620 - mean_absolute_error: 62.0488 - val_loss: 6121.7236 - val_mean_absolute_error: 76.5186\n",
      "Epoch 378/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4331.2607 - mean_absolute_error: 63.4261\n",
      "Epoch 378: loss improved from 4345.50537 to 4278.19775, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4214.1689 - mean_absolute_error: 62.2288 - val_loss: 6091.4082 - val_mean_absolute_error: 76.3238\n",
      "Epoch 379/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3661.2080 - mean_absolute_error: 57.4042\n",
      "Epoch 379: loss did not improve from 4278.19775\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4208.1602 - mean_absolute_error: 61.7931 - val_loss: 6061.2217 - val_mean_absolute_error: 76.1294\n",
      "Epoch 380/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4264.8320 - mean_absolute_error: 61.9123\n",
      "Epoch 380: loss improved from 4278.19775 to 4181.44434, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4276.6240 - mean_absolute_error: 62.5260 - val_loss: 6031.1050 - val_mean_absolute_error: 75.9349\n",
      "Epoch 381/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3899.7119 - mean_absolute_error: 58.7703\n",
      "Epoch 381: loss did not improve from 4181.44434\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4040.3545 - mean_absolute_error: 60.3431 - val_loss: 6001.4854 - val_mean_absolute_error: 75.7431\n",
      "Epoch 382/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4178.8252 - mean_absolute_error: 61.4179\n",
      "Epoch 382: loss did not improve from 4181.44434\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4197.2217 - mean_absolute_error: 61.7192 - val_loss: 5971.5840 - val_mean_absolute_error: 75.5491\n",
      "Epoch 383/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4546.1934 - mean_absolute_error: 64.9686\n",
      "Epoch 383: loss did not improve from 4181.44434\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4224.6182 - mean_absolute_error: 61.9928 - val_loss: 5941.7432 - val_mean_absolute_error: 75.3549\n",
      "Epoch 384/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4428.0249 - mean_absolute_error: 63.5590\n",
      "Epoch 384: loss did not improve from 4181.44434\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4210.7363 - mean_absolute_error: 61.5912 - val_loss: 5911.9043 - val_mean_absolute_error: 75.1603\n",
      "Epoch 385/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4026.6099 - mean_absolute_error: 60.1621\n",
      "Epoch 385: loss improved from 4181.44434 to 4107.91455, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4119.1782 - mean_absolute_error: 61.2181 - val_loss: 5882.0835 - val_mean_absolute_error: 74.9653\n",
      "Epoch 386/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3892.2202 - mean_absolute_error: 58.6384\n",
      "Epoch 386: loss did not improve from 4107.91455\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4061.4761 - mean_absolute_error: 60.2817 - val_loss: 5852.6035 - val_mean_absolute_error: 74.7720\n",
      "Epoch 387/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4460.1636 - mean_absolute_error: 64.1327\n",
      "Epoch 387: loss did not improve from 4107.91455\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4238.0342 - mean_absolute_error: 62.0314 - val_loss: 5822.9365 - val_mean_absolute_error: 74.5770\n",
      "Epoch 388/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3788.6479 - mean_absolute_error: 58.2517\n",
      "Epoch 388: loss improved from 4107.91455 to 3912.28271, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3913.7598 - mean_absolute_error: 59.6070 - val_loss: 5793.7222 - val_mean_absolute_error: 74.3845\n",
      "Epoch 389/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3550.8613 - mean_absolute_error: 56.9346\n",
      "Epoch 389: loss did not improve from 3912.28271\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3897.5317 - mean_absolute_error: 59.1220 - val_loss: 5764.8730 - val_mean_absolute_error: 74.1940\n",
      "Epoch 390/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3892.5735 - mean_absolute_error: 59.6628\n",
      "Epoch 390: loss did not improve from 3912.28271\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4031.9478 - mean_absolute_error: 60.5040 - val_loss: 5735.6973 - val_mean_absolute_error: 74.0007\n",
      "Epoch 391/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4495.4692 - mean_absolute_error: 64.2472\n",
      "Epoch 391: loss did not improve from 3912.28271\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4129.3994 - mean_absolute_error: 61.2436 - val_loss: 5706.7910 - val_mean_absolute_error: 73.8088\n",
      "Epoch 392/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3643.8691 - mean_absolute_error: 57.3732\n",
      "Epoch 392: loss improved from 3912.28271 to 3865.47729, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3896.1323 - mean_absolute_error: 59.4490 - val_loss: 5678.1128 - val_mean_absolute_error: 73.6179\n",
      "Epoch 393/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3704.7944 - mean_absolute_error: 58.0152\n",
      "Epoch 393: loss improved from 3865.47729 to 3750.00635, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3795.4124 - mean_absolute_error: 58.9183 - val_loss: 5649.8057 - val_mean_absolute_error: 73.4290\n",
      "Epoch 394/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3867.4797 - mean_absolute_error: 60.1592\n",
      "Epoch 394: loss did not improve from 3750.00635\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3870.7207 - mean_absolute_error: 59.2740 - val_loss: 5621.7759 - val_mean_absolute_error: 73.2415\n",
      "Epoch 395/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4099.3643 - mean_absolute_error: 60.3932\n",
      "Epoch 395: loss did not improve from 3750.00635\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3975.0684 - mean_absolute_error: 60.2295 - val_loss: 5593.3735 - val_mean_absolute_error: 73.0509\n",
      "Epoch 396/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3919.6621 - mean_absolute_error: 59.4763\n",
      "Epoch 396: loss did not improve from 3750.00635\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3916.2607 - mean_absolute_error: 59.4468 - val_loss: 5565.4277 - val_mean_absolute_error: 72.8630\n",
      "Epoch 397/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3717.5684 - mean_absolute_error: 57.5871\n",
      "Epoch 397: loss improved from 3750.00635 to 3716.96362, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3804.0938 - mean_absolute_error: 58.6636 - val_loss: 5537.4287 - val_mean_absolute_error: 72.6743\n",
      "Epoch 398/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3899.5459 - mean_absolute_error: 59.6166\n",
      "Epoch 398: loss did not improve from 3716.96362\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3839.3215 - mean_absolute_error: 58.8379 - val_loss: 5509.6543 - val_mean_absolute_error: 72.4865\n",
      "Epoch 399/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3652.0396 - mean_absolute_error: 56.8408\n",
      "Epoch 399: loss did not improve from 3716.96362\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3813.5652 - mean_absolute_error: 58.4577 - val_loss: 5481.8628 - val_mean_absolute_error: 72.2982\n",
      "Epoch 400/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4223.8745 - mean_absolute_error: 62.0884\n",
      "Epoch 400: loss did not improve from 3716.96362\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3891.2515 - mean_absolute_error: 59.4532 - val_loss: 5454.0098 - val_mean_absolute_error: 72.1090\n",
      "Epoch 401/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3558.4211 - mean_absolute_error: 55.7898\n",
      "Epoch 401: loss did not improve from 3716.96362\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3781.8372 - mean_absolute_error: 58.0993 - val_loss: 5426.4424 - val_mean_absolute_error: 71.9213\n",
      "Epoch 402/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4161.3120 - mean_absolute_error: 61.8361\n",
      "Epoch 402: loss did not improve from 3716.96362\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3855.0190 - mean_absolute_error: 58.7098 - val_loss: 5398.7705 - val_mean_absolute_error: 71.7323\n",
      "Epoch 403/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3489.4490 - mean_absolute_error: 55.9039\n",
      "Epoch 403: loss improved from 3716.96362 to 3648.43188, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3693.0857 - mean_absolute_error: 57.7743 - val_loss: 5370.9546 - val_mean_absolute_error: 71.5419\n",
      "Epoch 404/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3801.8142 - mean_absolute_error: 58.7213\n",
      "Epoch 404: loss did not improve from 3648.43188\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3718.2937 - mean_absolute_error: 57.9366 - val_loss: 5343.5527 - val_mean_absolute_error: 71.3538\n",
      "Epoch 405/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3583.6052 - mean_absolute_error: 57.7657\n",
      "Epoch 405: loss improved from 3648.43188 to 3557.35010, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3605.7383 - mean_absolute_error: 57.3312 - val_loss: 5316.3779 - val_mean_absolute_error: 71.1668\n",
      "Epoch 406/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3457.7493 - mean_absolute_error: 55.0598\n",
      "Epoch 406: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3677.6060 - mean_absolute_error: 57.2067 - val_loss: 5289.4092 - val_mean_absolute_error: 70.9807\n",
      "Epoch 407/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3448.6353 - mean_absolute_error: 55.0784\n",
      "Epoch 407: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3532.3008 - mean_absolute_error: 56.2224 - val_loss: 5262.4502 - val_mean_absolute_error: 70.7943\n",
      "Epoch 408/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4219.6416 - mean_absolute_error: 62.2722\n",
      "Epoch 408: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3695.6677 - mean_absolute_error: 57.5769 - val_loss: 5235.4561 - val_mean_absolute_error: 70.6071\n",
      "Epoch 409/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2885.0151 - mean_absolute_error: 50.5895\n",
      "Epoch 409: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3420.7485 - mean_absolute_error: 55.2137 - val_loss: 5208.5835 - val_mean_absolute_error: 70.4202\n",
      "Epoch 410/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3367.0874 - mean_absolute_error: 54.4497\n",
      "Epoch 410: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3535.3145 - mean_absolute_error: 56.0622 - val_loss: 5181.7148 - val_mean_absolute_error: 70.2329\n",
      "Epoch 411/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3874.5356 - mean_absolute_error: 58.4830\n",
      "Epoch 411: loss did not improve from 3557.35010\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3657.9905 - mean_absolute_error: 56.9765 - val_loss: 5154.8613 - val_mean_absolute_error: 70.0452\n",
      "Epoch 412/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3647.8054 - mean_absolute_error: 57.0359\n",
      "Epoch 412: loss improved from 3557.35010 to 3462.71484, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3548.3037 - mean_absolute_error: 56.3801 - val_loss: 5128.1670 - val_mean_absolute_error: 69.8582\n",
      "Epoch 413/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3291.9202 - mean_absolute_error: 54.3086\n",
      "Epoch 413: loss did not improve from 3462.71484\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3362.2678 - mean_absolute_error: 54.6431 - val_loss: 5101.8545 - val_mean_absolute_error: 69.6733\n",
      "Epoch 414/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3490.1958 - mean_absolute_error: 55.4152\n",
      "Epoch 414: loss did not improve from 3462.71484\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3460.0720 - mean_absolute_error: 55.0364 - val_loss: 5075.5254 - val_mean_absolute_error: 69.4878\n",
      "Epoch 415/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3808.5654 - mean_absolute_error: 58.6763\n",
      "Epoch 415: loss improved from 3462.71484 to 3418.37134, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3577.0959 - mean_absolute_error: 56.6644 - val_loss: 5048.8584 - val_mean_absolute_error: 69.2995\n",
      "Epoch 416/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3318.4849 - mean_absolute_error: 53.6121\n",
      "Epoch 416: loss did not improve from 3418.37134\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3448.8894 - mean_absolute_error: 55.3544 - val_loss: 5022.6758 - val_mean_absolute_error: 69.1141\n",
      "Epoch 417/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3741.2004 - mean_absolute_error: 58.2569\n",
      "Epoch 417: loss improved from 3418.37134 to 3323.76025, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3461.2908 - mean_absolute_error: 55.6744 - val_loss: 4996.6377 - val_mean_absolute_error: 68.9292\n",
      "Epoch 418/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2958.8623 - mean_absolute_error: 50.4556\n",
      "Epoch 418: loss did not improve from 3323.76025\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3316.9722 - mean_absolute_error: 53.9033 - val_loss: 4970.9551 - val_mean_absolute_error: 68.7464\n",
      "Epoch 419/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2712.1177 - mean_absolute_error: 48.9805\n",
      "Epoch 419: loss did not improve from 3323.76025\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3309.7898 - mean_absolute_error: 54.0874 - val_loss: 4944.9604 - val_mean_absolute_error: 68.5608\n",
      "Epoch 420/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3362.4883 - mean_absolute_error: 54.7050\n",
      "Epoch 420: loss did not improve from 3323.76025\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3340.4102 - mean_absolute_error: 54.5828 - val_loss: 4919.0449 - val_mean_absolute_error: 68.3754\n",
      "Epoch 421/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2885.4072 - mean_absolute_error: 51.6726\n",
      "Epoch 421: loss improved from 3323.76025 to 3295.15015, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3289.8960 - mean_absolute_error: 54.4134 - val_loss: 4893.3569 - val_mean_absolute_error: 68.1910\n",
      "Epoch 422/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3599.2009 - mean_absolute_error: 57.3604\n",
      "Epoch 422: loss did not improve from 3295.15015\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3383.5276 - mean_absolute_error: 54.9416 - val_loss: 4867.8203 - val_mean_absolute_error: 68.0073\n",
      "Epoch 423/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3236.1514 - mean_absolute_error: 54.0242\n",
      "Epoch 423: loss improved from 3295.15015 to 3247.15503, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3270.5635 - mean_absolute_error: 54.1133 - val_loss: 4842.4883 - val_mean_absolute_error: 67.8246\n",
      "Epoch 424/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3421.3599 - mean_absolute_error: 55.3706\n",
      "Epoch 424: loss did not improve from 3247.15503\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3260.1997 - mean_absolute_error: 53.5346 - val_loss: 4817.3574 - val_mean_absolute_error: 67.6428\n",
      "Epoch 425/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3655.3279 - mean_absolute_error: 57.5247\n",
      "Epoch 425: loss improved from 3247.15503 to 3188.21436, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3379.4917 - mean_absolute_error: 54.8958 - val_loss: 4792.0059 - val_mean_absolute_error: 67.4590\n",
      "Epoch 426/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2797.8774 - mean_absolute_error: 49.6106\n",
      "Epoch 426: loss did not improve from 3188.21436\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3167.5493 - mean_absolute_error: 52.9237 - val_loss: 4767.1147 - val_mean_absolute_error: 67.2780\n",
      "Epoch 427/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3258.6890 - mean_absolute_error: 54.2477\n",
      "Epoch 427: loss improved from 3188.21436 to 3094.68994, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3226.7803 - mean_absolute_error: 53.7623 - val_loss: 4742.2891 - val_mean_absolute_error: 67.0970\n",
      "Epoch 428/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3185.3247 - mean_absolute_error: 53.1463\n",
      "Epoch 428: loss did not improve from 3094.68994\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3234.4802 - mean_absolute_error: 53.6587 - val_loss: 4717.5850 - val_mean_absolute_error: 66.9164\n",
      "Epoch 429/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3167.4863 - mean_absolute_error: 53.0968\n",
      "Epoch 429: loss did not improve from 3094.68994\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3196.0723 - mean_absolute_error: 53.1142 - val_loss: 4692.8730 - val_mean_absolute_error: 66.7353\n",
      "Epoch 430/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3454.5303 - mean_absolute_error: 55.1664\n",
      "Epoch 430: loss improved from 3094.68994 to 3093.73096, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3286.1003 - mean_absolute_error: 53.8736 - val_loss: 4668.1792 - val_mean_absolute_error: 66.5539\n",
      "Epoch 431/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3071.9524 - mean_absolute_error: 51.6308\n",
      "Epoch 431: loss did not improve from 3093.73096\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3225.3591 - mean_absolute_error: 53.1829 - val_loss: 4643.6602 - val_mean_absolute_error: 66.3732\n",
      "Epoch 432/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3246.4919 - mean_absolute_error: 53.3656\n",
      "Epoch 432: loss did not improve from 3093.73096\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3187.5994 - mean_absolute_error: 53.0719 - val_loss: 4619.0347 - val_mean_absolute_error: 66.1913\n",
      "Epoch 433/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2973.6626 - mean_absolute_error: 51.4445\n",
      "Epoch 433: loss did not improve from 3093.73096\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3100.7134 - mean_absolute_error: 51.9495 - val_loss: 4594.6270 - val_mean_absolute_error: 66.0105\n",
      "Epoch 434/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3450.1975 - mean_absolute_error: 53.0808\n",
      "Epoch 434: loss improved from 3093.73096 to 2955.78003, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3155.8003 - mean_absolute_error: 52.3708 - val_loss: 4569.9673 - val_mean_absolute_error: 65.8273\n",
      "Epoch 435/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 2740.8940 - mean_absolute_error: 48.6423\n",
      "Epoch 435: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2996.6416 - mean_absolute_error: 51.3723 - val_loss: 4545.9302 - val_mean_absolute_error: 65.6483\n",
      "Epoch 436/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3370.7366 - mean_absolute_error: 54.3985\n",
      "Epoch 436: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3115.0920 - mean_absolute_error: 52.3394 - val_loss: 4521.9648 - val_mean_absolute_error: 65.4693\n",
      "Epoch 437/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2955.6392 - mean_absolute_error: 51.4823\n",
      "Epoch 437: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3035.9968 - mean_absolute_error: 51.5825 - val_loss: 4498.0547 - val_mean_absolute_error: 65.2903\n",
      "Epoch 438/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2419.9795 - mean_absolute_error: 46.1720\n",
      "Epoch 438: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2964.3042 - mean_absolute_error: 50.8113 - val_loss: 4474.1768 - val_mean_absolute_error: 65.1111\n",
      "Epoch 439/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3002.9453 - mean_absolute_error: 51.9278\n",
      "Epoch 439: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2973.1016 - mean_absolute_error: 50.8695 - val_loss: 4450.2275 - val_mean_absolute_error: 64.9308\n",
      "Epoch 440/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3470.0779 - mean_absolute_error: 55.3444\n",
      "Epoch 440: loss did not improve from 2955.78003\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3138.3574 - mean_absolute_error: 52.2961 - val_loss: 4426.1108 - val_mean_absolute_error: 64.7487\n",
      "Epoch 441/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2334.0798 - mean_absolute_error: 44.9917\n",
      "Epoch 441: loss improved from 2955.78003 to 2864.37524, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2820.7056 - mean_absolute_error: 49.7183 - val_loss: 4402.2720 - val_mean_absolute_error: 64.5683\n",
      "Epoch 442/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3056.9058 - mean_absolute_error: 52.1307\n",
      "Epoch 442: loss did not improve from 2864.37524\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2988.0916 - mean_absolute_error: 51.2900 - val_loss: 4378.7393 - val_mean_absolute_error: 64.3897\n",
      "Epoch 443/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2853.5583 - mean_absolute_error: 49.6091\n",
      "Epoch 443: loss did not improve from 2864.37524\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2957.9458 - mean_absolute_error: 50.6821 - val_loss: 4355.3682 - val_mean_absolute_error: 64.2118\n",
      "Epoch 444/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2813.9080 - mean_absolute_error: 48.8934\n",
      "Epoch 444: loss did not improve from 2864.37524\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2838.2690 - mean_absolute_error: 49.2099 - val_loss: 4332.1099 - val_mean_absolute_error: 64.0343\n",
      "Epoch 445/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3195.8877 - mean_absolute_error: 53.4825\n",
      "Epoch 445: loss did not improve from 2864.37524\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2981.9753 - mean_absolute_error: 51.1075 - val_loss: 4308.6484 - val_mean_absolute_error: 63.8548\n",
      "Epoch 446/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2324.1440 - mean_absolute_error: 44.1808\n",
      "Epoch 446: loss improved from 2864.37524 to 2817.50073, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2669.9419 - mean_absolute_error: 47.9408 - val_loss: 4285.6147 - val_mean_absolute_error: 63.6781\n",
      "Epoch 447/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2723.7949 - mean_absolute_error: 47.7538\n",
      "Epoch 447: loss did not improve from 2817.50073\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2899.1956 - mean_absolute_error: 49.8837 - val_loss: 4262.4839 - val_mean_absolute_error: 63.5001\n",
      "Epoch 448/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3235.6807 - mean_absolute_error: 54.8225\n",
      "Epoch 448: loss improved from 2817.50073 to 2725.83374, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2965.4561 - mean_absolute_error: 51.5299 - val_loss: 4239.2607 - val_mean_absolute_error: 63.3209\n",
      "Epoch 449/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2823.4067 - mean_absolute_error: 48.9211\n",
      "Epoch 449: loss did not improve from 2725.83374\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2764.1785 - mean_absolute_error: 48.7967 - val_loss: 4216.7207 - val_mean_absolute_error: 63.1466\n",
      "Epoch 450/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2734.0342 - mean_absolute_error: 48.0537\n",
      "Epoch 450: loss did not improve from 2725.83374\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2851.2756 - mean_absolute_error: 49.8474 - val_loss: 4193.9502 - val_mean_absolute_error: 62.9699\n",
      "Epoch 451/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3418.5425 - mean_absolute_error: 54.6781\n",
      "Epoch 451: loss did not improve from 2725.83374\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2948.4143 - mean_absolute_error: 50.7489 - val_loss: 4171.2910 - val_mean_absolute_error: 62.7937\n",
      "Epoch 452/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3063.3125 - mean_absolute_error: 51.4222\n",
      "Epoch 452: loss improved from 2725.83374 to 2643.45093, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2765.7751 - mean_absolute_error: 49.1515 - val_loss: 4149.0015 - val_mean_absolute_error: 62.6198\n",
      "Epoch 453/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2977.5571 - mean_absolute_error: 50.8910\n",
      "Epoch 453: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2846.5859 - mean_absolute_error: 49.4801 - val_loss: 4126.8057 - val_mean_absolute_error: 62.4462\n",
      "Epoch 454/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2509.2607 - mean_absolute_error: 46.1521\n",
      "Epoch 454: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2721.3777 - mean_absolute_error: 48.0966 - val_loss: 4104.4258 - val_mean_absolute_error: 62.2707\n",
      "Epoch 455/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2660.0688 - mean_absolute_error: 48.4569\n",
      "Epoch 455: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2728.4329 - mean_absolute_error: 48.6993 - val_loss: 4081.9717 - val_mean_absolute_error: 62.0941\n",
      "Epoch 456/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2593.5464 - mean_absolute_error: 48.0001\n",
      "Epoch 456: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2703.8542 - mean_absolute_error: 47.9929 - val_loss: 4059.6567 - val_mean_absolute_error: 61.9182\n",
      "Epoch 457/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3099.1157 - mean_absolute_error: 52.3158\n",
      "Epoch 457: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2746.8257 - mean_absolute_error: 48.5086 - val_loss: 4037.0686 - val_mean_absolute_error: 61.7395\n",
      "Epoch 458/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3210.1250 - mean_absolute_error: 53.8330\n",
      "Epoch 458: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2816.1382 - mean_absolute_error: 49.4299 - val_loss: 4014.6675 - val_mean_absolute_error: 61.5619\n",
      "Epoch 459/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3335.1499 - mean_absolute_error: 54.6164\n",
      "Epoch 459: loss did not improve from 2643.45093\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2827.3181 - mean_absolute_error: 49.3583 - val_loss: 3992.4824 - val_mean_absolute_error: 61.3855\n",
      "Epoch 460/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2807.8438 - mean_absolute_error: 47.8337\n",
      "Epoch 460: loss improved from 2643.45093 to 2600.97021, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2565.1687 - mean_absolute_error: 46.4202 - val_loss: 3970.7246 - val_mean_absolute_error: 61.2119\n",
      "Epoch 461/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2747.4282 - mean_absolute_error: 48.2187\n",
      "Epoch 461: loss did not improve from 2600.97021\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2606.7812 - mean_absolute_error: 47.0913 - val_loss: 3948.9556 - val_mean_absolute_error: 61.0378\n",
      "Epoch 462/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2438.0632 - mean_absolute_error: 45.8606\n",
      "Epoch 462: loss did not improve from 2600.97021\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2504.7007 - mean_absolute_error: 46.0019 - val_loss: 3927.2632 - val_mean_absolute_error: 60.8639\n",
      "Epoch 463/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2769.8447 - mean_absolute_error: 49.1268\n",
      "Epoch 463: loss improved from 2600.97021 to 2576.79907, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2656.9597 - mean_absolute_error: 47.8151 - val_loss: 3905.4392 - val_mean_absolute_error: 60.6884\n",
      "Epoch 464/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2346.8613 - mean_absolute_error: 44.9265\n",
      "Epoch 464: loss did not improve from 2576.79907\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2531.4702 - mean_absolute_error: 46.2570 - val_loss: 3883.9395 - val_mean_absolute_error: 60.5150\n",
      "Epoch 465/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2563.8198 - mean_absolute_error: 46.4561\n",
      "Epoch 465: loss improved from 2576.79907 to 2479.33716, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2532.0569 - mean_absolute_error: 46.4136 - val_loss: 3862.4678 - val_mean_absolute_error: 60.3414\n",
      "Epoch 466/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2716.0713 - mean_absolute_error: 49.2371\n",
      "Epoch 466: loss improved from 2479.33716 to 2462.72681, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2586.2141 - mean_absolute_error: 47.4462 - val_loss: 3841.1274 - val_mean_absolute_error: 60.1683\n",
      "Epoch 467/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2966.3423 - mean_absolute_error: 51.0433\n",
      "Epoch 467: loss did not improve from 2462.72681\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2640.8894 - mean_absolute_error: 47.3363 - val_loss: 3820.0847 - val_mean_absolute_error: 59.9972\n",
      "Epoch 468/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2598.0808 - mean_absolute_error: 47.4366\n",
      "Epoch 468: loss improved from 2462.72681 to 2453.39233, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2576.2388 - mean_absolute_error: 46.8204 - val_loss: 3798.9543 - val_mean_absolute_error: 59.8248\n",
      "Epoch 469/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2306.6748 - mean_absolute_error: 44.8212\n",
      "Epoch 469: loss did not improve from 2453.39233\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2481.1860 - mean_absolute_error: 45.9671 - val_loss: 3778.0579 - val_mean_absolute_error: 59.6539\n",
      "Epoch 470/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2483.2019 - mean_absolute_error: 46.1428\n",
      "Epoch 470: loss did not improve from 2453.39233\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2400.7368 - mean_absolute_error: 44.7998 - val_loss: 3757.2437 - val_mean_absolute_error: 59.4832\n",
      "Epoch 471/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2461.7747 - mean_absolute_error: 44.5529\n",
      "Epoch 471: loss did not improve from 2453.39233\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2461.3157 - mean_absolute_error: 45.2050 - val_loss: 3736.1812 - val_mean_absolute_error: 59.3100\n",
      "Epoch 472/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2390.7427 - mean_absolute_error: 44.1421\n",
      "Epoch 472: loss improved from 2453.39233 to 2431.43506, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2496.4194 - mean_absolute_error: 45.7929 - val_loss: 3715.1519 - val_mean_absolute_error: 59.1366\n",
      "Epoch 473/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2354.7207 - mean_absolute_error: 43.9924\n",
      "Epoch 473: loss improved from 2431.43506 to 2381.12769, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2384.7239 - mean_absolute_error: 44.9247 - val_loss: 3694.4766 - val_mean_absolute_error: 58.9655\n",
      "Epoch 474/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2626.8320 - mean_absolute_error: 47.6283\n",
      "Epoch 474: loss did not improve from 2381.12769\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2427.1697 - mean_absolute_error: 45.0122 - val_loss: 3674.0464 - val_mean_absolute_error: 58.7961\n",
      "Epoch 475/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2683.5193 - mean_absolute_error: 48.7467\n",
      "Epoch 475: loss improved from 2381.12769 to 2326.57178, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2452.7234 - mean_absolute_error: 45.8061 - val_loss: 3653.3428 - val_mean_absolute_error: 58.6239\n",
      "Epoch 476/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2574.7803 - mean_absolute_error: 47.9582\n",
      "Epoch 476: loss did not improve from 2326.57178\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2425.4355 - mean_absolute_error: 45.6389 - val_loss: 3633.0029 - val_mean_absolute_error: 58.4542\n",
      "Epoch 477/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2424.0154 - mean_absolute_error: 44.9971\n",
      "Epoch 477: loss did not improve from 2326.57178\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2441.1553 - mean_absolute_error: 45.4355 - val_loss: 3612.7305 - val_mean_absolute_error: 58.2846\n",
      "Epoch 478/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2481.8062 - mean_absolute_error: 44.5722\n",
      "Epoch 478: loss did not improve from 2326.57178\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2383.0120 - mean_absolute_error: 44.5738 - val_loss: 3592.6494 - val_mean_absolute_error: 58.1161\n",
      "Epoch 479/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2369.9131 - mean_absolute_error: 45.4113\n",
      "Epoch 479: loss did not improve from 2326.57178\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2361.9258 - mean_absolute_error: 44.5250 - val_loss: 3572.5190 - val_mean_absolute_error: 57.9468\n",
      "Epoch 480/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2618.0396 - mean_absolute_error: 46.8608\n",
      "Epoch 480: loss improved from 2326.57178 to 2263.11426, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2436.7036 - mean_absolute_error: 45.4765 - val_loss: 3552.2603 - val_mean_absolute_error: 57.7758\n",
      "Epoch 481/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1936.3442 - mean_absolute_error: 38.9053\n",
      "Epoch 481: loss did not improve from 2263.11426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2218.9788 - mean_absolute_error: 42.9752 - val_loss: 3532.4624 - val_mean_absolute_error: 57.6083\n",
      "Epoch 482/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2102.8848 - mean_absolute_error: 41.8099\n",
      "Epoch 482: loss did not improve from 2263.11426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2246.0271 - mean_absolute_error: 43.0196 - val_loss: 3512.7224 - val_mean_absolute_error: 57.4408\n",
      "Epoch 483/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2608.6187 - mean_absolute_error: 46.7778\n",
      "Epoch 483: loss did not improve from 2263.11426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2348.8594 - mean_absolute_error: 43.8473 - val_loss: 3492.8711 - val_mean_absolute_error: 57.2719\n",
      "Epoch 484/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2154.9814 - mean_absolute_error: 42.5039\n",
      "Epoch 484: loss did not improve from 2263.11426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2181.3818 - mean_absolute_error: 42.3907 - val_loss: 3472.9990 - val_mean_absolute_error: 57.1023\n",
      "Epoch 485/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1874.6150 - mean_absolute_error: 38.0779\n",
      "Epoch 485: loss did not improve from 2263.11426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2143.7334 - mean_absolute_error: 41.8246 - val_loss: 3453.2979 - val_mean_absolute_error: 56.9336\n",
      "Epoch 486/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2484.4512 - mean_absolute_error: 46.1341\n",
      "Epoch 486: loss improved from 2263.11426 to 2183.85107, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2316.4829 - mean_absolute_error: 44.1433 - val_loss: 3433.4570 - val_mean_absolute_error: 56.7633\n",
      "Epoch 487/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2271.5913 - mean_absolute_error: 43.0315\n",
      "Epoch 487: loss did not improve from 2183.85107\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2297.1819 - mean_absolute_error: 43.8573 - val_loss: 3413.9648 - val_mean_absolute_error: 56.5955\n",
      "Epoch 488/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1774.6937 - mean_absolute_error: 37.8692\n",
      "Epoch 488: loss improved from 2183.85107 to 2165.46069, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2099.9614 - mean_absolute_error: 41.6952 - val_loss: 3394.8313 - val_mean_absolute_error: 56.4303\n",
      "Epoch 489/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2398.2068 - mean_absolute_error: 44.3402\n",
      "Epoch 489: loss improved from 2165.46069 to 2061.34692, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2208.4583 - mean_absolute_error: 43.0572 - val_loss: 3375.7065 - val_mean_absolute_error: 56.2647\n",
      "Epoch 490/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2185.2456 - mean_absolute_error: 42.6080\n",
      "Epoch 490: loss did not improve from 2061.34692\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2171.8525 - mean_absolute_error: 42.3745 - val_loss: 3356.9194 - val_mean_absolute_error: 56.1016\n",
      "Epoch 491/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2433.8662 - mean_absolute_error: 45.4435\n",
      "Epoch 491: loss did not improve from 2061.34692\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2252.8987 - mean_absolute_error: 43.2030 - val_loss: 3337.8091 - val_mean_absolute_error: 55.9352\n",
      "Epoch 492/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2102.3167 - mean_absolute_error: 41.9927\n",
      "Epoch 492: loss did not improve from 2061.34692\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2169.7544 - mean_absolute_error: 42.4220 - val_loss: 3318.7729 - val_mean_absolute_error: 55.7689\n",
      "Epoch 493/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2218.0125 - mean_absolute_error: 43.5525\n",
      "Epoch 493: loss did not improve from 2061.34692\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2133.7275 - mean_absolute_error: 41.7429 - val_loss: 3299.6812 - val_mean_absolute_error: 55.6017\n",
      "Epoch 494/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1912.0514 - mean_absolute_error: 38.4457\n",
      "Epoch 494: loss did not improve from 2061.34692\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2059.4312 - mean_absolute_error: 40.6215 - val_loss: 3280.5859 - val_mean_absolute_error: 55.4339\n",
      "Epoch 495/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2026.7964 - mean_absolute_error: 41.0390\n",
      "Epoch 495: loss improved from 2061.34692 to 2018.60339, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2124.9973 - mean_absolute_error: 42.0485 - val_loss: 3261.4946 - val_mean_absolute_error: 55.2657\n",
      "Epoch 496/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2286.4236 - mean_absolute_error: 42.2393\n",
      "Epoch 496: loss did not improve from 2018.60339\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2124.6577 - mean_absolute_error: 41.4015 - val_loss: 3242.9336 - val_mean_absolute_error: 55.1017\n",
      "Epoch 497/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2533.1670 - mean_absolute_error: 46.3292\n",
      "Epoch 497: loss did not improve from 2018.60339\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2155.7715 - mean_absolute_error: 42.1146 - val_loss: 3224.2761 - val_mean_absolute_error: 54.9364\n",
      "Epoch 498/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2230.0095 - mean_absolute_error: 43.6225\n",
      "Epoch 498: loss improved from 2018.60339 to 1999.38879, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2046.8842 - mean_absolute_error: 41.1482 - val_loss: 3205.7529 - val_mean_absolute_error: 54.7717\n",
      "Epoch 499/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 2106.7637 - mean_absolute_error: 41.3529\n",
      "Epoch 499: loss did not improve from 1999.38879\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2061.0522 - mean_absolute_error: 41.1964 - val_loss: 3187.3853 - val_mean_absolute_error: 54.6080\n",
      "Epoch 500/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2584.4478 - mean_absolute_error: 47.6253\n",
      "Epoch 500: loss improved from 1999.38879 to 1999.06677, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2136.6721 - mean_absolute_error: 42.1831 - val_loss: 3169.1865 - val_mean_absolute_error: 54.4453\n",
      "Epoch 501/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1953.5270 - mean_absolute_error: 40.7888\n",
      "Epoch 501: loss improved from 1999.06677 to 1986.59338, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2054.2742 - mean_absolute_error: 41.3717 - val_loss: 3151.1711 - val_mean_absolute_error: 54.2837\n",
      "Epoch 502/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2122.5544 - mean_absolute_error: 42.1130\n",
      "Epoch 502: loss improved from 1986.59338 to 1963.93152, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2034.9832 - mean_absolute_error: 40.8880 - val_loss: 3133.2766 - val_mean_absolute_error: 54.1228\n",
      "Epoch 503/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1910.6812 - mean_absolute_error: 40.2561\n",
      "Epoch 503: loss did not improve from 1963.93152\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2010.0547 - mean_absolute_error: 40.6265 - val_loss: 3115.4780 - val_mean_absolute_error: 53.9623\n",
      "Epoch 504/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2302.0325 - mean_absolute_error: 43.2588\n",
      "Epoch 504: loss did not improve from 1963.93152\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2076.0005 - mean_absolute_error: 40.9235 - val_loss: 3097.6719 - val_mean_absolute_error: 53.8012\n",
      "Epoch 505/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1934.5005 - mean_absolute_error: 40.0421\n",
      "Epoch 505: loss improved from 1963.93152 to 1954.24158, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1963.4709 - mean_absolute_error: 40.0839 - val_loss: 3079.9209 - val_mean_absolute_error: 53.6402\n",
      "Epoch 506/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1831.4788 - mean_absolute_error: 38.8745\n",
      "Epoch 506: loss improved from 1954.24158 to 1900.86938, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1955.1895 - mean_absolute_error: 40.1219 - val_loss: 3062.2649 - val_mean_absolute_error: 53.4796\n",
      "Epoch 507/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2241.4551 - mean_absolute_error: 43.0015\n",
      "Epoch 507: loss did not improve from 1900.86938\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2033.8470 - mean_absolute_error: 40.2562 - val_loss: 3044.8018 - val_mean_absolute_error: 53.3202\n",
      "Epoch 508/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1926.7861 - mean_absolute_error: 39.4545\n",
      "Epoch 508: loss did not improve from 1900.86938\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1921.8452 - mean_absolute_error: 39.2850 - val_loss: 3027.1997 - val_mean_absolute_error: 53.1592\n",
      "Epoch 509/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1944.9526 - mean_absolute_error: 38.7780\n",
      "Epoch 509: loss improved from 1900.86938 to 1887.00330, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1959.7800 - mean_absolute_error: 39.4636 - val_loss: 3009.6130 - val_mean_absolute_error: 52.9977\n",
      "Epoch 510/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2145.8535 - mean_absolute_error: 41.2695\n",
      "Epoch 510: loss did not improve from 1887.00330\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1933.8146 - mean_absolute_error: 39.3533 - val_loss: 2992.1943 - val_mean_absolute_error: 52.8374\n",
      "Epoch 511/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1744.9858 - mean_absolute_error: 36.6780\n",
      "Epoch 511: loss improved from 1887.00330 to 1858.97632, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1904.3633 - mean_absolute_error: 39.0788 - val_loss: 2974.7908 - val_mean_absolute_error: 52.6767\n",
      "Epoch 512/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1913.9766 - mean_absolute_error: 37.0817\n",
      "Epoch 512: loss did not improve from 1858.97632\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1859.0000 - mean_absolute_error: 37.7770 - val_loss: 2957.6902 - val_mean_absolute_error: 52.5184\n",
      "Epoch 513/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1809.0927 - mean_absolute_error: 39.0974\n",
      "Epoch 513: loss improved from 1858.97632 to 1833.29041, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1838.8369 - mean_absolute_error: 38.5297 - val_loss: 2940.4285 - val_mean_absolute_error: 52.3581\n",
      "Epoch 514/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1976.4961 - mean_absolute_error: 39.1609\n",
      "Epoch 514: loss did not improve from 1833.29041\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1833.0114 - mean_absolute_error: 37.7083 - val_loss: 2923.4185 - val_mean_absolute_error: 52.1996\n",
      "Epoch 515/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1736.8936 - mean_absolute_error: 36.9791\n",
      "Epoch 515: loss did not improve from 1833.29041\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1850.8120 - mean_absolute_error: 38.2132 - val_loss: 2906.0176 - val_mean_absolute_error: 52.0370\n",
      "Epoch 516/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1873.5480 - mean_absolute_error: 38.9975\n",
      "Epoch 516: loss did not improve from 1833.29041\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1908.5549 - mean_absolute_error: 39.2279 - val_loss: 2888.6782 - val_mean_absolute_error: 51.8745\n",
      "Epoch 517/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1872.8466 - mean_absolute_error: 37.5138\n",
      "Epoch 517: loss improved from 1833.29041 to 1759.44360, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1844.3059 - mean_absolute_error: 38.0862 - val_loss: 2871.6411 - val_mean_absolute_error: 51.7144\n",
      "Epoch 518/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1510.7509 - mean_absolute_error: 34.7249\n",
      "Epoch 518: loss did not improve from 1759.44360\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1755.0841 - mean_absolute_error: 37.3310 - val_loss: 2854.9102 - val_mean_absolute_error: 51.5567\n",
      "Epoch 519/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1913.2341 - mean_absolute_error: 39.6090\n",
      "Epoch 519: loss did not improve from 1759.44360\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1792.7109 - mean_absolute_error: 37.7752 - val_loss: 2838.2070 - val_mean_absolute_error: 51.3987\n",
      "Epoch 520/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1847.1449 - mean_absolute_error: 39.0223\n",
      "Epoch 520: loss did not improve from 1759.44360\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1718.6855 - mean_absolute_error: 36.6245 - val_loss: 2821.7417 - val_mean_absolute_error: 51.2425\n",
      "Epoch 521/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1541.4774 - mean_absolute_error: 34.2252\n",
      "Epoch 521: loss did not improve from 1759.44360\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1786.4922 - mean_absolute_error: 37.5448 - val_loss: 2805.0698 - val_mean_absolute_error: 51.0840\n",
      "Epoch 522/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1498.4976 - mean_absolute_error: 34.1647\n",
      "Epoch 522: loss improved from 1759.44360 to 1750.19019, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1642.5302 - mean_absolute_error: 35.5975 - val_loss: 2788.7214 - val_mean_absolute_error: 50.9280\n",
      "Epoch 523/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1990.8525 - mean_absolute_error: 39.7155\n",
      "Epoch 523: loss improved from 1750.19019 to 1692.81641, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1763.4849 - mean_absolute_error: 37.2856 - val_loss: 2772.2610 - val_mean_absolute_error: 50.7704\n",
      "Epoch 524/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1666.3077 - mean_absolute_error: 36.7613\n",
      "Epoch 524: loss improved from 1692.81641 to 1648.69458, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1699.1011 - mean_absolute_error: 37.0339 - val_loss: 2756.0725 - val_mean_absolute_error: 50.6151\n",
      "Epoch 525/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2029.9093 - mean_absolute_error: 40.6342\n",
      "Epoch 525: loss did not improve from 1648.69458\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1756.9607 - mean_absolute_error: 36.9545 - val_loss: 2740.1763 - val_mean_absolute_error: 50.4620\n",
      "Epoch 526/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1542.0776 - mean_absolute_error: 34.3514\n",
      "Epoch 526: loss improved from 1648.69458 to 1625.64673, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1649.4061 - mean_absolute_error: 35.9205 - val_loss: 2724.2864 - val_mean_absolute_error: 50.3086\n",
      "Epoch 527/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1979.1805 - mean_absolute_error: 38.7430\n",
      "Epoch 527: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1738.8429 - mean_absolute_error: 36.3212 - val_loss: 2708.5347 - val_mean_absolute_error: 50.1561\n",
      "Epoch 528/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1919.2039 - mean_absolute_error: 39.1294\n",
      "Epoch 528: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1713.2559 - mean_absolute_error: 36.6450 - val_loss: 2692.4534 - val_mean_absolute_error: 49.9999\n",
      "Epoch 529/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1460.3123 - mean_absolute_error: 32.4567\n",
      "Epoch 529: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1624.9532 - mean_absolute_error: 34.9880 - val_loss: 2676.5000 - val_mean_absolute_error: 49.8444\n",
      "Epoch 530/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1687.0420 - mean_absolute_error: 35.4718\n",
      "Epoch 530: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1715.7788 - mean_absolute_error: 36.5242 - val_loss: 2660.1870 - val_mean_absolute_error: 49.6850\n",
      "Epoch 531/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1566.6475 - mean_absolute_error: 34.2862\n",
      "Epoch 531: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1709.8972 - mean_absolute_error: 36.4070 - val_loss: 2644.1050 - val_mean_absolute_error: 49.5274\n",
      "Epoch 532/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1760.4065 - mean_absolute_error: 38.2836\n",
      "Epoch 532: loss did not improve from 1625.64673\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1740.5629 - mean_absolute_error: 36.9862 - val_loss: 2628.1453 - val_mean_absolute_error: 49.3704\n",
      "Epoch 533/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1447.3639 - mean_absolute_error: 32.6800\n",
      "Epoch 533: loss improved from 1625.64673 to 1569.07874, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1580.8320 - mean_absolute_error: 35.1351 - val_loss: 2612.5083 - val_mean_absolute_error: 49.2162\n",
      "Epoch 534/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1624.0613 - mean_absolute_error: 35.3749\n",
      "Epoch 534: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1688.2716 - mean_absolute_error: 36.3639 - val_loss: 2596.9836 - val_mean_absolute_error: 49.0626\n",
      "Epoch 535/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1805.8690 - mean_absolute_error: 37.8019\n",
      "Epoch 535: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1679.0441 - mean_absolute_error: 36.2467 - val_loss: 2581.5662 - val_mean_absolute_error: 48.9096\n",
      "Epoch 536/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1553.6223 - mean_absolute_error: 34.6556\n",
      "Epoch 536: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1569.9412 - mean_absolute_error: 34.3929 - val_loss: 2566.2734 - val_mean_absolute_error: 48.7574\n",
      "Epoch 537/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1547.5723 - mean_absolute_error: 33.5329\n",
      "Epoch 537: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1606.5393 - mean_absolute_error: 35.2117 - val_loss: 2550.7583 - val_mean_absolute_error: 48.6025\n",
      "Epoch 538/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1865.9938 - mean_absolute_error: 37.5020\n",
      "Epoch 538: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1606.4054 - mean_absolute_error: 34.8735 - val_loss: 2535.4800 - val_mean_absolute_error: 48.4494\n",
      "Epoch 539/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1545.7999 - mean_absolute_error: 33.9385\n",
      "Epoch 539: loss did not improve from 1569.07874\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1562.2743 - mean_absolute_error: 34.5515 - val_loss: 2520.2786 - val_mean_absolute_error: 48.2967\n",
      "Epoch 540/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1471.2798 - mean_absolute_error: 33.0294\n",
      "Epoch 540: loss improved from 1569.07874 to 1535.68555, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1500.4132 - mean_absolute_error: 33.6398 - val_loss: 2505.2090 - val_mean_absolute_error: 48.1449\n",
      "Epoch 541/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1468.7761 - mean_absolute_error: 33.0935\n",
      "Epoch 541: loss did not improve from 1535.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1569.1284 - mean_absolute_error: 34.4167 - val_loss: 2490.1143 - val_mean_absolute_error: 47.9923\n",
      "Epoch 542/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1710.8168 - mean_absolute_error: 36.2561\n",
      "Epoch 542: loss did not improve from 1535.68555\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1635.3176 - mean_absolute_error: 35.4115 - val_loss: 2474.7900 - val_mean_absolute_error: 47.8369\n",
      "Epoch 543/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2004.8904 - mean_absolute_error: 39.9356\n",
      "Epoch 543: loss improved from 1535.68555 to 1500.83728, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1638.3994 - mean_absolute_error: 35.5049 - val_loss: 2459.6455 - val_mean_absolute_error: 47.6829\n",
      "Epoch 544/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1508.3119 - mean_absolute_error: 33.6154\n",
      "Epoch 544: loss improved from 1500.83728 to 1489.43835, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1523.9938 - mean_absolute_error: 34.2929 - val_loss: 2444.8010 - val_mean_absolute_error: 47.5314\n",
      "Epoch 545/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1329.6527 - mean_absolute_error: 32.3647\n",
      "Epoch 545: loss improved from 1489.43835 to 1437.52185, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1446.0428 - mean_absolute_error: 33.5313 - val_loss: 2430.2954 - val_mean_absolute_error: 47.3830\n",
      "Epoch 546/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1768.8499 - mean_absolute_error: 37.8061\n",
      "Epoch 546: loss did not improve from 1437.52185\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1583.5863 - mean_absolute_error: 34.8464 - val_loss: 2415.8354 - val_mean_absolute_error: 47.2345\n",
      "Epoch 547/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1669.6035 - mean_absolute_error: 37.0290\n",
      "Epoch 547: loss did not improve from 1437.52185\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1561.4553 - mean_absolute_error: 34.8367 - val_loss: 2401.2656 - val_mean_absolute_error: 47.0845\n",
      "Epoch 548/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1587.4438 - mean_absolute_error: 36.3989\n",
      "Epoch 548: loss did not improve from 1437.52185\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1545.1920 - mean_absolute_error: 34.9426 - val_loss: 2386.7070 - val_mean_absolute_error: 46.9341\n",
      "Epoch 549/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1300.1436 - mean_absolute_error: 31.5035\n",
      "Epoch 549: loss did not improve from 1437.52185\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1446.2307 - mean_absolute_error: 33.2353 - val_loss: 2372.4453 - val_mean_absolute_error: 46.7864\n",
      "Epoch 550/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1682.4281 - mean_absolute_error: 37.2758\n",
      "Epoch 550: loss improved from 1437.52185 to 1405.50452, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1545.0406 - mean_absolute_error: 34.7750 - val_loss: 2358.1289 - val_mean_absolute_error: 46.6376\n",
      "Epoch 551/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1613.8107 - mean_absolute_error: 34.7041\n",
      "Epoch 551: loss did not improve from 1405.50452\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1497.7673 - mean_absolute_error: 33.5538 - val_loss: 2344.0493 - val_mean_absolute_error: 46.4908\n",
      "Epoch 552/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1427.8340 - mean_absolute_error: 33.0723\n",
      "Epoch 552: loss did not improve from 1405.50452\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1389.1522 - mean_absolute_error: 31.9540 - val_loss: 2330.0552 - val_mean_absolute_error: 46.3445\n",
      "Epoch 553/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1815.0161 - mean_absolute_error: 38.9536\n",
      "Epoch 553: loss did not improve from 1405.50452\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1534.5430 - mean_absolute_error: 34.0026 - val_loss: 2315.7163 - val_mean_absolute_error: 46.1941\n",
      "Epoch 554/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1400.3140 - mean_absolute_error: 31.3702\n",
      "Epoch 554: loss improved from 1405.50452 to 1346.61060, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1397.7278 - mean_absolute_error: 32.3947 - val_loss: 2301.3621 - val_mean_absolute_error: 46.0430\n",
      "Epoch 555/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1251.4468 - mean_absolute_error: 28.5822\n",
      "Epoch 555: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1348.7112 - mean_absolute_error: 31.1887 - val_loss: 2287.4688 - val_mean_absolute_error: 45.8964\n",
      "Epoch 556/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1137.4878 - mean_absolute_error: 27.7798\n",
      "Epoch 556: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1289.9607 - mean_absolute_error: 30.6511 - val_loss: 2273.6545 - val_mean_absolute_error: 45.7501\n",
      "Epoch 557/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1694.7766 - mean_absolute_error: 36.8713\n",
      "Epoch 557: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1433.8499 - mean_absolute_error: 32.9768 - val_loss: 2259.7124 - val_mean_absolute_error: 45.6020\n",
      "Epoch 558/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1448.9441 - mean_absolute_error: 31.6655\n",
      "Epoch 558: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1399.0420 - mean_absolute_error: 32.2109 - val_loss: 2246.0483 - val_mean_absolute_error: 45.4564\n",
      "Epoch 559/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1503.8735 - mean_absolute_error: 35.3101\n",
      "Epoch 559: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1383.1831 - mean_absolute_error: 32.6250 - val_loss: 2232.3757 - val_mean_absolute_error: 45.3103\n",
      "Epoch 560/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1178.7412 - mean_absolute_error: 29.6021\n",
      "Epoch 560: loss did not improve from 1346.61060\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1309.2239 - mean_absolute_error: 31.1491 - val_loss: 2218.8977 - val_mean_absolute_error: 45.1658\n",
      "Epoch 561/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1640.6348 - mean_absolute_error: 35.5679\n",
      "Epoch 561: loss improved from 1346.61060 to 1291.13257, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1388.0264 - mean_absolute_error: 32.4932 - val_loss: 2205.2617 - val_mean_absolute_error: 45.0191\n",
      "Epoch 562/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1221.6683 - mean_absolute_error: 29.7794\n",
      "Epoch 562: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1299.6182 - mean_absolute_error: 31.1062 - val_loss: 2192.0007 - val_mean_absolute_error: 44.8761\n",
      "Epoch 563/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1384.6514 - mean_absolute_error: 33.2579\n",
      "Epoch 563: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1352.6479 - mean_absolute_error: 32.2651 - val_loss: 2178.7861 - val_mean_absolute_error: 44.7331\n",
      "Epoch 564/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1521.7910 - mean_absolute_error: 33.6097\n",
      "Epoch 564: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1363.5337 - mean_absolute_error: 31.5908 - val_loss: 2165.6294 - val_mean_absolute_error: 44.5902\n",
      "Epoch 565/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1355.7631 - mean_absolute_error: 32.6703\n",
      "Epoch 565: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1313.1553 - mean_absolute_error: 31.3251 - val_loss: 2152.2390 - val_mean_absolute_error: 44.4444\n",
      "Epoch 566/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1285.4675 - mean_absolute_error: 30.5719\n",
      "Epoch 566: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1310.5695 - mean_absolute_error: 31.0872 - val_loss: 2138.8008 - val_mean_absolute_error: 44.2976\n",
      "Epoch 567/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1196.5022 - mean_absolute_error: 29.9680\n",
      "Epoch 567: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1306.8521 - mean_absolute_error: 31.1383 - val_loss: 2125.5183 - val_mean_absolute_error: 44.1521\n",
      "Epoch 568/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1037.9745 - mean_absolute_error: 27.2112\n",
      "Epoch 568: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1272.0466 - mean_absolute_error: 30.3405 - val_loss: 2112.2476 - val_mean_absolute_error: 44.0062\n",
      "Epoch 569/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1353.9895 - mean_absolute_error: 30.9701\n",
      "Epoch 569: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1315.5660 - mean_absolute_error: 31.1024 - val_loss: 2098.7888 - val_mean_absolute_error: 43.8577\n",
      "Epoch 570/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1629.7784 - mean_absolute_error: 35.9122\n",
      "Epoch 570: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1383.4553 - mean_absolute_error: 32.2828 - val_loss: 2085.4702 - val_mean_absolute_error: 43.7103\n",
      "Epoch 571/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1247.3525 - mean_absolute_error: 29.9433\n",
      "Epoch 571: loss did not improve from 1291.13257\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1269.3621 - mean_absolute_error: 30.2876 - val_loss: 2072.4712 - val_mean_absolute_error: 43.5660\n",
      "Epoch 572/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1103.4111 - mean_absolute_error: 29.1076\n",
      "Epoch 572: loss improved from 1291.13257 to 1247.13110, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1209.0479 - mean_absolute_error: 30.0009 - val_loss: 2059.4277 - val_mean_absolute_error: 43.4207\n",
      "Epoch 573/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1244.1802 - mean_absolute_error: 30.5881\n",
      "Epoch 573: loss did not improve from 1247.13110\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1259.5753 - mean_absolute_error: 30.5022 - val_loss: 2046.5736 - val_mean_absolute_error: 43.2771\n",
      "Epoch 574/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1603.6112 - mean_absolute_error: 35.4951\n",
      "Epoch 574: loss improved from 1247.13110 to 1132.28064, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1322.1157 - mean_absolute_error: 31.8792 - val_loss: 2033.7537 - val_mean_absolute_error: 43.1334\n",
      "Epoch 575/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1135.1831 - mean_absolute_error: 28.9890\n",
      "Epoch 575: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1169.4468 - mean_absolute_error: 28.8836 - val_loss: 2021.7300 - val_mean_absolute_error: 42.9982\n",
      "Epoch 576/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 891.4533 - mean_absolute_error: 23.9337\n",
      "Epoch 576: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1188.1606 - mean_absolute_error: 28.9220 - val_loss: 2009.1890 - val_mean_absolute_error: 42.8567\n",
      "Epoch 577/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1427.5248 - mean_absolute_error: 32.1617\n",
      "Epoch 577: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1303.7858 - mean_absolute_error: 30.9729 - val_loss: 1996.3219 - val_mean_absolute_error: 42.7111\n",
      "Epoch 578/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 934.4745 - mean_absolute_error: 24.5457\n",
      "Epoch 578: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1097.6332 - mean_absolute_error: 28.1382 - val_loss: 1983.8995 - val_mean_absolute_error: 42.5701\n",
      "Epoch 579/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1186.9341 - mean_absolute_error: 29.6608\n",
      "Epoch 579: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1204.6448 - mean_absolute_error: 29.8626 - val_loss: 1971.6764 - val_mean_absolute_error: 42.4308\n",
      "Epoch 580/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1432.1201 - mean_absolute_error: 32.9352\n",
      "Epoch 580: loss did not improve from 1132.28064\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1221.1698 - mean_absolute_error: 30.0986 - val_loss: 1959.5184 - val_mean_absolute_error: 42.2919\n",
      "Epoch 581/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1510.8198 - mean_absolute_error: 34.9613\n",
      "Epoch 581: loss improved from 1132.28064 to 1105.29675, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1272.0986 - mean_absolute_error: 31.2692 - val_loss: 1947.3607 - val_mean_absolute_error: 42.1526\n",
      "Epoch 582/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1224.2781 - mean_absolute_error: 29.8153\n",
      "Epoch 582: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1146.1973 - mean_absolute_error: 28.8957 - val_loss: 1935.7717 - val_mean_absolute_error: 42.0193\n",
      "Epoch 583/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1578.0945 - mean_absolute_error: 35.1378\n",
      "Epoch 583: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1270.0460 - mean_absolute_error: 30.5985 - val_loss: 1923.8300 - val_mean_absolute_error: 41.8816\n",
      "Epoch 584/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 990.1025 - mean_absolute_error: 26.7825\n",
      "Epoch 584: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1102.8474 - mean_absolute_error: 28.3907 - val_loss: 1911.9629 - val_mean_absolute_error: 41.7443\n",
      "Epoch 585/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1333.5665 - mean_absolute_error: 31.5713\n",
      "Epoch 585: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1203.6927 - mean_absolute_error: 29.8594 - val_loss: 1900.1100 - val_mean_absolute_error: 41.6067\n",
      "Epoch 586/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 983.1127 - mean_absolute_error: 26.4522\n",
      "Epoch 586: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1142.5599 - mean_absolute_error: 29.0480 - val_loss: 1888.2400 - val_mean_absolute_error: 41.4684\n",
      "Epoch 587/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1203.2212 - mean_absolute_error: 30.1243\n",
      "Epoch 587: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1127.4901 - mean_absolute_error: 28.7329 - val_loss: 1876.6757 - val_mean_absolute_error: 41.3333\n",
      "Epoch 588/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1069.4386 - mean_absolute_error: 27.7795\n",
      "Epoch 588: loss did not improve from 1105.29675\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1117.7720 - mean_absolute_error: 28.5515 - val_loss: 1865.0229 - val_mean_absolute_error: 41.1968\n",
      "Epoch 589/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1006.7731 - mean_absolute_error: 27.0939\n",
      "Epoch 589: loss improved from 1105.29675 to 1052.07397, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1123.9839 - mean_absolute_error: 29.0745 - val_loss: 1853.3580 - val_mean_absolute_error: 41.0596\n",
      "Epoch 590/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1091.5571 - mean_absolute_error: 28.3693\n",
      "Epoch 590: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1082.1669 - mean_absolute_error: 27.7454 - val_loss: 1842.0824 - val_mean_absolute_error: 40.9266\n",
      "Epoch 591/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 863.2404 - mean_absolute_error: 24.1583\n",
      "Epoch 591: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1057.2517 - mean_absolute_error: 27.2016 - val_loss: 1830.4583 - val_mean_absolute_error: 40.7891\n",
      "Epoch 592/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1248.4260 - mean_absolute_error: 30.7347\n",
      "Epoch 592: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1142.3363 - mean_absolute_error: 29.0568 - val_loss: 1818.5692 - val_mean_absolute_error: 40.6479\n",
      "Epoch 593/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1130.3289 - mean_absolute_error: 28.3166\n",
      "Epoch 593: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1120.0836 - mean_absolute_error: 27.9432 - val_loss: 1807.0129 - val_mean_absolute_error: 40.5103\n",
      "Epoch 594/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 986.4242 - mean_absolute_error: 26.7954\n",
      "Epoch 594: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1069.2498 - mean_absolute_error: 27.5202 - val_loss: 1795.3301 - val_mean_absolute_error: 40.3707\n",
      "Epoch 595/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1144.2279 - mean_absolute_error: 29.9936\n",
      "Epoch 595: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1097.7529 - mean_absolute_error: 28.3469 - val_loss: 1783.5198 - val_mean_absolute_error: 40.2291\n",
      "Epoch 596/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1334.6270 - mean_absolute_error: 31.5242\n",
      "Epoch 596: loss did not improve from 1052.07397\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1097.5082 - mean_absolute_error: 28.0807 - val_loss: 1772.0154 - val_mean_absolute_error: 40.0906\n",
      "Epoch 597/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1026.2751 - mean_absolute_error: 27.9630\n",
      "Epoch 597: loss improved from 1052.07397 to 993.34540, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1078.8170 - mean_absolute_error: 28.5914 - val_loss: 1760.5985 - val_mean_absolute_error: 39.9528\n",
      "Epoch 598/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1239.6882 - mean_absolute_error: 30.8032\n",
      "Epoch 598: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1074.6466 - mean_absolute_error: 28.0021 - val_loss: 1749.7556 - val_mean_absolute_error: 39.8215\n",
      "Epoch 599/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1205.7119 - mean_absolute_error: 30.3918\n",
      "Epoch 599: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1035.7982 - mean_absolute_error: 27.0414 - val_loss: 1738.8856 - val_mean_absolute_error: 39.6894\n",
      "Epoch 600/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1185.0894 - mean_absolute_error: 29.1862\n",
      "Epoch 600: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1115.0448 - mean_absolute_error: 28.5254 - val_loss: 1727.6395 - val_mean_absolute_error: 39.5524\n",
      "Epoch 601/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 997.6518 - mean_absolute_error: 25.3074\n",
      "Epoch 601: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1054.4359 - mean_absolute_error: 27.2626 - val_loss: 1716.5417 - val_mean_absolute_error: 39.4166\n",
      "Epoch 602/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1226.7095 - mean_absolute_error: 30.2514\n",
      "Epoch 602: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1075.9238 - mean_absolute_error: 28.1825 - val_loss: 1705.4446 - val_mean_absolute_error: 39.2805\n",
      "Epoch 603/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1395.8574 - mean_absolute_error: 32.0722\n",
      "Epoch 603: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1086.8058 - mean_absolute_error: 27.7772 - val_loss: 1694.7079 - val_mean_absolute_error: 39.1483\n",
      "Epoch 604/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 786.8885 - mean_absolute_error: 22.6380\n",
      "Epoch 604: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 956.8268 - mean_absolute_error: 26.0642 - val_loss: 1683.9170 - val_mean_absolute_error: 39.0150\n",
      "Epoch 605/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 746.6506 - mean_absolute_error: 21.8411\n",
      "Epoch 605: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 965.5193 - mean_absolute_error: 26.1053 - val_loss: 1673.1973 - val_mean_absolute_error: 38.8821\n",
      "Epoch 606/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 942.4289 - mean_absolute_error: 25.8063\n",
      "Epoch 606: loss did not improve from 993.34540\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 970.3287 - mean_absolute_error: 26.3631 - val_loss: 1662.6417 - val_mean_absolute_error: 38.7509\n",
      "Epoch 607/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 654.8460 - mean_absolute_error: 21.1863\n",
      "Epoch 607: loss improved from 993.34540 to 940.34216, saving model to model_aapl.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 927.7289 - mean_absolute_error: 25.9363 - val_loss: 1652.2427 - val_mean_absolute_error: 38.6212\n",
      "Epoch 608/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1269.8911 - mean_absolute_error: 31.3842\n",
      "Epoch 608: loss did not improve from 940.34216\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1048.9968 - mean_absolute_error: 27.7272 - val_loss: 1641.9772 - val_mean_absolute_error: 38.4927\n",
      "Epoch 609/10000\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 844.5153 - mean_absolute_error: 23.6136\n",
      "Epoch 609: loss improved from 940.34216 to 939.58575, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 20373.3164 - mean_absolute_error: 141.4105\n",
      "Epoch 46: loss improved from 21224.55664 to 21109.57812, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 21109.5781 - mean_absolute_error: 143.9732 - val_loss: 24850.1465 - val_mean_absolute_error: 157.4913\n",
      "Epoch 47/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20870.0039 - mean_absolute_error: 142.9319\n",
      "Epoch 47: loss improved from 21109.57812 to 20978.58203, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 20978.5820 - mean_absolute_error: 143.5433 - val_loss: 24715.8086 - val_mean_absolute_error: 157.0643\n",
      "Epoch 48/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 21696.1250 - mean_absolute_error: 145.7052\n",
      "Epoch 48: loss improved from 20978.58203 to 20912.13477, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20912.1348 - mean_absolute_error: 143.3082 - val_loss: 24582.6348 - val_mean_absolute_error: 156.6398\n",
      "Epoch 49/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19080.4121 - mean_absolute_error: 136.4289\n",
      "Epoch 49: loss improved from 20912.13477 to 20758.92578, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20758.9258 - mean_absolute_error: 142.7452 - val_loss: 24451.5352 - val_mean_absolute_error: 156.2207\n",
      "Epoch 50/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20101.1875 - mean_absolute_error: 140.3086\n",
      "Epoch 50: loss improved from 20758.92578 to 20626.48438, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 20626.4844 - mean_absolute_error: 142.3068 - val_loss: 24322.2891 - val_mean_absolute_error: 155.8065\n",
      "Epoch 51/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20212.3906 - mean_absolute_error: 140.7769\n",
      "Epoch 51: loss improved from 20626.48438 to 20549.71289, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 20549.7129 - mean_absolute_error: 142.0195 - val_loss: 24194.7754 - val_mean_absolute_error: 155.3968\n",
      "Epoch 52/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20358.4492 - mean_absolute_error: 141.5467\n",
      "Epoch 52: loss improved from 20549.71289 to 20406.56250, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20406.5625 - mean_absolute_error: 141.5162 - val_loss: 24068.3633 - val_mean_absolute_error: 154.9895\n",
      "Epoch 53/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19658.9199 - mean_absolute_error: 138.6724\n",
      "Epoch 53: loss improved from 20406.56250 to 20289.12109, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 20289.1211 - mean_absolute_error: 141.0840 - val_loss: 23943.9941 - val_mean_absolute_error: 154.5878\n",
      "Epoch 54/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 21106.8203 - mean_absolute_error: 144.2296\n",
      "Epoch 54: loss improved from 20289.12109 to 20149.78711, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20149.7871 - mean_absolute_error: 140.6103 - val_loss: 23821.9688 - val_mean_absolute_error: 154.1926\n",
      "Epoch 55/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20175.3164 - mean_absolute_error: 140.9451\n",
      "Epoch 55: loss improved from 20149.78711 to 20057.92969, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20057.9297 - mean_absolute_error: 140.2679 - val_loss: 23701.2891 - val_mean_absolute_error: 153.8007\n",
      "Epoch 56/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20647.6133 - mean_absolute_error: 142.4786\n",
      "Epoch 56: loss improved from 20057.92969 to 19977.40430, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 19977.4043 - mean_absolute_error: 139.9773 - val_loss: 23581.6621 - val_mean_absolute_error: 153.4113\n",
      "Epoch 57/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20992.7148 - mean_absolute_error: 143.9255\n",
      "Epoch 57: loss improved from 19977.40430 to 19863.63086, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 19863.6309 - mean_absolute_error: 139.5723 - val_loss: 23463.5352 - val_mean_absolute_error: 153.0258\n",
      "Epoch 58/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 20011.6875 - mean_absolute_error: 140.0168\n",
      "Epoch 58: loss improved from 19863.63086 to 19754.85547, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 19754.8555 - mean_absolute_error: 139.1990 - val_loss: 23347.3848 - val_mean_absolute_error: 152.6459\n",
      "Epoch 59/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19832.5977 - mean_absolute_error: 139.7592\n",
      "Epoch 59: loss improved from 19754.85547 to 19645.27930, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 19645.2793 - mean_absolute_error: 138.8067 - val_loss: 23231.8672 - val_mean_absolute_error: 152.2670\n",
      "Epoch 60/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19297.3945 - mean_absolute_error: 137.1177\n",
      "Epoch 60: loss improved from 19645.27930 to 19531.23047, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 19531.2305 - mean_absolute_error: 138.3934 - val_loss: 23117.7559 - val_mean_absolute_error: 151.8918\n",
      "Epoch 61/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18447.3672 - mean_absolute_error: 134.4236\n",
      "Epoch 61: loss improved from 19531.23047 to 19413.91211, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 19413.9121 - mean_absolute_error: 137.9536 - val_loss: 23005.2441 - val_mean_absolute_error: 151.5210\n",
      "Epoch 62/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19317.3359 - mean_absolute_error: 137.9042\n",
      "Epoch 62: loss improved from 19413.91211 to 19322.79297, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 19322.7930 - mean_absolute_error: 137.6261 - val_loss: 22893.3828 - val_mean_absolute_error: 151.1514\n",
      "Epoch 63/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19507.4766 - mean_absolute_error: 138.4766\n",
      "Epoch 63: loss improved from 19322.79297 to 19220.37305, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 19220.3730 - mean_absolute_error: 137.2595 - val_loss: 22783.1504 - val_mean_absolute_error: 150.7864\n",
      "Epoch 64/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18080.0723 - mean_absolute_error: 133.0079\n",
      "Epoch 64: loss improved from 19220.37305 to 19134.88086, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 19134.8809 - mean_absolute_error: 136.9509 - val_loss: 22673.3359 - val_mean_absolute_error: 150.4218\n",
      "Epoch 65/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18569.0371 - mean_absolute_error: 134.8379\n",
      "Epoch 65: loss improved from 19134.88086 to 19030.32617, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 19030.3262 - mean_absolute_error: 136.5758 - val_loss: 22564.8145 - val_mean_absolute_error: 150.0606\n",
      "Epoch 66/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18397.1582 - mean_absolute_error: 134.3170\n",
      "Epoch 66: loss improved from 19030.32617 to 18926.84570, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 18926.8457 - mean_absolute_error: 136.1915 - val_loss: 22456.9727 - val_mean_absolute_error: 149.7009\n",
      "Epoch 67/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18745.3848 - mean_absolute_error: 135.3987\n",
      "Epoch 67: loss improved from 18926.84570 to 18820.15234, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18820.1523 - mean_absolute_error: 135.7868 - val_loss: 22350.2109 - val_mean_absolute_error: 149.3439\n",
      "Epoch 68/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18874.6973 - mean_absolute_error: 135.8864\n",
      "Epoch 68: loss improved from 18820.15234 to 18729.42969, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step - loss: 18729.4297 - mean_absolute_error: 135.4568 - val_loss: 22244.3535 - val_mean_absolute_error: 148.9890\n",
      "Epoch 69/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17850.4375 - mean_absolute_error: 132.1093\n",
      "Epoch 69: loss improved from 18729.42969 to 18654.46680, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18654.4668 - mean_absolute_error: 135.1736 - val_loss: 22139.8496 - val_mean_absolute_error: 148.6379\n",
      "Epoch 70/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19121.8652 - mean_absolute_error: 136.9886\n",
      "Epoch 70: loss improved from 18654.46680 to 18540.19727, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 18540.1973 - mean_absolute_error: 134.7629 - val_loss: 22035.9297 - val_mean_absolute_error: 148.2879\n",
      "Epoch 71/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18181.8867 - mean_absolute_error: 133.5530\n",
      "Epoch 71: loss improved from 18540.19727 to 18464.26758, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18464.2676 - mean_absolute_error: 134.4874 - val_loss: 21933.2344 - val_mean_absolute_error: 147.9412\n",
      "Epoch 72/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18518.4922 - mean_absolute_error: 134.7629\n",
      "Epoch 72: loss improved from 18464.26758 to 18352.00000, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18352.0000 - mean_absolute_error: 134.0581 - val_loss: 21831.1328 - val_mean_absolute_error: 147.5958\n",
      "Epoch 73/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19089.0859 - mean_absolute_error: 136.8540\n",
      "Epoch 73: loss improved from 18352.00000 to 18287.28906, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18287.2891 - mean_absolute_error: 133.8045 - val_loss: 21730.0020 - val_mean_absolute_error: 147.2528\n",
      "Epoch 74/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17898.8477 - mean_absolute_error: 132.1543\n",
      "Epoch 74: loss improved from 18287.28906 to 18179.58789, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18179.5879 - mean_absolute_error: 133.4291 - val_loss: 21630.6426 - val_mean_absolute_error: 146.9150\n",
      "Epoch 75/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 19303.8789 - mean_absolute_error: 137.7733\n",
      "Epoch 75: loss improved from 18179.58789 to 18072.90039, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 18072.9004 - mean_absolute_error: 133.0259 - val_loss: 21531.3262 - val_mean_absolute_error: 146.5766\n",
      "Epoch 76/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17418.3945 - mean_absolute_error: 130.6861\n",
      "Epoch 76: loss improved from 18072.90039 to 17997.92188, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 17997.9219 - mean_absolute_error: 132.7288 - val_loss: 21432.8633 - val_mean_absolute_error: 146.2404\n",
      "Epoch 77/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16850.2402 - mean_absolute_error: 128.2257\n",
      "Epoch 77: loss improved from 17997.92188 to 17879.20898, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 17879.2090 - mean_absolute_error: 132.2977 - val_loss: 21335.6172 - val_mean_absolute_error: 145.9075\n",
      "Epoch 78/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17857.5684 - mean_absolute_error: 132.3983\n",
      "Epoch 78: loss improved from 17879.20898 to 17822.69922, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 17822.6992 - mean_absolute_error: 132.0707 - val_loss: 21238.6074 - val_mean_absolute_error: 145.5747\n",
      "Epoch 79/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17147.3867 - mean_absolute_error: 129.8696\n",
      "Epoch 79: loss improved from 17822.69922 to 17739.50781, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 17739.5078 - mean_absolute_error: 131.7562 - val_loss: 21142.6562 - val_mean_absolute_error: 145.2447\n",
      "Epoch 80/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18791.6699 - mean_absolute_error: 135.9706\n",
      "Epoch 80: loss improved from 17739.50781 to 17640.20312, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 17640.2031 - mean_absolute_error: 131.3878 - val_loss: 21047.3105 - val_mean_absolute_error: 144.9161\n",
      "Epoch 81/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18117.9766 - mean_absolute_error: 133.2885\n",
      "Epoch 81: loss improved from 17640.20312 to 17569.28906, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 17569.2891 - mean_absolute_error: 131.1120 - val_loss: 20952.7090 - val_mean_absolute_error: 144.5894\n",
      "Epoch 82/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18027.6484 - mean_absolute_error: 132.7984\n",
      "Epoch 82: loss improved from 17569.28906 to 17474.76562, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 17474.7656 - mean_absolute_error: 130.7421 - val_loss: 20858.5195 - val_mean_absolute_error: 144.2633\n",
      "Epoch 83/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16229.0527 - mean_absolute_error: 125.8888\n",
      "Epoch 83: loss improved from 17474.76562 to 17366.80859, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 17366.8086 - mean_absolute_error: 130.3342 - val_loss: 20765.5078 - val_mean_absolute_error: 143.9406\n",
      "Epoch 84/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17994.8672 - mean_absolute_error: 132.4132\n",
      "Epoch 84: loss improved from 17366.80859 to 17304.88867, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 17304.8887 - mean_absolute_error: 130.1080 - val_loss: 20673.3047 - val_mean_absolute_error: 143.6199\n",
      "Epoch 85/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16080.7314 - mean_absolute_error: 125.3252\n",
      "Epoch 85: loss improved from 17304.88867 to 17225.52148, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 17225.5215 - mean_absolute_error: 129.7969 - val_loss: 20581.3281 - val_mean_absolute_error: 143.2993\n",
      "Epoch 86/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17430.2930 - mean_absolute_error: 130.9387\n",
      "Epoch 86: loss improved from 17225.52148 to 17140.36523, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 17140.3652 - mean_absolute_error: 129.4698 - val_loss: 20489.3105 - val_mean_absolute_error: 142.9779\n",
      "Epoch 87/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15783.4102 - mean_absolute_error: 124.1259\n",
      "Epoch 87: loss improved from 17140.36523 to 17052.95703, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 17052.9570 - mean_absolute_error: 129.1277 - val_loss: 20398.5430 - val_mean_absolute_error: 142.6601\n",
      "Epoch 88/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17396.0586 - mean_absolute_error: 130.5676\n",
      "Epoch 88: loss improved from 17052.95703 to 16983.33203, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 16983.3320 - mean_absolute_error: 128.8486 - val_loss: 20307.8027 - val_mean_absolute_error: 142.3418\n",
      "Epoch 89/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 18967.3867 - mean_absolute_error: 136.7226\n",
      "Epoch 89: loss improved from 16983.33203 to 16880.53320, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 16880.5332 - mean_absolute_error: 128.4536 - val_loss: 20217.9492 - val_mean_absolute_error: 142.0258\n",
      "Epoch 90/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16496.3750 - mean_absolute_error: 127.0762\n",
      "Epoch 90: loss improved from 16880.53320 to 16847.33594, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 16847.3359 - mean_absolute_error: 128.3261 - val_loss: 20129.0156 - val_mean_absolute_error: 141.7124\n",
      "Epoch 91/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 15915.3184 - mean_absolute_error: 124.3975\n",
      "Epoch 91: loss improved from 16847.33594 to 16730.52930, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 16730.5293 - mean_absolute_error: 127.8588 - val_loss: 20040.8789 - val_mean_absolute_error: 141.4010\n",
      "Epoch 92/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17213.0918 - mean_absolute_error: 130.0752\n",
      "Epoch 92: loss improved from 16730.52930 to 16638.00195, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16638.0020 - mean_absolute_error: 127.5027 - val_loss: 19953.1426 - val_mean_absolute_error: 141.0905\n",
      "Epoch 93/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15369.3447 - mean_absolute_error: 122.4333\n",
      "Epoch 93: loss improved from 16638.00195 to 16577.42773, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16577.4277 - mean_absolute_error: 127.2736 - val_loss: 19866.1699 - val_mean_absolute_error: 140.7819\n",
      "Epoch 94/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16303.0625 - mean_absolute_error: 126.3492\n",
      "Epoch 94: loss improved from 16577.42773 to 16497.76172, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 16497.7617 - mean_absolute_error: 126.9488 - val_loss: 19779.0703 - val_mean_absolute_error: 140.4722\n",
      "Epoch 95/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15528.3242 - mean_absolute_error: 123.3336\n",
      "Epoch 95: loss improved from 16497.76172 to 16418.95312, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16418.9531 - mean_absolute_error: 126.6405 - val_loss: 19692.7363 - val_mean_absolute_error: 140.1646\n",
      "Epoch 96/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15433.5000 - mean_absolute_error: 122.6885\n",
      "Epoch 96: loss improved from 16418.95312 to 16334.86719, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 16334.8672 - mean_absolute_error: 126.2955 - val_loss: 19607.4004 - val_mean_absolute_error: 139.8598\n",
      "Epoch 97/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15467.4150 - mean_absolute_error: 122.3379\n",
      "Epoch 97: loss improved from 16334.86719 to 16273.17773, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16273.1777 - mean_absolute_error: 126.0642 - val_loss: 19522.3652 - val_mean_absolute_error: 139.5555\n",
      "Epoch 98/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15248.7109 - mean_absolute_error: 121.5732\n",
      "Epoch 98: loss improved from 16273.17773 to 16175.34766, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 16175.3477 - mean_absolute_error: 125.6729 - val_loss: 19437.6719 - val_mean_absolute_error: 139.2517\n",
      "Epoch 99/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 17130.1230 - mean_absolute_error: 129.8297\n",
      "Epoch 99: loss improved from 16175.34766 to 16114.28223, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16114.2822 - mean_absolute_error: 125.4395 - val_loss: 19353.7422 - val_mean_absolute_error: 138.9501\n",
      "Epoch 100/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16988.1309 - mean_absolute_error: 128.7844\n",
      "Epoch 100: loss improved from 16114.28223 to 16021.61035, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 16021.6104 - mean_absolute_error: 125.0685 - val_loss: 19270.0977 - val_mean_absolute_error: 138.6487\n",
      "Epoch 101/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15398.2617 - mean_absolute_error: 122.3207\n",
      "Epoch 101: loss improved from 16021.61035 to 15950.23828, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 15950.2383 - mean_absolute_error: 124.7806 - val_loss: 19187.4785 - val_mean_absolute_error: 138.3505\n",
      "Epoch 102/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14952.8770 - mean_absolute_error: 120.9713\n",
      "Epoch 102: loss improved from 15950.23828 to 15884.95605, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 15884.9561 - mean_absolute_error: 124.5198 - val_loss: 19104.6328 - val_mean_absolute_error: 138.0507\n",
      "Epoch 103/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14895.9062 - mean_absolute_error: 120.7202\n",
      "Epoch 103: loss improved from 15884.95605 to 15792.13281, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 15792.1328 - mean_absolute_error: 124.1548 - val_loss: 19022.4297 - val_mean_absolute_error: 137.7527\n",
      "Epoch 104/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15032.1582 - mean_absolute_error: 121.2527\n",
      "Epoch 104: loss improved from 15792.13281 to 15736.96777, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 15736.9678 - mean_absolute_error: 123.9284 - val_loss: 18940.5645 - val_mean_absolute_error: 137.4552\n",
      "Epoch 105/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15694.0703 - mean_absolute_error: 123.4952\n",
      "Epoch 105: loss improved from 15736.96777 to 15644.64648, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 15644.6465 - mean_absolute_error: 123.5542 - val_loss: 18858.9551 - val_mean_absolute_error: 137.1580\n",
      "Epoch 106/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15066.3350 - mean_absolute_error: 120.9161\n",
      "Epoch 106: loss improved from 15644.64648 to 15582.48535, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 15582.4854 - mean_absolute_error: 123.3011 - val_loss: 18778.0859 - val_mean_absolute_error: 136.8629\n",
      "Epoch 107/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16950.6289 - mean_absolute_error: 128.6512\n",
      "Epoch 107: loss improved from 15582.48535 to 15502.65625, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 15502.6562 - mean_absolute_error: 122.9678 - val_loss: 18697.2891 - val_mean_absolute_error: 136.5674\n",
      "Epoch 108/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13419.9277 - mean_absolute_error: 114.3440\n",
      "Epoch 108: loss improved from 15502.65625 to 15450.94238, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 15450.9424 - mean_absolute_error: 122.7600 - val_loss: 18617.4102 - val_mean_absolute_error: 136.2747\n",
      "Epoch 109/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14211.6816 - mean_absolute_error: 118.1634\n",
      "Epoch 109: loss improved from 15450.94238 to 15367.52246, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 15367.5225 - mean_absolute_error: 122.4266 - val_loss: 18537.3301 - val_mean_absolute_error: 135.9805\n",
      "Epoch 110/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16041.5986 - mean_absolute_error: 124.8531\n",
      "Epoch 110: loss improved from 15367.52246 to 15299.43262, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 15299.4326 - mean_absolute_error: 122.1454 - val_loss: 18457.7871 - val_mean_absolute_error: 135.6877\n",
      "Epoch 111/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14600.9248 - mean_absolute_error: 119.0143\n",
      "Epoch 111: loss improved from 15299.43262 to 15219.11230, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 15219.1123 - mean_absolute_error: 121.8128 - val_loss: 18379.0273 - val_mean_absolute_error: 135.3972\n",
      "Epoch 112/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 16223.0586 - mean_absolute_error: 126.0623\n",
      "Epoch 112: loss improved from 15219.11230 to 15149.31250, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 15149.3125 - mean_absolute_error: 121.5295 - val_loss: 18300.5488 - val_mean_absolute_error: 135.1071\n",
      "Epoch 113/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14936.2188 - mean_absolute_error: 121.3957\n",
      "Epoch 113: loss improved from 15149.31250 to 15094.94531, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step - loss: 15094.9453 - mean_absolute_error: 121.2979 - val_loss: 18222.4883 - val_mean_absolute_error: 134.8179\n",
      "Epoch 114/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14256.1592 - mean_absolute_error: 118.1720\n",
      "Epoch 114: loss improved from 15094.94531 to 14997.95898, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 14997.9590 - mean_absolute_error: 120.9032 - val_loss: 18144.9316 - val_mean_absolute_error: 134.5300\n",
      "Epoch 115/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15634.3340 - mean_absolute_error: 123.3366\n",
      "Epoch 115: loss improved from 14997.95898 to 14945.00781, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 14945.0078 - mean_absolute_error: 120.6807 - val_loss: 18067.9180 - val_mean_absolute_error: 134.2434\n",
      "Epoch 116/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14566.9023 - mean_absolute_error: 119.4505\n",
      "Epoch 116: loss improved from 14945.00781 to 14868.54395, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 14868.5439 - mean_absolute_error: 120.3647 - val_loss: 17991.0840 - val_mean_absolute_error: 133.9569\n",
      "Epoch 117/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14410.0723 - mean_absolute_error: 118.3975\n",
      "Epoch 117: loss improved from 14868.54395 to 14826.51270, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14826.5127 - mean_absolute_error: 120.1845 - val_loss: 17914.4414 - val_mean_absolute_error: 133.6705\n",
      "Epoch 118/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14548.9160 - mean_absolute_error: 119.2793\n",
      "Epoch 118: loss improved from 14826.51270 to 14736.31543, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14736.3154 - mean_absolute_error: 119.8099 - val_loss: 17838.3750 - val_mean_absolute_error: 133.3857\n",
      "Epoch 119/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14895.7764 - mean_absolute_error: 120.5372\n",
      "Epoch 119: loss improved from 14736.31543 to 14665.53125, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14665.5312 - mean_absolute_error: 119.5130 - val_loss: 17762.7500 - val_mean_absolute_error: 133.1019\n",
      "Epoch 120/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14316.2461 - mean_absolute_error: 118.0808\n",
      "Epoch 120: loss improved from 14665.53125 to 14602.75293, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 14602.7529 - mean_absolute_error: 119.2650 - val_loss: 17687.3184 - val_mean_absolute_error: 132.8183\n",
      "Epoch 121/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15331.0889 - mean_absolute_error: 122.1267\n",
      "Epoch 121: loss improved from 14602.75293 to 14526.19141, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 14526.1914 - mean_absolute_error: 118.9388 - val_loss: 17612.2090 - val_mean_absolute_error: 132.5352\n",
      "Epoch 122/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14685.8467 - mean_absolute_error: 119.5710\n",
      "Epoch 122: loss improved from 14526.19141 to 14454.58008, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14454.5801 - mean_absolute_error: 118.6450 - val_loss: 17537.4512 - val_mean_absolute_error: 132.2529\n",
      "Epoch 123/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14039.0039 - mean_absolute_error: 116.8031\n",
      "Epoch 123: loss improved from 14454.58008 to 14397.92480, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 14397.9248 - mean_absolute_error: 118.3985 - val_loss: 17462.9492 - val_mean_absolute_error: 131.9709\n",
      "Epoch 124/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15237.8672 - mean_absolute_error: 121.8969\n",
      "Epoch 124: loss improved from 14397.92480 to 14321.44043, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14321.4404 - mean_absolute_error: 118.0689 - val_loss: 17388.6895 - val_mean_absolute_error: 131.6893\n",
      "Epoch 125/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13311.7559 - mean_absolute_error: 113.7925\n",
      "Epoch 125: loss improved from 14321.44043 to 14264.17480, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 14264.1748 - mean_absolute_error: 117.8405 - val_loss: 17315.2305 - val_mean_absolute_error: 131.4101\n",
      "Epoch 126/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13140.6582 - mean_absolute_error: 113.1374\n",
      "Epoch 126: loss improved from 14264.17480 to 14214.09473, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 14214.0947 - mean_absolute_error: 117.6027 - val_loss: 17242.1191 - val_mean_absolute_error: 131.1316\n",
      "Epoch 127/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14008.4160 - mean_absolute_error: 117.0374\n",
      "Epoch 127: loss improved from 14214.09473 to 14164.85547, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14164.8555 - mean_absolute_error: 117.3955 - val_loss: 17169.0254 - val_mean_absolute_error: 130.8526\n",
      "Epoch 128/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13661.3789 - mean_absolute_error: 115.4961\n",
      "Epoch 128: loss improved from 14164.85547 to 14069.30664, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 14069.3066 - mean_absolute_error: 116.9952 - val_loss: 17096.5879 - val_mean_absolute_error: 130.5755\n",
      "Epoch 129/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13934.8154 - mean_absolute_error: 116.0087\n",
      "Epoch 129: loss improved from 14069.30664 to 13988.13281, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13988.1328 - mean_absolute_error: 116.6519 - val_loss: 17024.1660 - val_mean_absolute_error: 130.2979\n",
      "Epoch 130/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 15235.7314 - mean_absolute_error: 122.0738\n",
      "Epoch 130: loss improved from 13988.13281 to 13948.85547, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 13948.8555 - mean_absolute_error: 116.4868 - val_loss: 16951.9238 - val_mean_absolute_error: 130.0204\n",
      "Epoch 131/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12571.8584 - mean_absolute_error: 110.7842\n",
      "Epoch 131: loss improved from 13948.85547 to 13878.50977, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13878.5098 - mean_absolute_error: 116.1769 - val_loss: 16880.2480 - val_mean_absolute_error: 129.7444\n",
      "Epoch 132/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14002.5801 - mean_absolute_error: 116.6711\n",
      "Epoch 132: loss improved from 13878.50977 to 13803.45703, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13803.4570 - mean_absolute_error: 115.8577 - val_loss: 16808.9258 - val_mean_absolute_error: 129.4693\n",
      "Epoch 133/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13562.6270 - mean_absolute_error: 114.9929\n",
      "Epoch 133: loss improved from 13803.45703 to 13752.52539, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13752.5254 - mean_absolute_error: 115.6451 - val_loss: 16737.9082 - val_mean_absolute_error: 129.1948\n",
      "Epoch 134/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14161.1055 - mean_absolute_error: 117.9176\n",
      "Epoch 134: loss improved from 13752.52539 to 13665.76367, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 13665.7637 - mean_absolute_error: 115.2733 - val_loss: 16667.1465 - val_mean_absolute_error: 128.9206\n",
      "Epoch 135/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14679.8633 - mean_absolute_error: 119.3104\n",
      "Epoch 135: loss improved from 13665.76367 to 13643.57129, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13643.5713 - mean_absolute_error: 115.1741 - val_loss: 16596.5117 - val_mean_absolute_error: 128.6464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13187.8750 - mean_absolute_error: 113.4063\n",
      "Epoch 136: loss improved from 13643.57129 to 13547.77148, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 13547.7715 - mean_absolute_error: 114.7505 - val_loss: 16526.5586 - val_mean_absolute_error: 128.3742\n",
      "Epoch 137/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13118.0420 - mean_absolute_error: 112.8029\n",
      "Epoch 137: loss improved from 13547.77148 to 13497.65918, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13497.6592 - mean_absolute_error: 114.5315 - val_loss: 16456.7480 - val_mean_absolute_error: 128.1020\n",
      "Epoch 138/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13268.4570 - mean_absolute_error: 113.9128\n",
      "Epoch 138: loss improved from 13497.65918 to 13417.70215, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 13417.7021 - mean_absolute_error: 114.1841 - val_loss: 16386.9004 - val_mean_absolute_error: 127.8291\n",
      "Epoch 139/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13492.0566 - mean_absolute_error: 114.6006\n",
      "Epoch 139: loss improved from 13417.70215 to 13373.56152, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 13373.5615 - mean_absolute_error: 113.9869 - val_loss: 16317.3799 - val_mean_absolute_error: 127.5569\n",
      "Epoch 140/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12931.3086 - mean_absolute_error: 111.8859\n",
      "Epoch 140: loss improved from 13373.56152 to 13310.08984, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 13310.0898 - mean_absolute_error: 113.7177 - val_loss: 16248.4795 - val_mean_absolute_error: 127.2865\n",
      "Epoch 141/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12684.3984 - mean_absolute_error: 111.3094\n",
      "Epoch 141: loss improved from 13310.08984 to 13255.00000, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13255.0000 - mean_absolute_error: 113.4642 - val_loss: 16179.6553 - val_mean_absolute_error: 127.0159\n",
      "Epoch 142/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14167.2725 - mean_absolute_error: 117.6768\n",
      "Epoch 142: loss improved from 13255.00000 to 13175.87793, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13175.8779 - mean_absolute_error: 113.1157 - val_loss: 16110.8877 - val_mean_absolute_error: 126.7449\n",
      "Epoch 143/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12811.2041 - mean_absolute_error: 111.1458\n",
      "Epoch 143: loss improved from 13175.87793 to 13120.57031, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13120.5703 - mean_absolute_error: 112.8768 - val_loss: 16042.7305 - val_mean_absolute_error: 126.4757\n",
      "Epoch 144/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 14080.7500 - mean_absolute_error: 117.0097\n",
      "Epoch 144: loss improved from 13120.57031 to 13060.99609, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13060.9961 - mean_absolute_error: 112.6051 - val_loss: 15974.5908 - val_mean_absolute_error: 126.2060\n",
      "Epoch 145/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12161.2539 - mean_absolute_error: 108.4582\n",
      "Epoch 145: loss improved from 13060.99609 to 12999.75879, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 12999.7588 - mean_absolute_error: 112.3346 - val_loss: 15906.9609 - val_mean_absolute_error: 125.9378\n",
      "Epoch 146/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13174.9502 - mean_absolute_error: 113.3437\n",
      "Epoch 146: loss improved from 12999.75879 to 12948.29590, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12948.2959 - mean_absolute_error: 112.1133 - val_loss: 15839.8018 - val_mean_absolute_error: 125.6709\n",
      "Epoch 147/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12456.0098 - mean_absolute_error: 110.1486\n",
      "Epoch 147: loss improved from 12948.29590 to 12873.37012, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12873.3701 - mean_absolute_error: 111.7745 - val_loss: 15773.0479 - val_mean_absolute_error: 125.4050\n",
      "Epoch 148/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 13037.2852 - mean_absolute_error: 112.6759\n",
      "Epoch 148: loss improved from 12873.37012 to 12827.00781, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12827.0078 - mean_absolute_error: 111.5558 - val_loss: 15706.5879 - val_mean_absolute_error: 125.1398\n",
      "Epoch 149/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12277.2910 - mean_absolute_error: 108.6641\n",
      "Epoch 149: loss improved from 12827.00781 to 12757.49121, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12757.4912 - mean_absolute_error: 111.2611 - val_loss: 15640.6436 - val_mean_absolute_error: 124.8760\n",
      "Epoch 150/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12720.3604 - mean_absolute_error: 111.1796\n",
      "Epoch 150: loss improved from 12757.49121 to 12703.66602, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12703.6660 - mean_absolute_error: 111.0186 - val_loss: 15574.5684 - val_mean_absolute_error: 124.6112\n",
      "Epoch 151/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12036.9043 - mean_absolute_error: 108.2238\n",
      "Epoch 151: loss improved from 12703.66602 to 12647.88477, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12647.8848 - mean_absolute_error: 110.7694 - val_loss: 15508.8525 - val_mean_absolute_error: 124.3472\n",
      "Epoch 152/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12148.2705 - mean_absolute_error: 108.5095\n",
      "Epoch 152: loss improved from 12647.88477 to 12596.55762, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12596.5576 - mean_absolute_error: 110.5209 - val_loss: 15443.1543 - val_mean_absolute_error: 124.0828\n",
      "Epoch 153/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11920.9004 - mean_absolute_error: 107.4722\n",
      "Epoch 153: loss improved from 12596.55762 to 12529.57031, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12529.5703 - mean_absolute_error: 110.2246 - val_loss: 15377.3027 - val_mean_absolute_error: 123.8171\n",
      "Epoch 154/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11847.7930 - mean_absolute_error: 106.7911\n",
      "Epoch 154: loss improved from 12529.57031 to 12467.06738, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 12467.0674 - mean_absolute_error: 109.9477 - val_loss: 15312.0723 - val_mean_absolute_error: 123.5534\n",
      "Epoch 155/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12203.5918 - mean_absolute_error: 108.2064\n",
      "Epoch 155: loss improved from 12467.06738 to 12406.34473, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12406.3447 - mean_absolute_error: 109.6602 - val_loss: 15246.9971 - val_mean_absolute_error: 123.2898\n",
      "Epoch 156/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12830.5576 - mean_absolute_error: 111.5589\n",
      "Epoch 156: loss improved from 12406.34473 to 12349.13477, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12349.1348 - mean_absolute_error: 109.3929 - val_loss: 15182.0000 - val_mean_absolute_error: 123.0259\n",
      "Epoch 157/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12996.2539 - mean_absolute_error: 112.6497\n",
      "Epoch 157: loss improved from 12349.13477 to 12295.25488, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12295.2549 - mean_absolute_error: 109.1457 - val_loss: 15117.8525 - val_mean_absolute_error: 122.7649\n",
      "Epoch 158/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12834.8818 - mean_absolute_error: 111.6369\n",
      "Epoch 158: loss improved from 12295.25488 to 12247.16602, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step - loss: 12247.1660 - mean_absolute_error: 108.9373 - val_loss: 15054.0498 - val_mean_absolute_error: 122.5048\n",
      "Epoch 159/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11735.7168 - mean_absolute_error: 106.6582\n",
      "Epoch 159: loss improved from 12247.16602 to 12202.50488, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12202.5049 - mean_absolute_error: 108.7356 - val_loss: 14990.5225 - val_mean_absolute_error: 122.2452\n",
      "Epoch 160/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12513.7598 - mean_absolute_error: 110.0242\n",
      "Epoch 160: loss improved from 12202.50488 to 12141.91797, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 12141.9180 - mean_absolute_error: 108.4446 - val_loss: 14927.6104 - val_mean_absolute_error: 121.9876\n",
      "Epoch 161/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11282.8516 - mean_absolute_error: 104.1511\n",
      "Epoch 161: loss improved from 12141.91797 to 12073.60156, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12073.6016 - mean_absolute_error: 108.1407 - val_loss: 14864.3525 - val_mean_absolute_error: 121.7281\n",
      "Epoch 162/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11174.7754 - mean_absolute_error: 103.8812\n",
      "Epoch 162: loss improved from 12073.60156 to 12010.87598, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 12010.8760 - mean_absolute_error: 107.8408 - val_loss: 14801.5234 - val_mean_absolute_error: 121.4697\n",
      "Epoch 163/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12447.0352 - mean_absolute_error: 109.7000\n",
      "Epoch 163: loss improved from 12010.87598 to 11965.04492, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11965.0449 - mean_absolute_error: 107.6373 - val_loss: 14738.2822 - val_mean_absolute_error: 121.2091\n",
      "Epoch 164/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11723.7285 - mean_absolute_error: 105.9801\n",
      "Epoch 164: loss improved from 11965.04492 to 11896.70215, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 11896.7021 - mean_absolute_error: 107.3144 - val_loss: 14675.3721 - val_mean_absolute_error: 120.9494\n",
      "Epoch 165/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12079.5029 - mean_absolute_error: 108.8490\n",
      "Epoch 165: loss improved from 11896.70215 to 11838.17383, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 11838.1738 - mean_absolute_error: 107.0463 - val_loss: 14612.6777 - val_mean_absolute_error: 120.6899\n",
      "Epoch 166/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10244.5840 - mean_absolute_error: 99.6911\n",
      "Epoch 166: loss improved from 11838.17383 to 11794.61035, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11794.6104 - mean_absolute_error: 106.8452 - val_loss: 14550.2793 - val_mean_absolute_error: 120.4311\n",
      "Epoch 167/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11627.4746 - mean_absolute_error: 105.7787\n",
      "Epoch 167: loss improved from 11794.61035 to 11732.79980, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11732.7998 - mean_absolute_error: 106.5427 - val_loss: 14488.0547 - val_mean_absolute_error: 120.1725\n",
      "Epoch 168/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 12522.7080 - mean_absolute_error: 110.0451\n",
      "Epoch 168: loss improved from 11732.79980 to 11694.02637, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 11694.0264 - mean_absolute_error: 106.3669 - val_loss: 14425.8369 - val_mean_absolute_error: 119.9134\n",
      "Epoch 169/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11770.4365 - mean_absolute_error: 106.8763\n",
      "Epoch 169: loss improved from 11694.02637 to 11627.01270, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 11627.0127 - mean_absolute_error: 106.0516 - val_loss: 14364.0547 - val_mean_absolute_error: 119.6555\n",
      "Epoch 170/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10991.7461 - mean_absolute_error: 103.0672\n",
      "Epoch 170: loss improved from 11627.01270 to 11569.88770, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11569.8877 - mean_absolute_error: 105.7772 - val_loss: 14302.8213 - val_mean_absolute_error: 119.3993\n",
      "Epoch 171/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11801.2002 - mean_absolute_error: 107.2652\n",
      "Epoch 171: loss improved from 11569.88770 to 11522.65137, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 11522.6514 - mean_absolute_error: 105.5526 - val_loss: 14241.3555 - val_mean_absolute_error: 119.1416\n",
      "Epoch 172/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11940.6221 - mean_absolute_error: 108.0275\n",
      "Epoch 172: loss improved from 11522.65137 to 11468.65234, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 11468.6523 - mean_absolute_error: 105.3024 - val_loss: 14180.3779 - val_mean_absolute_error: 118.8855\n",
      "Epoch 173/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11181.9395 - mean_absolute_error: 103.6818\n",
      "Epoch 173: loss improved from 11468.65234 to 11413.99023, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11413.9902 - mean_absolute_error: 105.0439 - val_loss: 14119.6143 - val_mean_absolute_error: 118.6296\n",
      "Epoch 174/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11562.1465 - mean_absolute_error: 106.0500\n",
      "Epoch 174: loss improved from 11413.99023 to 11348.82715, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 11348.8271 - mean_absolute_error: 104.7276 - val_loss: 14058.8652 - val_mean_absolute_error: 118.3733\n",
      "Epoch 175/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10994.2227 - mean_absolute_error: 103.4628\n",
      "Epoch 175: loss improved from 11348.82715 to 11294.78711, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 11294.7871 - mean_absolute_error: 104.4807 - val_loss: 13998.5244 - val_mean_absolute_error: 118.1182\n",
      "Epoch 176/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11506.4414 - mean_absolute_error: 105.2414\n",
      "Epoch 176: loss improved from 11294.78711 to 11241.20410, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 11241.2041 - mean_absolute_error: 104.2181 - val_loss: 13938.9434 - val_mean_absolute_error: 117.8657\n",
      "Epoch 177/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11484.2744 - mean_absolute_error: 105.4815\n",
      "Epoch 177: loss improved from 11241.20410 to 11196.00879, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11196.0088 - mean_absolute_error: 103.9978 - val_loss: 13879.3135 - val_mean_absolute_error: 117.6124\n",
      "Epoch 178/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10422.0049 - mean_absolute_error: 100.4184\n",
      "Epoch 178: loss improved from 11196.00879 to 11145.48535, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 11145.4854 - mean_absolute_error: 103.7704 - val_loss: 13820.2832 - val_mean_absolute_error: 117.3612\n",
      "Epoch 179/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10676.1494 - mean_absolute_error: 101.5636\n",
      "Epoch 179: loss improved from 11145.48535 to 11081.28516, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11081.2852 - mean_absolute_error: 103.4436 - val_loss: 13761.3408 - val_mean_absolute_error: 117.1099\n",
      "Epoch 180/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11285.1309 - mean_absolute_error: 104.0272\n",
      "Epoch 180: loss improved from 11081.28516 to 11040.72363, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 11040.7236 - mean_absolute_error: 103.2631 - val_loss: 13702.5674 - val_mean_absolute_error: 116.8587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10785.2168 - mean_absolute_error: 102.2102\n",
      "Epoch 181: loss improved from 11040.72363 to 10986.67773, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10986.6777 - mean_absolute_error: 103.0009 - val_loss: 13643.8379 - val_mean_absolute_error: 116.6071\n",
      "Epoch 182/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10928.1729 - mean_absolute_error: 103.1073\n",
      "Epoch 182: loss improved from 10986.67773 to 10946.23633, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10946.2363 - mean_absolute_error: 102.7832 - val_loss: 13585.3027 - val_mean_absolute_error: 116.3558\n",
      "Epoch 183/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10100.7988 - mean_absolute_error: 98.5891\n",
      "Epoch 183: loss improved from 10946.23633 to 10887.34961, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10887.3496 - mean_absolute_error: 102.5070 - val_loss: 13527.5713 - val_mean_absolute_error: 116.1075\n",
      "Epoch 184/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11503.2734 - mean_absolute_error: 105.5241\n",
      "Epoch 184: loss improved from 10887.34961 to 10840.27539, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10840.2754 - mean_absolute_error: 102.2824 - val_loss: 13469.6787 - val_mean_absolute_error: 115.8579\n",
      "Epoch 185/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11207.2129 - mean_absolute_error: 104.4946\n",
      "Epoch 185: loss improved from 10840.27539 to 10775.37891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10775.3789 - mean_absolute_error: 101.9687 - val_loss: 13411.9561 - val_mean_absolute_error: 115.6085\n",
      "Epoch 186/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10453.2949 - mean_absolute_error: 100.0276\n",
      "Epoch 186: loss improved from 10775.37891 to 10735.97754, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10735.9775 - mean_absolute_error: 101.7676 - val_loss: 13354.2529 - val_mean_absolute_error: 115.3587\n",
      "Epoch 187/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11493.2637 - mean_absolute_error: 105.5696\n",
      "Epoch 187: loss improved from 10735.97754 to 10682.28027, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10682.2803 - mean_absolute_error: 101.4977 - val_loss: 13296.9316 - val_mean_absolute_error: 115.1100\n",
      "Epoch 188/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11037.8789 - mean_absolute_error: 103.6153\n",
      "Epoch 188: loss improved from 10682.28027 to 10624.76660, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10624.7666 - mean_absolute_error: 101.2154 - val_loss: 13239.7129 - val_mean_absolute_error: 114.8612\n",
      "Epoch 189/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11762.3145 - mean_absolute_error: 106.8798\n",
      "Epoch 189: loss improved from 10624.76660 to 10589.31543, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10589.3154 - mean_absolute_error: 101.0416 - val_loss: 13182.5371 - val_mean_absolute_error: 114.6120\n",
      "Epoch 190/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10879.0488 - mean_absolute_error: 102.8266\n",
      "Epoch 190: loss improved from 10589.31543 to 10531.12891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 10531.1289 - mean_absolute_error: 100.7536 - val_loss: 13125.4287 - val_mean_absolute_error: 114.3626\n",
      "Epoch 191/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 11354.3340 - mean_absolute_error: 104.9045\n",
      "Epoch 191: loss improved from 10531.12891 to 10472.10938, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10472.1094 - mean_absolute_error: 100.4488 - val_loss: 13068.3750 - val_mean_absolute_error: 114.1129\n",
      "Epoch 192/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10925.1807 - mean_absolute_error: 102.4493\n",
      "Epoch 192: loss improved from 10472.10938 to 10434.81641, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 10434.8164 - mean_absolute_error: 100.2662 - val_loss: 13012.1104 - val_mean_absolute_error: 113.8661\n",
      "Epoch 193/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10377.4189 - mean_absolute_error: 99.9954\n",
      "Epoch 193: loss improved from 10434.81641 to 10382.28711, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10382.2871 - mean_absolute_error: 100.0148 - val_loss: 12956.1572 - val_mean_absolute_error: 113.6201\n",
      "Epoch 194/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10657.4199 - mean_absolute_error: 102.1273\n",
      "Epoch 194: loss improved from 10382.28711 to 10326.84180, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10326.8418 - mean_absolute_error: 99.7356 - val_loss: 12899.9951 - val_mean_absolute_error: 113.3727\n",
      "Epoch 195/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9874.7207 - mean_absolute_error: 97.9562\n",
      "Epoch 195: loss improved from 10326.84180 to 10291.40332, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10291.4033 - mean_absolute_error: 99.5575 - val_loss: 12843.9297 - val_mean_absolute_error: 113.1252\n",
      "Epoch 196/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10092.9258 - mean_absolute_error: 98.3468\n",
      "Epoch 196: loss improved from 10291.40332 to 10226.35840, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 10226.3584 - mean_absolute_error: 99.2279 - val_loss: 12788.6152 - val_mean_absolute_error: 112.8804\n",
      "Epoch 197/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10218.0107 - mean_absolute_error: 99.0889\n",
      "Epoch 197: loss improved from 10226.35840 to 10185.08887, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10185.0889 - mean_absolute_error: 99.0214 - val_loss: 12733.6670 - val_mean_absolute_error: 112.6368\n",
      "Epoch 198/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9837.5039 - mean_absolute_error: 96.4901\n",
      "Epoch 198: loss improved from 10185.08887 to 10145.19238, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10145.1924 - mean_absolute_error: 98.8218 - val_loss: 12678.4971 - val_mean_absolute_error: 112.3916\n",
      "Epoch 199/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10856.5225 - mean_absolute_error: 101.9948\n",
      "Epoch 199: loss improved from 10145.19238 to 10085.92578, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10085.9258 - mean_absolute_error: 98.5173 - val_loss: 12623.4961 - val_mean_absolute_error: 112.1467\n",
      "Epoch 200/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9522.7617 - mean_absolute_error: 95.9337\n",
      "Epoch 200: loss improved from 10085.92578 to 10039.31738, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 10039.3174 - mean_absolute_error: 98.2891 - val_loss: 12569.0566 - val_mean_absolute_error: 111.9037\n",
      "Epoch 201/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9277.2002 - mean_absolute_error: 94.0725\n",
      "Epoch 201: loss improved from 10039.31738 to 10000.34766, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 10000.3477 - mean_absolute_error: 98.0898 - val_loss: 12514.1240 - val_mean_absolute_error: 111.6580\n",
      "Epoch 202/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9301.2969 - mean_absolute_error: 94.6912\n",
      "Epoch 202: loss improved from 10000.34766 to 9943.19629, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9943.1963 - mean_absolute_error: 97.7872 - val_loss: 12459.8877 - val_mean_absolute_error: 111.4148\n",
      "Epoch 203/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9324.0645 - mean_absolute_error: 94.7638\n",
      "Epoch 203: loss improved from 9943.19629 to 9892.86621, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step - loss: 9892.8662 - mean_absolute_error: 97.5442 - val_loss: 12405.9551 - val_mean_absolute_error: 111.1725\n",
      "Epoch 204/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8814.0664 - mean_absolute_error: 91.5414\n",
      "Epoch 204: loss improved from 9892.86621 to 9844.99902, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9844.9990 - mean_absolute_error: 97.2820 - val_loss: 12352.1104 - val_mean_absolute_error: 110.9301\n",
      "Epoch 205/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9333.2510 - mean_absolute_error: 94.8391\n",
      "Epoch 205: loss improved from 9844.99902 to 9799.49219, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9799.4922 - mean_absolute_error: 97.0578 - val_loss: 12298.4238 - val_mean_absolute_error: 110.6879\n",
      "Epoch 206/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9038.1074 - mean_absolute_error: 93.0591\n",
      "Epoch 206: loss improved from 9799.49219 to 9774.50488, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9774.5049 - mean_absolute_error: 96.9229 - val_loss: 12244.9385 - val_mean_absolute_error: 110.4460\n",
      "Epoch 207/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10305.4355 - mean_absolute_error: 99.5741\n",
      "Epoch 207: loss improved from 9774.50488 to 9712.33105, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9712.3311 - mean_absolute_error: 96.6143 - val_loss: 12191.3252 - val_mean_absolute_error: 110.2030\n",
      "Epoch 208/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10814.4971 - mean_absolute_error: 102.2513\n",
      "Epoch 208: loss improved from 9712.33105 to 9678.55078, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9678.5508 - mean_absolute_error: 96.4267 - val_loss: 12137.9199 - val_mean_absolute_error: 109.9604\n",
      "Epoch 209/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9909.3125 - mean_absolute_error: 96.9726\n",
      "Epoch 209: loss improved from 9678.55078 to 9620.54688, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9620.5469 - mean_absolute_error: 96.1204 - val_loss: 12084.9854 - val_mean_absolute_error: 109.7195\n",
      "Epoch 210/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9613.4062 - mean_absolute_error: 96.0538\n",
      "Epoch 210: loss improved from 9620.54688 to 9585.68848, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9585.6885 - mean_absolute_error: 95.9356 - val_loss: 12032.4668 - val_mean_absolute_error: 109.4799\n",
      "Epoch 211/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8555.6787 - mean_absolute_error: 90.6834\n",
      "Epoch 211: loss improved from 9585.68848 to 9519.91895, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9519.9189 - mean_absolute_error: 95.6005 - val_loss: 11980.0303 - val_mean_absolute_error: 109.2401\n",
      "Epoch 212/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10803.8945 - mean_absolute_error: 102.9882\n",
      "Epoch 212: loss improved from 9519.91895 to 9477.44336, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 9477.4434 - mean_absolute_error: 95.3723 - val_loss: 11927.0469 - val_mean_absolute_error: 108.9974\n",
      "Epoch 213/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9192.6260 - mean_absolute_error: 94.3606\n",
      "Epoch 213: loss improved from 9477.44336 to 9424.74219, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9424.7422 - mean_absolute_error: 95.0995 - val_loss: 11874.9727 - val_mean_absolute_error: 108.7582\n",
      "Epoch 214/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9981.8066 - mean_absolute_error: 97.5965\n",
      "Epoch 214: loss improved from 9424.74219 to 9405.15332, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9405.1533 - mean_absolute_error: 94.9885 - val_loss: 11823.5879 - val_mean_absolute_error: 108.5217\n",
      "Epoch 215/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9795.8584 - mean_absolute_error: 96.8134\n",
      "Epoch 215: loss improved from 9405.15332 to 9329.02246, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9329.0225 - mean_absolute_error: 94.5976 - val_loss: 11772.3984 - val_mean_absolute_error: 108.2856\n",
      "Epoch 216/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8486.6719 - mean_absolute_error: 89.7924\n",
      "Epoch 216: loss improved from 9329.02246 to 9295.07031, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 9295.0703 - mean_absolute_error: 94.4228 - val_loss: 11721.3857 - val_mean_absolute_error: 108.0498\n",
      "Epoch 217/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9704.4004 - mean_absolute_error: 96.2108\n",
      "Epoch 217: loss improved from 9295.07031 to 9248.00391, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 9248.0039 - mean_absolute_error: 94.1704 - val_loss: 11670.2920 - val_mean_absolute_error: 107.8131\n",
      "Epoch 218/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9543.4131 - mean_absolute_error: 95.5038\n",
      "Epoch 218: loss improved from 9248.00391 to 9213.71094, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9213.7109 - mean_absolute_error: 93.9832 - val_loss: 11619.2891 - val_mean_absolute_error: 107.5763\n",
      "Epoch 219/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 10348.3672 - mean_absolute_error: 99.9159\n",
      "Epoch 219: loss improved from 9213.71094 to 9159.96191, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 9159.9619 - mean_absolute_error: 93.6955 - val_loss: 11568.4971 - val_mean_absolute_error: 107.3400\n",
      "Epoch 220/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9603.4326 - mean_absolute_error: 96.4234\n",
      "Epoch 220: loss improved from 9159.96191 to 9113.93457, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9113.9346 - mean_absolute_error: 93.4579 - val_loss: 11517.5547 - val_mean_absolute_error: 107.1024\n",
      "Epoch 221/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8973.3545 - mean_absolute_error: 92.3403\n",
      "Epoch 221: loss improved from 9113.93457 to 9069.51660, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9069.5166 - mean_absolute_error: 93.2146 - val_loss: 11466.5684 - val_mean_absolute_error: 106.8641\n",
      "Epoch 222/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8743.3867 - mean_absolute_error: 91.1255\n",
      "Epoch 222: loss improved from 9069.51660 to 9033.74512, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9033.7451 - mean_absolute_error: 93.0234 - val_loss: 11416.1533 - val_mean_absolute_error: 106.6280\n",
      "Epoch 223/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8972.6963 - mean_absolute_error: 92.4612\n",
      "Epoch 223: loss improved from 9033.74512 to 8985.65039, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8985.6504 - mean_absolute_error: 92.7724 - val_loss: 11365.8984 - val_mean_absolute_error: 106.3921\n",
      "Epoch 224/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8621.6309 - mean_absolute_error: 90.7740\n",
      "Epoch 224: loss improved from 8985.65039 to 8938.91113, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8938.9111 - mean_absolute_error: 92.5201 - val_loss: 11315.3506 - val_mean_absolute_error: 106.1543\n",
      "Epoch 225/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9489.5742 - mean_absolute_error: 95.4242\n",
      "Epoch 225: loss improved from 8938.91113 to 8897.43359, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8897.4336 - mean_absolute_error: 92.2790 - val_loss: 11265.3701 - val_mean_absolute_error: 105.9186\n",
      "Epoch 226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 8777.0479 - mean_absolute_error: 91.8970\n",
      "Epoch 226: loss improved from 8897.43359 to 8855.01172, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8855.0117 - mean_absolute_error: 92.0615 - val_loss: 11215.4570 - val_mean_absolute_error: 105.6827\n",
      "Epoch 227/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8919.0449 - mean_absolute_error: 92.8108\n",
      "Epoch 227: loss improved from 8855.01172 to 8807.02832, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8807.0283 - mean_absolute_error: 91.7966 - val_loss: 11165.5244 - val_mean_absolute_error: 105.4462\n",
      "Epoch 228/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8500.6680 - mean_absolute_error: 90.2675\n",
      "Epoch 228: loss improved from 8807.02832 to 8761.29492, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8761.2949 - mean_absolute_error: 91.5534 - val_loss: 11116.0830 - val_mean_absolute_error: 105.2115\n",
      "Epoch 229/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8182.5005 - mean_absolute_error: 88.4722\n",
      "Epoch 229: loss improved from 8761.29492 to 8719.20605, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8719.2061 - mean_absolute_error: 91.3208 - val_loss: 11066.7109 - val_mean_absolute_error: 104.9766\n",
      "Epoch 230/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7370.9502 - mean_absolute_error: 83.5227\n",
      "Epoch 230: loss improved from 8719.20605 to 8685.70215, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8685.7021 - mean_absolute_error: 91.1385 - val_loss: 11017.7070 - val_mean_absolute_error: 104.7429\n",
      "Epoch 231/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8177.1943 - mean_absolute_error: 87.7883\n",
      "Epoch 231: loss improved from 8685.70215 to 8646.05371, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8646.0537 - mean_absolute_error: 90.9092 - val_loss: 10968.8232 - val_mean_absolute_error: 104.5093\n",
      "Epoch 232/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8717.8730 - mean_absolute_error: 90.9763\n",
      "Epoch 232: loss improved from 8646.05371 to 8601.25586, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8601.2559 - mean_absolute_error: 90.6723 - val_loss: 10920.1533 - val_mean_absolute_error: 104.2762\n",
      "Epoch 233/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8739.3906 - mean_absolute_error: 91.9147\n",
      "Epoch 233: loss improved from 8601.25586 to 8558.31836, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8558.3184 - mean_absolute_error: 90.4309 - val_loss: 10871.9336 - val_mean_absolute_error: 104.0447\n",
      "Epoch 234/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8684.5420 - mean_absolute_error: 91.2361\n",
      "Epoch 234: loss improved from 8558.31836 to 8508.97168, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8508.9717 - mean_absolute_error: 90.1533 - val_loss: 10823.8691 - val_mean_absolute_error: 103.8135\n",
      "Epoch 235/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8277.3867 - mean_absolute_error: 88.7759\n",
      "Epoch 235: loss improved from 8508.97168 to 8470.23340, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 8470.2334 - mean_absolute_error: 89.9380 - val_loss: 10775.6816 - val_mean_absolute_error: 103.5812\n",
      "Epoch 236/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7750.8389 - mean_absolute_error: 85.7056\n",
      "Epoch 236: loss improved from 8470.23340 to 8423.64453, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 8423.6445 - mean_absolute_error: 89.6833 - val_loss: 10727.7295 - val_mean_absolute_error: 103.3494\n",
      "Epoch 237/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 9097.7402 - mean_absolute_error: 93.7547\n",
      "Epoch 237: loss improved from 8423.64453 to 8394.31348, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8394.3135 - mean_absolute_error: 89.5179 - val_loss: 10679.9121 - val_mean_absolute_error: 103.1178\n",
      "Epoch 238/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8332.5684 - mean_absolute_error: 89.2302\n",
      "Epoch 238: loss improved from 8394.31348 to 8346.69727, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8346.6973 - mean_absolute_error: 89.2593 - val_loss: 10632.2451 - val_mean_absolute_error: 102.8865\n",
      "Epoch 239/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8293.5361 - mean_absolute_error: 89.0466\n",
      "Epoch 239: loss improved from 8346.69727 to 8309.32910, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8309.3291 - mean_absolute_error: 89.0472 - val_loss: 10585.0137 - val_mean_absolute_error: 102.6567\n",
      "Epoch 240/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7939.4170 - mean_absolute_error: 86.6676\n",
      "Epoch 240: loss improved from 8309.32910 to 8261.82422, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8261.8242 - mean_absolute_error: 88.7879 - val_loss: 10538.1152 - val_mean_absolute_error: 102.4280\n",
      "Epoch 241/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7760.0342 - mean_absolute_error: 85.6695\n",
      "Epoch 241: loss improved from 8261.82422 to 8225.03223, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8225.0322 - mean_absolute_error: 88.5803 - val_loss: 10491.0322 - val_mean_absolute_error: 102.1979\n",
      "Epoch 242/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8741.2578 - mean_absolute_error: 92.0851\n",
      "Epoch 242: loss improved from 8225.03223 to 8189.13232, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8189.1323 - mean_absolute_error: 88.3634 - val_loss: 10443.9043 - val_mean_absolute_error: 101.9670\n",
      "Epoch 243/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7550.5015 - mean_absolute_error: 84.6959\n",
      "Epoch 243: loss improved from 8189.13232 to 8141.36182, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 8141.3618 - mean_absolute_error: 88.1002 - val_loss: 10397.0488 - val_mean_absolute_error: 101.7370\n",
      "Epoch 244/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8582.3262 - mean_absolute_error: 90.5407\n",
      "Epoch 244: loss improved from 8141.36182 to 8094.09961, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8094.0996 - mean_absolute_error: 87.8269 - val_loss: 10349.9365 - val_mean_absolute_error: 101.5052\n",
      "Epoch 245/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6840.6914 - mean_absolute_error: 80.2930\n",
      "Epoch 245: loss improved from 8094.09961 to 8056.25928, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8056.2593 - mean_absolute_error: 87.6229 - val_loss: 10303.3828 - val_mean_absolute_error: 101.2757\n",
      "Epoch 246/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8575.9766 - mean_absolute_error: 90.9515\n",
      "Epoch 246: loss improved from 8056.25928 to 8016.34521, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 8016.3452 - mean_absolute_error: 87.3869 - val_loss: 10256.5684 - val_mean_absolute_error: 101.0443\n",
      "Epoch 247/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7632.9824 - mean_absolute_error: 85.0961\n",
      "Epoch 247: loss improved from 8016.34521 to 7979.05176, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7979.0518 - mean_absolute_error: 87.1730 - val_loss: 10210.4092 - val_mean_absolute_error: 100.8156\n",
      "Epoch 248/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8035.9014 - mean_absolute_error: 87.5322\n",
      "Epoch 248: loss improved from 7979.05176 to 7937.88477, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7937.8848 - mean_absolute_error: 86.9291 - val_loss: 10164.4316 - val_mean_absolute_error: 100.5873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8024.0928 - mean_absolute_error: 87.2820\n",
      "Epoch 249: loss improved from 7937.88477 to 7911.67334, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7911.6733 - mean_absolute_error: 86.7908 - val_loss: 10118.7549 - val_mean_absolute_error: 100.3600\n",
      "Epoch 250/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7698.6572 - mean_absolute_error: 84.7553\n",
      "Epoch 250: loss improved from 7911.67334 to 7866.25146, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7866.2515 - mean_absolute_error: 86.5228 - val_loss: 10073.1670 - val_mean_absolute_error: 100.1326\n",
      "Epoch 251/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7191.1143 - mean_absolute_error: 82.5404\n",
      "Epoch 251: loss improved from 7866.25146 to 7829.88428, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7829.8843 - mean_absolute_error: 86.2984 - val_loss: 10027.7119 - val_mean_absolute_error: 99.9054\n",
      "Epoch 252/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8215.4199 - mean_absolute_error: 88.5052\n",
      "Epoch 252: loss improved from 7829.88428 to 7787.61768, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7787.6177 - mean_absolute_error: 86.0539 - val_loss: 9981.9863 - val_mean_absolute_error: 99.6763\n",
      "Epoch 253/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7740.3560 - mean_absolute_error: 85.5654\n",
      "Epoch 253: loss improved from 7787.61768 to 7742.24609, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7742.2461 - mean_absolute_error: 85.8032 - val_loss: 9936.9072 - val_mean_absolute_error: 99.4499\n",
      "Epoch 254/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8059.9702 - mean_absolute_error: 87.7376\n",
      "Epoch 254: loss improved from 7742.24609 to 7704.46436, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7704.4644 - mean_absolute_error: 85.5846 - val_loss: 9891.5928 - val_mean_absolute_error: 99.2218\n",
      "Epoch 255/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6891.7070 - mean_absolute_error: 80.1623\n",
      "Epoch 255: loss improved from 7704.46436 to 7660.13379, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7660.1338 - mean_absolute_error: 85.3371 - val_loss: 9847.0596 - val_mean_absolute_error: 98.9972\n",
      "Epoch 256/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 8471.5654 - mean_absolute_error: 90.3046\n",
      "Epoch 256: loss improved from 7660.13379 to 7633.83203, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 7633.8320 - mean_absolute_error: 85.1664 - val_loss: 9802.0488 - val_mean_absolute_error: 98.7696\n",
      "Epoch 257/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7327.2397 - mean_absolute_error: 83.1813\n",
      "Epoch 257: loss improved from 7633.83203 to 7595.04688, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7595.0469 - mean_absolute_error: 84.9413 - val_loss: 9757.2471 - val_mean_absolute_error: 98.5425\n",
      "Epoch 258/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7564.3301 - mean_absolute_error: 84.8308\n",
      "Epoch 258: loss improved from 7595.04688 to 7555.84766, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7555.8477 - mean_absolute_error: 84.7064 - val_loss: 9712.8994 - val_mean_absolute_error: 98.3172\n",
      "Epoch 259/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7413.9404 - mean_absolute_error: 84.0795\n",
      "Epoch 259: loss improved from 7555.84766 to 7510.48486, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 7510.4849 - mean_absolute_error: 84.4405 - val_loss: 9668.7480 - val_mean_absolute_error: 98.0924\n",
      "Epoch 260/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7513.6230 - mean_absolute_error: 84.8197\n",
      "Epoch 260: loss improved from 7510.48486 to 7476.40039, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7476.4004 - mean_absolute_error: 84.2379 - val_loss: 9624.8574 - val_mean_absolute_error: 97.8685\n",
      "Epoch 261/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7572.3135 - mean_absolute_error: 84.5589\n",
      "Epoch 261: loss improved from 7476.40039 to 7442.81201, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 7442.8120 - mean_absolute_error: 84.0411 - val_loss: 9581.4756 - val_mean_absolute_error: 97.6466\n",
      "Epoch 262/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6398.7578 - mean_absolute_error: 77.5668\n",
      "Epoch 262: loss improved from 7442.81201 to 7396.08203, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7396.0820 - mean_absolute_error: 83.7721 - val_loss: 9538.2832 - val_mean_absolute_error: 97.4251\n",
      "Epoch 263/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7733.9492 - mean_absolute_error: 85.7759\n",
      "Epoch 263: loss improved from 7396.08203 to 7361.21289, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7361.2129 - mean_absolute_error: 83.5486 - val_loss: 9494.7441 - val_mean_absolute_error: 97.2014\n",
      "Epoch 264/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6950.7759 - mean_absolute_error: 80.6513\n",
      "Epoch 264: loss improved from 7361.21289 to 7326.98730, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7326.9873 - mean_absolute_error: 83.3441 - val_loss: 9451.3975 - val_mean_absolute_error: 96.9782\n",
      "Epoch 265/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7648.3857 - mean_absolute_error: 84.9356\n",
      "Epoch 265: loss improved from 7326.98730 to 7291.78125, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7291.7812 - mean_absolute_error: 83.1287 - val_loss: 9407.9375 - val_mean_absolute_error: 96.7539\n",
      "Epoch 266/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7933.1538 - mean_absolute_error: 86.9492\n",
      "Epoch 266: loss improved from 7291.78125 to 7257.63770, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7257.6377 - mean_absolute_error: 82.9230 - val_loss: 9364.8926 - val_mean_absolute_error: 96.5312\n",
      "Epoch 267/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7133.7578 - mean_absolute_error: 82.1003\n",
      "Epoch 267: loss improved from 7257.63770 to 7215.89551, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7215.8955 - mean_absolute_error: 82.6827 - val_loss: 9322.1289 - val_mean_absolute_error: 96.3094\n",
      "Epoch 268/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7271.2930 - mean_absolute_error: 83.2096\n",
      "Epoch 268: loss improved from 7215.89551 to 7173.23047, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7173.2305 - mean_absolute_error: 82.4166 - val_loss: 9279.2441 - val_mean_absolute_error: 96.0865\n",
      "Epoch 269/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6495.7305 - mean_absolute_error: 78.1180\n",
      "Epoch 269: loss improved from 7173.23047 to 7136.37549, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7136.3755 - mean_absolute_error: 82.1966 - val_loss: 9236.7754 - val_mean_absolute_error: 95.8653\n",
      "Epoch 270/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6435.7104 - mean_absolute_error: 78.1772\n",
      "Epoch 270: loss improved from 7136.37549 to 7097.49316, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7097.4932 - mean_absolute_error: 81.9589 - val_loss: 9194.3105 - val_mean_absolute_error: 95.6435\n",
      "Epoch 271/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7648.7720 - mean_absolute_error: 85.8203\n",
      "Epoch 271: loss improved from 7097.49316 to 7069.59961, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7069.5996 - mean_absolute_error: 81.7854 - val_loss: 9152.0254 - val_mean_absolute_error: 95.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6904.3193 - mean_absolute_error: 80.7857\n",
      "Epoch 272: loss improved from 7069.59961 to 7026.57617, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7026.5762 - mean_absolute_error: 81.5238 - val_loss: 9109.7676 - val_mean_absolute_error: 95.2005\n",
      "Epoch 273/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7522.1108 - mean_absolute_error: 84.6142\n",
      "Epoch 273: loss improved from 7026.57617 to 6989.79443, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6989.7944 - mean_absolute_error: 81.2982 - val_loss: 9067.5635 - val_mean_absolute_error: 94.9786\n",
      "Epoch 274/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7212.1133 - mean_absolute_error: 83.0665\n",
      "Epoch 274: loss improved from 6989.79443 to 6959.16211, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6959.1621 - mean_absolute_error: 81.1069 - val_loss: 9025.5977 - val_mean_absolute_error: 94.7574\n",
      "Epoch 275/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5871.1094 - mean_absolute_error: 73.6444\n",
      "Epoch 275: loss improved from 6959.16211 to 6915.76270, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6915.7627 - mean_absolute_error: 80.8438 - val_loss: 8983.8096 - val_mean_absolute_error: 94.5367\n",
      "Epoch 276/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6595.7144 - mean_absolute_error: 78.5862\n",
      "Epoch 276: loss improved from 6915.76270 to 6890.56445, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6890.5645 - mean_absolute_error: 80.6773 - val_loss: 8942.1836 - val_mean_absolute_error: 94.3163\n",
      "Epoch 277/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7790.2397 - mean_absolute_error: 86.6904\n",
      "Epoch 277: loss improved from 6890.56445 to 6851.56738, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6851.5674 - mean_absolute_error: 80.4421 - val_loss: 8900.4463 - val_mean_absolute_error: 94.0947\n",
      "Epoch 278/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7037.2988 - mean_absolute_error: 81.5971\n",
      "Epoch 278: loss improved from 6851.56738 to 6814.55859, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 6814.5586 - mean_absolute_error: 80.2067 - val_loss: 8859.0615 - val_mean_absolute_error: 93.8746\n",
      "Epoch 279/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6975.0986 - mean_absolute_error: 81.9440\n",
      "Epoch 279: loss improved from 6814.55859 to 6776.24561, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6776.2456 - mean_absolute_error: 79.9728 - val_loss: 8818.0703 - val_mean_absolute_error: 93.6560\n",
      "Epoch 280/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7195.6763 - mean_absolute_error: 82.9391\n",
      "Epoch 280: loss improved from 6776.24561 to 6749.21143, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 6749.2114 - mean_absolute_error: 79.8059 - val_loss: 8777.1211 - val_mean_absolute_error: 93.4371\n",
      "Epoch 281/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6560.9346 - mean_absolute_error: 78.9796\n",
      "Epoch 281: loss improved from 6749.21143 to 6706.82812, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6706.8281 - mean_absolute_error: 79.5427 - val_loss: 8736.5762 - val_mean_absolute_error: 93.2199\n",
      "Epoch 282/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6065.8604 - mean_absolute_error: 75.5210\n",
      "Epoch 282: loss improved from 6706.82812 to 6681.73926, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 6681.7393 - mean_absolute_error: 79.3738 - val_loss: 8696.1484 - val_mean_absolute_error: 93.0028\n",
      "Epoch 283/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6700.9160 - mean_absolute_error: 79.7362\n",
      "Epoch 283: loss improved from 6681.73926 to 6645.69434, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6645.6943 - mean_absolute_error: 79.1470 - val_loss: 8655.7441 - val_mean_absolute_error: 92.7853\n",
      "Epoch 284/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7644.9170 - mean_absolute_error: 85.8914\n",
      "Epoch 284: loss improved from 6645.69434 to 6599.99023, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6599.9902 - mean_absolute_error: 78.8642 - val_loss: 8615.3594 - val_mean_absolute_error: 92.5675\n",
      "Epoch 285/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6476.7793 - mean_absolute_error: 78.4566\n",
      "Epoch 285: loss improved from 6599.99023 to 6568.98242, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6568.9824 - mean_absolute_error: 78.6798 - val_loss: 8575.1592 - val_mean_absolute_error: 92.3501\n",
      "Epoch 286/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6413.6138 - mean_absolute_error: 77.8761\n",
      "Epoch 286: loss improved from 6568.98242 to 6543.86865, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6543.8687 - mean_absolute_error: 78.5140 - val_loss: 8535.0078 - val_mean_absolute_error: 92.1324\n",
      "Epoch 287/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6591.5967 - mean_absolute_error: 78.5287\n",
      "Epoch 287: loss improved from 6543.86865 to 6507.20557, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6507.2056 - mean_absolute_error: 78.2713 - val_loss: 8495.4346 - val_mean_absolute_error: 91.9174\n",
      "Epoch 288/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7458.9434 - mean_absolute_error: 84.8168\n",
      "Epoch 288: loss improved from 6507.20557 to 6473.91113, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6473.9111 - mean_absolute_error: 78.0611 - val_loss: 8455.8359 - val_mean_absolute_error: 91.7017\n",
      "Epoch 289/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 7228.3149 - mean_absolute_error: 82.3592\n",
      "Epoch 289: loss improved from 6473.91113 to 6438.55762, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6438.5576 - mean_absolute_error: 77.8382 - val_loss: 8416.2949 - val_mean_absolute_error: 91.4859\n",
      "Epoch 290/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5666.3462 - mean_absolute_error: 72.8012\n",
      "Epoch 290: loss improved from 6438.55762 to 6400.21680, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 6400.2168 - mean_absolute_error: 77.5903 - val_loss: 8377.0283 - val_mean_absolute_error: 91.2710\n",
      "Epoch 291/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6523.9375 - mean_absolute_error: 78.8073\n",
      "Epoch 291: loss improved from 6400.21680 to 6374.49951, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6374.4995 - mean_absolute_error: 77.4252 - val_loss: 8337.6865 - val_mean_absolute_error: 91.0553\n",
      "Epoch 292/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6478.4453 - mean_absolute_error: 78.0863\n",
      "Epoch 292: loss improved from 6374.49951 to 6343.83496, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 6343.8350 - mean_absolute_error: 77.2172 - val_loss: 8298.4023 - val_mean_absolute_error: 90.8393\n",
      "Epoch 293/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6696.6172 - mean_absolute_error: 79.0825\n",
      "Epoch 293: loss improved from 6343.83496 to 6298.80811, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6298.8081 - mean_absolute_error: 76.9289 - val_loss: 8259.1270 - val_mean_absolute_error: 90.6229\n",
      "Epoch 294/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5947.3887 - mean_absolute_error: 73.7614\n",
      "Epoch 294: loss improved from 6298.80811 to 6273.89355, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6273.8936 - mean_absolute_error: 76.7654 - val_loss: 8219.9053 - val_mean_absolute_error: 90.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5194.0698 - mean_absolute_error: 69.3478\n",
      "Epoch 295: loss improved from 6273.89355 to 6234.65625, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6234.6562 - mean_absolute_error: 76.5174 - val_loss: 8180.8022 - val_mean_absolute_error: 90.1897\n",
      "Epoch 296/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5540.6880 - mean_absolute_error: 71.6421\n",
      "Epoch 296: loss improved from 6234.65625 to 6202.36084, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6202.3608 - mean_absolute_error: 76.3033 - val_loss: 8141.9082 - val_mean_absolute_error: 89.9738\n",
      "Epoch 297/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6008.7471 - mean_absolute_error: 74.8968\n",
      "Epoch 297: loss improved from 6202.36084 to 6167.32959, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 6167.3296 - mean_absolute_error: 76.0706 - val_loss: 8103.2378 - val_mean_absolute_error: 89.7586\n",
      "Epoch 298/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5975.6572 - mean_absolute_error: 74.7433\n",
      "Epoch 298: loss improved from 6167.32959 to 6135.21436, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6135.2144 - mean_absolute_error: 75.8672 - val_loss: 8064.9165 - val_mean_absolute_error: 89.5449\n",
      "Epoch 299/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6280.0039 - mean_absolute_error: 76.1739\n",
      "Epoch 299: loss improved from 6135.21436 to 6107.71631, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 6107.7163 - mean_absolute_error: 75.6828 - val_loss: 8026.7427 - val_mean_absolute_error: 89.3315\n",
      "Epoch 300/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5619.0254 - mean_absolute_error: 72.5134\n",
      "Epoch 300: loss improved from 6107.71631 to 6075.36768, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6075.3677 - mean_absolute_error: 75.4790 - val_loss: 7988.7412 - val_mean_absolute_error: 89.1185\n",
      "Epoch 301/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5754.5996 - mean_absolute_error: 72.5347\n",
      "Epoch 301: loss improved from 6075.36768 to 6041.43896, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6041.4390 - mean_absolute_error: 75.2511 - val_loss: 7950.4692 - val_mean_absolute_error: 88.9036\n",
      "Epoch 302/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4700.8638 - mean_absolute_error: 66.3201\n",
      "Epoch 302: loss improved from 6041.43896 to 6018.86182, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6018.8618 - mean_absolute_error: 75.1010 - val_loss: 7912.5840 - val_mean_absolute_error: 88.6902\n",
      "Epoch 303/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6660.5928 - mean_absolute_error: 79.5045\n",
      "Epoch 303: loss improved from 6018.86182 to 5978.60986, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5978.6099 - mean_absolute_error: 74.8187 - val_loss: 7874.6782 - val_mean_absolute_error: 88.4763\n",
      "Epoch 304/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6526.4150 - mean_absolute_error: 78.4769\n",
      "Epoch 304: loss improved from 5978.60986 to 5943.47510, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5943.4751 - mean_absolute_error: 74.5915 - val_loss: 7837.1499 - val_mean_absolute_error: 88.2640\n",
      "Epoch 305/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6570.1133 - mean_absolute_error: 78.9026\n",
      "Epoch 305: loss improved from 5943.47510 to 5914.87305, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5914.8730 - mean_absolute_error: 74.3986 - val_loss: 7799.6226 - val_mean_absolute_error: 88.0511\n",
      "Epoch 306/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5672.6523 - mean_absolute_error: 73.1356\n",
      "Epoch 306: loss improved from 5914.87305 to 5880.54834, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 5880.5483 - mean_absolute_error: 74.1599 - val_loss: 7762.0342 - val_mean_absolute_error: 87.8374\n",
      "Epoch 307/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6474.6758 - mean_absolute_error: 78.0148\n",
      "Epoch 307: loss improved from 5880.54834 to 5851.10693, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5851.1069 - mean_absolute_error: 73.9682 - val_loss: 7724.7217 - val_mean_absolute_error: 87.6247\n",
      "Epoch 308/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5347.1660 - mean_absolute_error: 70.7794\n",
      "Epoch 308: loss improved from 5851.10693 to 5819.59668, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5819.5967 - mean_absolute_error: 73.7573 - val_loss: 7687.4766 - val_mean_absolute_error: 87.4120\n",
      "Epoch 309/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5969.4316 - mean_absolute_error: 74.9166\n",
      "Epoch 309: loss improved from 5819.59668 to 5789.46875, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5789.4688 - mean_absolute_error: 73.5546 - val_loss: 7650.5352 - val_mean_absolute_error: 87.2004\n",
      "Epoch 310/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5503.5166 - mean_absolute_error: 71.5576\n",
      "Epoch 310: loss improved from 5789.46875 to 5758.18994, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5758.1899 - mean_absolute_error: 73.3406 - val_loss: 7613.9033 - val_mean_absolute_error: 86.9901\n",
      "Epoch 311/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6031.8745 - mean_absolute_error: 75.6059\n",
      "Epoch 311: loss improved from 5758.18994 to 5727.75000, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5727.7500 - mean_absolute_error: 73.1235 - val_loss: 7577.1440 - val_mean_absolute_error: 86.7786\n",
      "Epoch 312/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5834.4185 - mean_absolute_error: 73.8514\n",
      "Epoch 312: loss improved from 5727.75000 to 5691.90430, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5691.9043 - mean_absolute_error: 72.8822 - val_loss: 7540.7085 - val_mean_absolute_error: 86.5684\n",
      "Epoch 313/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6254.9971 - mean_absolute_error: 76.6723\n",
      "Epoch 313: loss improved from 5691.90430 to 5661.42822, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5661.4282 - mean_absolute_error: 72.6679 - val_loss: 7504.6475 - val_mean_absolute_error: 86.3599\n",
      "Epoch 314/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 6811.9658 - mean_absolute_error: 81.0980\n",
      "Epoch 314: loss improved from 5661.42822 to 5628.68018, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5628.6802 - mean_absolute_error: 72.4462 - val_loss: 7468.5068 - val_mean_absolute_error: 86.1504\n",
      "Epoch 315/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5592.3301 - mean_absolute_error: 71.8234\n",
      "Epoch 315: loss improved from 5628.68018 to 5601.67871, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5601.6787 - mean_absolute_error: 72.2634 - val_loss: 7432.6001 - val_mean_absolute_error: 85.9417\n",
      "Epoch 316/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5333.3994 - mean_absolute_error: 71.1553\n",
      "Epoch 316: loss improved from 5601.67871 to 5577.15430, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5577.1543 - mean_absolute_error: 72.0894 - val_loss: 7397.0610 - val_mean_absolute_error: 85.7347\n",
      "Epoch 317/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5954.4551 - mean_absolute_error: 75.0574\n",
      "Epoch 317: loss improved from 5577.15430 to 5538.70361, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5538.7036 - mean_absolute_error: 71.8205 - val_loss: 7361.0645 - val_mean_absolute_error: 85.5245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5419.0542 - mean_absolute_error: 71.1891\n",
      "Epoch 318: loss improved from 5538.70361 to 5510.91699, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5510.9170 - mean_absolute_error: 71.6292 - val_loss: 7325.4312 - val_mean_absolute_error: 85.3159\n",
      "Epoch 319/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4893.7207 - mean_absolute_error: 67.4977\n",
      "Epoch 319: loss improved from 5510.91699 to 5488.95752, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5488.9575 - mean_absolute_error: 71.4798 - val_loss: 7289.7241 - val_mean_absolute_error: 85.1064\n",
      "Epoch 320/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5646.1050 - mean_absolute_error: 72.6047\n",
      "Epoch 320: loss improved from 5488.95752 to 5456.22705, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5456.2271 - mean_absolute_error: 71.2600 - val_loss: 7254.1123 - val_mean_absolute_error: 84.8969\n",
      "Epoch 321/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5331.3223 - mean_absolute_error: 70.7215\n",
      "Epoch 321: loss improved from 5456.22705 to 5423.95459, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5423.9546 - mean_absolute_error: 71.0386 - val_loss: 7218.8457 - val_mean_absolute_error: 84.6890\n",
      "Epoch 322/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5675.1909 - mean_absolute_error: 72.4044\n",
      "Epoch 322: loss improved from 5423.95459 to 5393.61182, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5393.6118 - mean_absolute_error: 70.8037 - val_loss: 7183.7817 - val_mean_absolute_error: 84.4817\n",
      "Epoch 323/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5906.1099 - mean_absolute_error: 74.7103\n",
      "Epoch 323: loss improved from 5393.61182 to 5364.57373, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5364.5737 - mean_absolute_error: 70.6005 - val_loss: 7148.9150 - val_mean_absolute_error: 84.2751\n",
      "Epoch 324/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4905.4194 - mean_absolute_error: 67.8831\n",
      "Epoch 324: loss improved from 5364.57373 to 5334.88428, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5334.8843 - mean_absolute_error: 70.3943 - val_loss: 7114.0835 - val_mean_absolute_error: 84.0682\n",
      "Epoch 325/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4862.8091 - mean_absolute_error: 67.8829\n",
      "Epoch 325: loss improved from 5334.88428 to 5309.77051, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5309.7705 - mean_absolute_error: 70.2130 - val_loss: 7079.1606 - val_mean_absolute_error: 83.8602\n",
      "Epoch 326/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5446.6787 - mean_absolute_error: 71.9812\n",
      "Epoch 326: loss improved from 5309.77051 to 5276.95996, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5276.9600 - mean_absolute_error: 69.9740 - val_loss: 7044.3701 - val_mean_absolute_error: 83.6525\n",
      "Epoch 327/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4719.8184 - mean_absolute_error: 66.0322\n",
      "Epoch 327: loss improved from 5276.95996 to 5251.37891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5251.3789 - mean_absolute_error: 69.7930 - val_loss: 7009.9448 - val_mean_absolute_error: 83.4465\n",
      "Epoch 328/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5725.9521 - mean_absolute_error: 72.8800\n",
      "Epoch 328: loss improved from 5251.37891 to 5219.36523, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5219.3652 - mean_absolute_error: 69.5711 - val_loss: 6975.5581 - val_mean_absolute_error: 83.2402\n",
      "Epoch 329/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5922.3311 - mean_absolute_error: 74.8393\n",
      "Epoch 329: loss improved from 5219.36523 to 5188.68555, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5188.6855 - mean_absolute_error: 69.3467 - val_loss: 6941.0869 - val_mean_absolute_error: 83.0329\n",
      "Epoch 330/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5391.8086 - mean_absolute_error: 70.1394\n",
      "Epoch 330: loss improved from 5188.68555 to 5165.56543, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5165.5654 - mean_absolute_error: 69.1710 - val_loss: 6907.0762 - val_mean_absolute_error: 82.8278\n",
      "Epoch 331/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4860.3086 - mean_absolute_error: 67.3762\n",
      "Epoch 331: loss improved from 5165.56543 to 5135.77441, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5135.7744 - mean_absolute_error: 68.9575 - val_loss: 6873.1006 - val_mean_absolute_error: 82.6225\n",
      "Epoch 332/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4803.4414 - mean_absolute_error: 67.0233\n",
      "Epoch 332: loss improved from 5135.77441 to 5103.25732, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5103.2573 - mean_absolute_error: 68.7245 - val_loss: 6839.1592 - val_mean_absolute_error: 82.4168\n",
      "Epoch 333/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5664.0601 - mean_absolute_error: 73.0823\n",
      "Epoch 333: loss improved from 5103.25732 to 5077.91260, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 5077.9126 - mean_absolute_error: 68.5372 - val_loss: 6805.5654 - val_mean_absolute_error: 82.2128\n",
      "Epoch 334/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4815.6338 - mean_absolute_error: 66.8149\n",
      "Epoch 334: loss improved from 5077.91260 to 5050.00928, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5050.0093 - mean_absolute_error: 68.3393 - val_loss: 6772.1348 - val_mean_absolute_error: 82.0092\n",
      "Epoch 335/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5213.9067 - mean_absolute_error: 69.5861\n",
      "Epoch 335: loss improved from 5050.00928 to 5019.04980, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5019.0498 - mean_absolute_error: 68.1084 - val_loss: 6738.5845 - val_mean_absolute_error: 81.8044\n",
      "Epoch 336/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5199.8594 - mean_absolute_error: 68.9888\n",
      "Epoch 336: loss improved from 5019.04980 to 4991.93066, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4991.9307 - mean_absolute_error: 67.9176 - val_loss: 6705.0786 - val_mean_absolute_error: 81.5993\n",
      "Epoch 337/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4706.6865 - mean_absolute_error: 66.3448\n",
      "Epoch 337: loss improved from 4991.93066 to 4964.93066, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4964.9307 - mean_absolute_error: 67.7201 - val_loss: 6671.8110 - val_mean_absolute_error: 81.3952\n",
      "Epoch 338/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5254.1772 - mean_absolute_error: 69.5602\n",
      "Epoch 338: loss improved from 4964.93066 to 4938.52490, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4938.5249 - mean_absolute_error: 67.5225 - val_loss: 6638.7549 - val_mean_absolute_error: 81.1919\n",
      "Epoch 339/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5866.1021 - mean_absolute_error: 74.5373\n",
      "Epoch 339: loss improved from 4938.52490 to 4910.31885, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 4910.3188 - mean_absolute_error: 67.3054 - val_loss: 6605.7769 - val_mean_absolute_error: 80.9886\n",
      "Epoch 340/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4672.8320 - mean_absolute_error: 64.6513\n",
      "Epoch 340: loss improved from 4910.31885 to 4883.26611, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4883.2661 - mean_absolute_error: 67.1087 - val_loss: 6572.9165 - val_mean_absolute_error: 80.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5665.5361 - mean_absolute_error: 73.0387\n",
      "Epoch 341: loss improved from 4883.26611 to 4854.89502, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4854.8950 - mean_absolute_error: 66.8851 - val_loss: 6540.2065 - val_mean_absolute_error: 80.5828\n",
      "Epoch 342/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5332.1777 - mean_absolute_error: 70.6136\n",
      "Epoch 342: loss improved from 4854.89502 to 4828.90430, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4828.9043 - mean_absolute_error: 66.6955 - val_loss: 6507.6763 - val_mean_absolute_error: 80.3807\n",
      "Epoch 343/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4922.3110 - mean_absolute_error: 67.9762\n",
      "Epoch 343: loss improved from 4828.90430 to 4802.03174, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4802.0317 - mean_absolute_error: 66.4928 - val_loss: 6475.2739 - val_mean_absolute_error: 80.1789\n",
      "Epoch 344/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4552.4951 - mean_absolute_error: 64.5185\n",
      "Epoch 344: loss improved from 4802.03174 to 4775.19922, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4775.1992 - mean_absolute_error: 66.2997 - val_loss: 6442.9976 - val_mean_absolute_error: 79.9773\n",
      "Epoch 345/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4815.0566 - mean_absolute_error: 66.4781\n",
      "Epoch 345: loss improved from 4775.19922 to 4754.45361, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 4754.4536 - mean_absolute_error: 66.1375 - val_loss: 6410.7915 - val_mean_absolute_error: 79.7757\n",
      "Epoch 346/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4529.6802 - mean_absolute_error: 65.1038\n",
      "Epoch 346: loss improved from 4754.45361 to 4727.75977, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4727.7598 - mean_absolute_error: 65.9243 - val_loss: 6378.4395 - val_mean_absolute_error: 79.5727\n",
      "Epoch 347/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4330.7168 - mean_absolute_error: 62.9589\n",
      "Epoch 347: loss improved from 4727.75977 to 4699.00488, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4699.0049 - mean_absolute_error: 65.7135 - val_loss: 6346.3887 - val_mean_absolute_error: 79.3710\n",
      "Epoch 348/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 5690.4297 - mean_absolute_error: 72.8270\n",
      "Epoch 348: loss improved from 4699.00488 to 4670.91357, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4670.9136 - mean_absolute_error: 65.5044 - val_loss: 6314.5845 - val_mean_absolute_error: 79.1704\n",
      "Epoch 349/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4231.2627 - mean_absolute_error: 62.2889\n",
      "Epoch 349: loss improved from 4670.91357 to 4643.25293, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4643.2529 - mean_absolute_error: 65.2931 - val_loss: 6283.0532 - val_mean_absolute_error: 78.9711\n",
      "Epoch 350/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4332.9414 - mean_absolute_error: 63.2075\n",
      "Epoch 350: loss improved from 4643.25293 to 4614.75977, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4614.7598 - mean_absolute_error: 65.0729 - val_loss: 6251.5967 - val_mean_absolute_error: 78.7716\n",
      "Epoch 351/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4136.4907 - mean_absolute_error: 61.8698\n",
      "Epoch 351: loss improved from 4614.75977 to 4589.45264, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4589.4526 - mean_absolute_error: 64.8782 - val_loss: 6220.3286 - val_mean_absolute_error: 78.5729\n",
      "Epoch 352/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4103.2305 - mean_absolute_error: 61.2275\n",
      "Epoch 352: loss improved from 4589.45264 to 4564.06592, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4564.0659 - mean_absolute_error: 64.6945 - val_loss: 6188.5869 - val_mean_absolute_error: 78.3707\n",
      "Epoch 353/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4321.8965 - mean_absolute_error: 62.7228\n",
      "Epoch 353: loss improved from 4564.06592 to 4540.17773, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4540.1777 - mean_absolute_error: 64.5006 - val_loss: 6157.2144 - val_mean_absolute_error: 78.1703\n",
      "Epoch 354/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4527.3726 - mean_absolute_error: 64.4779\n",
      "Epoch 354: loss improved from 4540.17773 to 4511.15576, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4511.1558 - mean_absolute_error: 64.2760 - val_loss: 6126.2974 - val_mean_absolute_error: 77.9723\n",
      "Epoch 355/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4492.2822 - mean_absolute_error: 64.3891\n",
      "Epoch 355: loss improved from 4511.15576 to 4495.26758, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4495.2676 - mean_absolute_error: 64.1452 - val_loss: 6095.4302 - val_mean_absolute_error: 77.7741\n",
      "Epoch 356/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4290.9512 - mean_absolute_error: 63.3635\n",
      "Epoch 356: loss improved from 4495.26758 to 4460.71826, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4460.7183 - mean_absolute_error: 63.8842 - val_loss: 6064.7646 - val_mean_absolute_error: 77.5767\n",
      "Epoch 357/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4021.9338 - mean_absolute_error: 60.4746\n",
      "Epoch 357: loss improved from 4460.71826 to 4438.21387, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4438.2139 - mean_absolute_error: 63.6958 - val_loss: 6033.9019 - val_mean_absolute_error: 77.3775\n",
      "Epoch 358/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4943.7979 - mean_absolute_error: 67.6918\n",
      "Epoch 358: loss improved from 4438.21387 to 4410.73193, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 4410.7319 - mean_absolute_error: 63.4891 - val_loss: 6003.1641 - val_mean_absolute_error: 77.1786\n",
      "Epoch 359/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4201.1162 - mean_absolute_error: 62.4985\n",
      "Epoch 359: loss improved from 4410.73193 to 4385.76270, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4385.7627 - mean_absolute_error: 63.2914 - val_loss: 5973.1436 - val_mean_absolute_error: 76.9839\n",
      "Epoch 360/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4601.6235 - mean_absolute_error: 65.3989\n",
      "Epoch 360: loss improved from 4385.76270 to 4360.17334, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4360.1733 - mean_absolute_error: 63.0915 - val_loss: 5943.0117 - val_mean_absolute_error: 76.7879\n",
      "Epoch 361/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4554.3613 - mean_absolute_error: 64.4513\n",
      "Epoch 361: loss improved from 4360.17334 to 4335.33398, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4335.3340 - mean_absolute_error: 62.8973 - val_loss: 5912.7983 - val_mean_absolute_error: 76.5910\n",
      "Epoch 362/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4658.9214 - mean_absolute_error: 65.4589\n",
      "Epoch 362: loss improved from 4335.33398 to 4314.49854, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4314.4985 - mean_absolute_error: 62.7427 - val_loss: 5882.6421 - val_mean_absolute_error: 76.3938\n",
      "Epoch 363/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4814.2363 - mean_absolute_error: 66.4570\n",
      "Epoch 363: loss improved from 4314.49854 to 4289.82812, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4289.8281 - mean_absolute_error: 62.5166 - val_loss: 5852.4551 - val_mean_absolute_error: 76.1960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4428.8018 - mean_absolute_error: 63.2766\n",
      "Epoch 364: loss improved from 4289.82812 to 4265.95117, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4265.9512 - mean_absolute_error: 62.3284 - val_loss: 5822.4888 - val_mean_absolute_error: 75.9991\n",
      "Epoch 365/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4779.2378 - mean_absolute_error: 65.8481\n",
      "Epoch 365: loss improved from 4265.95117 to 4237.20654, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4237.2065 - mean_absolute_error: 62.1055 - val_loss: 5792.3589 - val_mean_absolute_error: 75.8006\n",
      "Epoch 366/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3575.6726 - mean_absolute_error: 55.8867\n",
      "Epoch 366: loss improved from 4237.20654 to 4214.69189, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 4214.6919 - mean_absolute_error: 61.9329 - val_loss: 5762.8286 - val_mean_absolute_error: 75.6056\n",
      "Epoch 367/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4371.8906 - mean_absolute_error: 62.4941\n",
      "Epoch 367: loss improved from 4214.69189 to 4188.28027, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4188.2803 - mean_absolute_error: 61.7169 - val_loss: 5733.1230 - val_mean_absolute_error: 75.4089\n",
      "Epoch 368/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4161.2202 - mean_absolute_error: 61.7377\n",
      "Epoch 368: loss improved from 4188.28027 to 4169.96289, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4169.9629 - mean_absolute_error: 61.5604 - val_loss: 5703.1436 - val_mean_absolute_error: 75.2098\n",
      "Epoch 369/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4160.7300 - mean_absolute_error: 61.7480\n",
      "Epoch 369: loss improved from 4169.96289 to 4140.66455, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4140.6646 - mean_absolute_error: 61.3251 - val_loss: 5673.5488 - val_mean_absolute_error: 75.0128\n",
      "Epoch 370/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4382.2207 - mean_absolute_error: 63.0726\n",
      "Epoch 370: loss improved from 4140.66455 to 4120.98242, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4120.9824 - mean_absolute_error: 61.1709 - val_loss: 5644.0986 - val_mean_absolute_error: 74.8163\n",
      "Epoch 371/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4602.3164 - mean_absolute_error: 64.9478\n",
      "Epoch 371: loss improved from 4120.98242 to 4091.72461, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4091.7246 - mean_absolute_error: 60.9140 - val_loss: 5614.6914 - val_mean_absolute_error: 74.6195\n",
      "Epoch 372/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3662.4565 - mean_absolute_error: 57.3875\n",
      "Epoch 372: loss improved from 4091.72461 to 4070.06958, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4070.0696 - mean_absolute_error: 60.7335 - val_loss: 5585.4204 - val_mean_absolute_error: 74.4231\n",
      "Epoch 373/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3987.7861 - mean_absolute_error: 59.7900\n",
      "Epoch 373: loss improved from 4070.06958 to 4043.23511, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4043.2351 - mean_absolute_error: 60.5181 - val_loss: 5556.3613 - val_mean_absolute_error: 74.2276\n",
      "Epoch 374/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4158.9639 - mean_absolute_error: 61.1437\n",
      "Epoch 374: loss improved from 4043.23511 to 4023.91870, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4023.9187 - mean_absolute_error: 60.3554 - val_loss: 5527.5649 - val_mean_absolute_error: 74.0334\n",
      "Epoch 375/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4007.4109 - mean_absolute_error: 60.2980\n",
      "Epoch 375: loss improved from 4023.91870 to 3999.21875, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3999.2188 - mean_absolute_error: 60.1692 - val_loss: 5499.2388 - val_mean_absolute_error: 73.8418\n",
      "Epoch 376/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4353.9683 - mean_absolute_error: 63.9047\n",
      "Epoch 376: loss improved from 3999.21875 to 3972.39136, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3972.3914 - mean_absolute_error: 59.9368 - val_loss: 5470.8984 - val_mean_absolute_error: 73.6497\n",
      "Epoch 377/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4300.3105 - mean_absolute_error: 62.8281\n",
      "Epoch 377: loss improved from 3972.39136 to 3952.41528, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3952.4153 - mean_absolute_error: 59.7657 - val_loss: 5442.3101 - val_mean_absolute_error: 73.4553\n",
      "Epoch 378/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3275.3562 - mean_absolute_error: 54.7127\n",
      "Epoch 378: loss improved from 3952.41528 to 3930.42993, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3930.4299 - mean_absolute_error: 59.5875 - val_loss: 5414.0381 - val_mean_absolute_error: 73.2626\n",
      "Epoch 379/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3311.0269 - mean_absolute_error: 54.1588\n",
      "Epoch 379: loss improved from 3930.42993 to 3906.79810, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3906.7981 - mean_absolute_error: 59.3891 - val_loss: 5385.8516 - val_mean_absolute_error: 73.0700\n",
      "Epoch 380/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3672.4536 - mean_absolute_error: 57.6870\n",
      "Epoch 380: loss improved from 3906.79810 to 3886.60498, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3886.6050 - mean_absolute_error: 59.2082 - val_loss: 5357.9043 - val_mean_absolute_error: 72.8785\n",
      "Epoch 381/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3038.4419 - mean_absolute_error: 51.4328\n",
      "Epoch 381: loss improved from 3886.60498 to 3865.93604, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3865.9360 - mean_absolute_error: 59.0307 - val_loss: 5329.8677 - val_mean_absolute_error: 72.6859\n",
      "Epoch 382/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3355.2925 - mean_absolute_error: 53.8657\n",
      "Epoch 382: loss improved from 3865.93604 to 3836.22949, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3836.2295 - mean_absolute_error: 58.7887 - val_loss: 5302.0908 - val_mean_absolute_error: 72.4946\n",
      "Epoch 383/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4101.6938 - mean_absolute_error: 61.4263\n",
      "Epoch 383: loss improved from 3836.22949 to 3814.65210, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3814.6521 - mean_absolute_error: 58.6087 - val_loss: 5274.3564 - val_mean_absolute_error: 72.3031\n",
      "Epoch 384/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2944.4282 - mean_absolute_error: 50.9163\n",
      "Epoch 384: loss improved from 3814.65210 to 3794.75806, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3794.7581 - mean_absolute_error: 58.4427 - val_loss: 5246.8774 - val_mean_absolute_error: 72.1128\n",
      "Epoch 385/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 4008.6826 - mean_absolute_error: 60.3329\n",
      "Epoch 385: loss improved from 3794.75806 to 3772.47559, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3772.4756 - mean_absolute_error: 58.2445 - val_loss: 5219.2314 - val_mean_absolute_error: 71.9208\n",
      "Epoch 386/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3483.5664 - mean_absolute_error: 56.3067\n",
      "Epoch 386: loss improved from 3772.47559 to 3749.09229, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3749.0923 - mean_absolute_error: 58.0410 - val_loss: 5191.3735 - val_mean_absolute_error: 71.7269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3929.5930 - mean_absolute_error: 59.0958\n",
      "Epoch 387: loss improved from 3749.09229 to 3726.89844, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3726.8984 - mean_absolute_error: 57.8536 - val_loss: 5163.6387 - val_mean_absolute_error: 71.5333\n",
      "Epoch 388/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3624.9707 - mean_absolute_error: 57.0243\n",
      "Epoch 388: loss improved from 3726.89844 to 3706.65503, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3706.6550 - mean_absolute_error: 57.6644 - val_loss: 5136.1650 - val_mean_absolute_error: 71.3410\n",
      "Epoch 389/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3842.5938 - mean_absolute_error: 58.7774\n",
      "Epoch 389: loss improved from 3706.65503 to 3681.60059, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3681.6006 - mean_absolute_error: 57.4600 - val_loss: 5109.3057 - val_mean_absolute_error: 71.1525\n",
      "Epoch 390/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3970.7781 - mean_absolute_error: 60.5469\n",
      "Epoch 390: loss improved from 3681.60059 to 3667.19214, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3667.1921 - mean_absolute_error: 57.3204 - val_loss: 5082.8062 - val_mean_absolute_error: 70.9661\n",
      "Epoch 391/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3469.3328 - mean_absolute_error: 56.5124\n",
      "Epoch 391: loss improved from 3667.19214 to 3638.43262, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3638.4326 - mean_absolute_error: 57.0859 - val_loss: 5056.2939 - val_mean_absolute_error: 70.7790\n",
      "Epoch 392/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3300.0596 - mean_absolute_error: 53.8707\n",
      "Epoch 392: loss improved from 3638.43262 to 3620.58350, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3620.5835 - mean_absolute_error: 56.9219 - val_loss: 5029.7329 - val_mean_absolute_error: 70.5911\n",
      "Epoch 393/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3403.1492 - mean_absolute_error: 55.1511\n",
      "Epoch 393: loss improved from 3620.58350 to 3597.50244, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3597.5024 - mean_absolute_error: 56.7252 - val_loss: 5003.1152 - val_mean_absolute_error: 70.4023\n",
      "Epoch 394/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3515.7219 - mean_absolute_error: 56.7724\n",
      "Epoch 394: loss improved from 3597.50244 to 3577.90820, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3577.9082 - mean_absolute_error: 56.5552 - val_loss: 4976.2896 - val_mean_absolute_error: 70.2116\n",
      "Epoch 395/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3381.4175 - mean_absolute_error: 55.4177\n",
      "Epoch 395: loss improved from 3577.90820 to 3553.10962, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3553.1096 - mean_absolute_error: 56.3279 - val_loss: 4950.0054 - val_mean_absolute_error: 70.0241\n",
      "Epoch 396/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3794.9983 - mean_absolute_error: 56.9453\n",
      "Epoch 396: loss improved from 3553.10962 to 3533.15063, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3533.1506 - mean_absolute_error: 56.1599 - val_loss: 4923.8545 - val_mean_absolute_error: 69.8372\n",
      "Epoch 397/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2989.9893 - mean_absolute_error: 50.4279\n",
      "Epoch 397: loss improved from 3533.15063 to 3508.84375, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3508.8438 - mean_absolute_error: 55.9422 - val_loss: 4897.7012 - val_mean_absolute_error: 69.6497\n",
      "Epoch 398/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3323.1733 - mean_absolute_error: 53.7829\n",
      "Epoch 398: loss improved from 3508.84375 to 3491.23560, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3491.2356 - mean_absolute_error: 55.7728 - val_loss: 4871.5811 - val_mean_absolute_error: 69.4619\n",
      "Epoch 399/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3246.3862 - mean_absolute_error: 53.3993\n",
      "Epoch 399: loss improved from 3491.23560 to 3469.55371, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3469.5537 - mean_absolute_error: 55.5841 - val_loss: 4845.6885 - val_mean_absolute_error: 69.2753\n",
      "Epoch 400/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3225.7583 - mean_absolute_error: 54.2736\n",
      "Epoch 400: loss improved from 3469.55371 to 3450.57251, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3450.5725 - mean_absolute_error: 55.4156 - val_loss: 4819.7939 - val_mean_absolute_error: 69.0881\n",
      "Epoch 401/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3341.4043 - mean_absolute_error: 53.1207\n",
      "Epoch 401: loss improved from 3450.57251 to 3426.76123, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3426.7612 - mean_absolute_error: 55.1939 - val_loss: 4793.5439 - val_mean_absolute_error: 68.8979\n",
      "Epoch 402/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3361.5464 - mean_absolute_error: 54.4353\n",
      "Epoch 402: loss improved from 3426.76123 to 3408.54980, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3408.5498 - mean_absolute_error: 55.0313 - val_loss: 4767.7065 - val_mean_absolute_error: 68.7101\n",
      "Epoch 403/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3187.3555 - mean_absolute_error: 53.5104\n",
      "Epoch 403: loss improved from 3408.54980 to 3391.90308, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3391.9031 - mean_absolute_error: 54.8864 - val_loss: 4742.0488 - val_mean_absolute_error: 68.5232\n",
      "Epoch 404/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3459.1614 - mean_absolute_error: 56.2516\n",
      "Epoch 404: loss improved from 3391.90308 to 3366.58911, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3366.5891 - mean_absolute_error: 54.6459 - val_loss: 4716.2012 - val_mean_absolute_error: 68.3343\n",
      "Epoch 405/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2710.4023 - mean_absolute_error: 48.0564\n",
      "Epoch 405: loss improved from 3366.58911 to 3347.79712, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3347.7971 - mean_absolute_error: 54.4836 - val_loss: 4690.7573 - val_mean_absolute_error: 68.1479\n",
      "Epoch 406/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3035.4751 - mean_absolute_error: 51.2566\n",
      "Epoch 406: loss improved from 3347.79712 to 3325.18213, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3325.1821 - mean_absolute_error: 54.2631 - val_loss: 4665.4590 - val_mean_absolute_error: 67.9620\n",
      "Epoch 407/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2856.5977 - mean_absolute_error: 50.2057\n",
      "Epoch 407: loss improved from 3325.18213 to 3304.26099, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 3304.2610 - mean_absolute_error: 54.0834 - val_loss: 4640.1914 - val_mean_absolute_error: 67.7759\n",
      "Epoch 408/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3318.3015 - mean_absolute_error: 53.6055\n",
      "Epoch 408: loss improved from 3304.26099 to 3285.46289, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3285.4629 - mean_absolute_error: 53.8996 - val_loss: 4615.1963 - val_mean_absolute_error: 67.5912\n",
      "Epoch 409/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3221.3037 - mean_absolute_error: 53.3977\n",
      "Epoch 409: loss improved from 3285.46289 to 3267.87012, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3267.8701 - mean_absolute_error: 53.7294 - val_loss: 4590.4678 - val_mean_absolute_error: 67.4080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2939.6428 - mean_absolute_error: 50.6871\n",
      "Epoch 410: loss improved from 3267.87012 to 3245.12842, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3245.1284 - mean_absolute_error: 53.5288 - val_loss: 4565.6396 - val_mean_absolute_error: 67.2236\n",
      "Epoch 411/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3455.0166 - mean_absolute_error: 53.9178\n",
      "Epoch 411: loss improved from 3245.12842 to 3227.32031, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3227.3203 - mean_absolute_error: 53.3631 - val_loss: 4540.7988 - val_mean_absolute_error: 67.0386\n",
      "Epoch 412/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3237.4160 - mean_absolute_error: 54.0402\n",
      "Epoch 412: loss improved from 3227.32031 to 3205.54224, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 3205.5422 - mean_absolute_error: 53.1517 - val_loss: 4515.9585 - val_mean_absolute_error: 66.8531\n",
      "Epoch 413/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3460.0793 - mean_absolute_error: 55.4184\n",
      "Epoch 413: loss improved from 3205.54224 to 3186.17041, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3186.1704 - mean_absolute_error: 52.9728 - val_loss: 4491.0767 - val_mean_absolute_error: 66.6667\n",
      "Epoch 414/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3040.6755 - mean_absolute_error: 51.3617\n",
      "Epoch 414: loss improved from 3186.17041 to 3164.68555, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3164.6855 - mean_absolute_error: 52.7708 - val_loss: 4466.6323 - val_mean_absolute_error: 66.4831\n",
      "Epoch 415/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3017.5437 - mean_absolute_error: 51.8056\n",
      "Epoch 415: loss improved from 3164.68555 to 3146.89355, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3146.8936 - mean_absolute_error: 52.6110 - val_loss: 4442.4038 - val_mean_absolute_error: 66.3007\n",
      "Epoch 416/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3615.6626 - mean_absolute_error: 56.7607\n",
      "Epoch 416: loss improved from 3146.89355 to 3131.95850, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3131.9585 - mean_absolute_error: 52.4566 - val_loss: 4418.3574 - val_mean_absolute_error: 66.1191\n",
      "Epoch 417/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3049.3198 - mean_absolute_error: 51.7170\n",
      "Epoch 417: loss improved from 3131.95850 to 3108.05957, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3108.0596 - mean_absolute_error: 52.2380 - val_loss: 4394.6113 - val_mean_absolute_error: 65.9393\n",
      "Epoch 418/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3447.0259 - mean_absolute_error: 54.6592\n",
      "Epoch 418: loss improved from 3108.05957 to 3088.45215, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3088.4521 - mean_absolute_error: 52.0438 - val_loss: 4370.6685 - val_mean_absolute_error: 65.7575\n",
      "Epoch 419/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3304.5566 - mean_absolute_error: 54.3306\n",
      "Epoch 419: loss improved from 3088.45215 to 3072.65039, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3072.6504 - mean_absolute_error: 51.8880 - val_loss: 4346.5898 - val_mean_absolute_error: 65.5741\n",
      "Epoch 420/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3074.7778 - mean_absolute_error: 51.6891\n",
      "Epoch 420: loss improved from 3072.65039 to 3055.37720, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3055.3772 - mean_absolute_error: 51.7286 - val_loss: 4323.0752 - val_mean_absolute_error: 65.3946\n",
      "Epoch 421/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2951.6689 - mean_absolute_error: 51.7091\n",
      "Epoch 421: loss improved from 3055.37720 to 3035.54321, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3035.5432 - mean_absolute_error: 51.5284 - val_loss: 4299.5737 - val_mean_absolute_error: 65.2146\n",
      "Epoch 422/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2934.9998 - mean_absolute_error: 50.0805\n",
      "Epoch 422: loss improved from 3035.54321 to 3014.21753, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3014.2175 - mean_absolute_error: 51.3305 - val_loss: 4276.2437 - val_mean_absolute_error: 65.0355\n",
      "Epoch 423/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3769.5593 - mean_absolute_error: 58.6646\n",
      "Epoch 423: loss improved from 3014.21753 to 3000.78662, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3000.7866 - mean_absolute_error: 51.1834 - val_loss: 4252.5996 - val_mean_absolute_error: 64.8535\n",
      "Epoch 424/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3238.4451 - mean_absolute_error: 53.0625\n",
      "Epoch 424: loss improved from 3000.78662 to 2982.27271, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2982.2727 - mean_absolute_error: 50.9966 - val_loss: 4229.4297 - val_mean_absolute_error: 64.6746\n",
      "Epoch 425/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3256.1670 - mean_absolute_error: 53.4382\n",
      "Epoch 425: loss improved from 2982.27271 to 2959.70630, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2959.7063 - mean_absolute_error: 50.7953 - val_loss: 4206.1802 - val_mean_absolute_error: 64.4946\n",
      "Epoch 426/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2373.1846 - mean_absolute_error: 44.7606\n",
      "Epoch 426: loss improved from 2959.70630 to 2940.53760, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2940.5376 - mean_absolute_error: 50.6017 - val_loss: 4182.8022 - val_mean_absolute_error: 64.3131\n",
      "Epoch 427/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2716.8906 - mean_absolute_error: 48.1402\n",
      "Epoch 427: loss improved from 2940.53760 to 2924.38916, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2924.3892 - mean_absolute_error: 50.4395 - val_loss: 4159.5044 - val_mean_absolute_error: 64.1317\n",
      "Epoch 428/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3102.5820 - mean_absolute_error: 50.9421\n",
      "Epoch 428: loss improved from 2924.38916 to 2904.19067, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2904.1907 - mean_absolute_error: 50.2393 - val_loss: 4136.4092 - val_mean_absolute_error: 63.9514\n",
      "Epoch 429/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3569.4917 - mean_absolute_error: 57.0057\n",
      "Epoch 429: loss improved from 2904.19067 to 2889.14722, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2889.1472 - mean_absolute_error: 50.0839 - val_loss: 4113.4648 - val_mean_absolute_error: 63.7718\n",
      "Epoch 430/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2862.0703 - mean_absolute_error: 49.7788\n",
      "Epoch 430: loss improved from 2889.14722 to 2868.47168, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2868.4717 - mean_absolute_error: 49.8860 - val_loss: 4090.8279 - val_mean_absolute_error: 63.5940\n",
      "Epoch 431/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2727.9863 - mean_absolute_error: 47.8329\n",
      "Epoch 431: loss improved from 2868.47168 to 2855.34790, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2855.3479 - mean_absolute_error: 49.7382 - val_loss: 4068.0203 - val_mean_absolute_error: 63.4145\n",
      "Epoch 432/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2447.9199 - mean_absolute_error: 45.5529\n",
      "Epoch 432: loss improved from 2855.34790 to 2835.50122, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2835.5012 - mean_absolute_error: 49.5492 - val_loss: 4045.4280 - val_mean_absolute_error: 63.2361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2783.1941 - mean_absolute_error: 48.1682\n",
      "Epoch 433: loss improved from 2835.50122 to 2818.00000, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2818.0000 - mean_absolute_error: 49.3638 - val_loss: 4022.6763 - val_mean_absolute_error: 63.0559\n",
      "Epoch 434/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2821.2109 - mean_absolute_error: 48.5182\n",
      "Epoch 434: loss improved from 2818.00000 to 2799.41528, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2799.4153 - mean_absolute_error: 49.1820 - val_loss: 4000.0889 - val_mean_absolute_error: 62.8766\n",
      "Epoch 435/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2916.8574 - mean_absolute_error: 50.1413\n",
      "Epoch 435: loss improved from 2799.41528 to 2783.28223, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2783.2822 - mean_absolute_error: 49.0153 - val_loss: 3977.3162 - val_mean_absolute_error: 62.6952\n",
      "Epoch 436/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2536.6125 - mean_absolute_error: 46.6186\n",
      "Epoch 436: loss improved from 2783.28223 to 2762.30688, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2762.3069 - mean_absolute_error: 48.8071 - val_loss: 3954.9883 - val_mean_absolute_error: 62.5169\n",
      "Epoch 437/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2334.1262 - mean_absolute_error: 44.8495\n",
      "Epoch 437: loss improved from 2762.30688 to 2743.81177, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2743.8118 - mean_absolute_error: 48.6233 - val_loss: 3932.4988 - val_mean_absolute_error: 62.3368\n",
      "Epoch 438/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3280.1941 - mean_absolute_error: 54.8718\n",
      "Epoch 438: loss improved from 2743.81177 to 2729.00708, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2729.0071 - mean_absolute_error: 48.4701 - val_loss: 3910.2454 - val_mean_absolute_error: 62.1580\n",
      "Epoch 439/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2321.6162 - mean_absolute_error: 43.8528\n",
      "Epoch 439: loss improved from 2729.00708 to 2715.41626, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2715.4163 - mean_absolute_error: 48.3345 - val_loss: 3887.9836 - val_mean_absolute_error: 61.9787\n",
      "Epoch 440/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2745.4331 - mean_absolute_error: 48.4842\n",
      "Epoch 440: loss improved from 2715.41626 to 2696.35083, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2696.3508 - mean_absolute_error: 48.1157 - val_loss: 3865.8831 - val_mean_absolute_error: 61.8001\n",
      "Epoch 441/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2900.8103 - mean_absolute_error: 50.2399\n",
      "Epoch 441: loss improved from 2696.35083 to 2677.60815, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2677.6082 - mean_absolute_error: 47.9323 - val_loss: 3844.0303 - val_mean_absolute_error: 61.6231\n",
      "Epoch 442/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2282.2629 - mean_absolute_error: 44.0955\n",
      "Epoch 442: loss improved from 2677.60815 to 2659.28491, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2659.2849 - mean_absolute_error: 47.7529 - val_loss: 3822.3530 - val_mean_absolute_error: 61.4469\n",
      "Epoch 443/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2838.1636 - mean_absolute_error: 49.1133\n",
      "Epoch 443: loss improved from 2659.28491 to 2645.26318, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2645.2632 - mean_absolute_error: 47.5879 - val_loss: 3800.5037 - val_mean_absolute_error: 61.2689\n",
      "Epoch 444/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2835.9854 - mean_absolute_error: 49.2662\n",
      "Epoch 444: loss improved from 2645.26318 to 2626.46729, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2626.4673 - mean_absolute_error: 47.3967 - val_loss: 3778.6619 - val_mean_absolute_error: 61.0904\n",
      "Epoch 445/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2419.6777 - mean_absolute_error: 44.9187\n",
      "Epoch 445: loss improved from 2626.46729 to 2608.61426, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2608.6143 - mean_absolute_error: 47.2095 - val_loss: 3757.0261 - val_mean_absolute_error: 60.9131\n",
      "Epoch 446/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2923.8340 - mean_absolute_error: 51.0840\n",
      "Epoch 446: loss improved from 2608.61426 to 2593.71167, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2593.7117 - mean_absolute_error: 47.0448 - val_loss: 3735.4431 - val_mean_absolute_error: 60.7356\n",
      "Epoch 447/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2703.1233 - mean_absolute_error: 48.0483\n",
      "Epoch 447: loss improved from 2593.71167 to 2575.12793, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2575.1279 - mean_absolute_error: 46.8573 - val_loss: 3714.3376 - val_mean_absolute_error: 60.5616\n",
      "Epoch 448/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 3305.4917 - mean_absolute_error: 55.6145\n",
      "Epoch 448: loss improved from 2575.12793 to 2558.40137, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2558.4014 - mean_absolute_error: 46.6818 - val_loss: 3693.2285 - val_mean_absolute_error: 60.3871\n",
      "Epoch 449/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2117.1487 - mean_absolute_error: 41.7105\n",
      "Epoch 449: loss improved from 2558.40137 to 2542.54883, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2542.5488 - mean_absolute_error: 46.5028 - val_loss: 3672.2788 - val_mean_absolute_error: 60.2134\n",
      "Epoch 450/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2481.5298 - mean_absolute_error: 46.6743\n",
      "Epoch 450: loss improved from 2542.54883 to 2527.43604, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2527.4360 - mean_absolute_error: 46.3349 - val_loss: 3650.9829 - val_mean_absolute_error: 60.0363\n",
      "Epoch 451/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2255.5662 - mean_absolute_error: 44.5475\n",
      "Epoch 451: loss improved from 2527.43604 to 2511.89380, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2511.8938 - mean_absolute_error: 46.1799 - val_loss: 3630.0061 - val_mean_absolute_error: 59.8613\n",
      "Epoch 452/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2532.9116 - mean_absolute_error: 46.3409\n",
      "Epoch 452: loss improved from 2511.89380 to 2494.14624, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2494.1462 - mean_absolute_error: 45.9788 - val_loss: 3609.4749 - val_mean_absolute_error: 59.6896\n",
      "Epoch 453/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2794.5632 - mean_absolute_error: 49.6775\n",
      "Epoch 453: loss improved from 2494.14624 to 2478.57593, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2478.5759 - mean_absolute_error: 45.8200 - val_loss: 3588.5762 - val_mean_absolute_error: 59.5143\n",
      "Epoch 454/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2415.8467 - mean_absolute_error: 45.3792\n",
      "Epoch 454: loss improved from 2478.57593 to 2460.92676, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2460.9268 - mean_absolute_error: 45.6169 - val_loss: 3568.1995 - val_mean_absolute_error: 59.3429\n",
      "Epoch 455/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2109.6252 - mean_absolute_error: 41.9535\n",
      "Epoch 455: loss improved from 2460.92676 to 2445.51709, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2445.5171 - mean_absolute_error: 45.4552 - val_loss: 3547.7869 - val_mean_absolute_error: 59.1706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2103.1731 - mean_absolute_error: 40.8110\n",
      "Epoch 456: loss improved from 2445.51709 to 2430.39087, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2430.3909 - mean_absolute_error: 45.2817 - val_loss: 3527.3628 - val_mean_absolute_error: 58.9978\n",
      "Epoch 457/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2009.3511 - mean_absolute_error: 41.1302\n",
      "Epoch 457: loss improved from 2430.39087 to 2414.96411, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2414.9641 - mean_absolute_error: 45.1338 - val_loss: 3507.0383 - val_mean_absolute_error: 58.8253\n",
      "Epoch 458/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2529.6973 - mean_absolute_error: 46.6671\n",
      "Epoch 458: loss improved from 2414.96411 to 2403.27075, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2403.2708 - mean_absolute_error: 44.9775 - val_loss: 3486.8057 - val_mean_absolute_error: 58.6531\n",
      "Epoch 459/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2537.5386 - mean_absolute_error: 46.7513\n",
      "Epoch 459: loss improved from 2403.27075 to 2384.56396, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2384.5640 - mean_absolute_error: 44.7753 - val_loss: 3466.9932 - val_mean_absolute_error: 58.4839\n",
      "Epoch 460/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2042.1113 - mean_absolute_error: 41.0188\n",
      "Epoch 460: loss improved from 2384.56396 to 2370.17334, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2370.1733 - mean_absolute_error: 44.6050 - val_loss: 3447.2544 - val_mean_absolute_error: 58.3149\n",
      "Epoch 461/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2539.8425 - mean_absolute_error: 45.9289\n",
      "Epoch 461: loss improved from 2370.17334 to 2354.11255, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2354.1125 - mean_absolute_error: 44.4397 - val_loss: 3427.7874 - val_mean_absolute_error: 58.1478\n",
      "Epoch 462/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2197.7402 - mean_absolute_error: 42.2646\n",
      "Epoch 462: loss improved from 2354.11255 to 2341.23730, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2341.2373 - mean_absolute_error: 44.2863 - val_loss: 3408.1357 - val_mean_absolute_error: 57.9785\n",
      "Epoch 463/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2144.4771 - mean_absolute_error: 41.3763\n",
      "Epoch 463: loss improved from 2341.23730 to 2323.32080, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2323.3208 - mean_absolute_error: 44.0885 - val_loss: 3388.1594 - val_mean_absolute_error: 57.8060\n",
      "Epoch 464/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2577.8730 - mean_absolute_error: 47.3460\n",
      "Epoch 464: loss improved from 2323.32080 to 2312.43384, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2312.4338 - mean_absolute_error: 43.9442 - val_loss: 3368.3340 - val_mean_absolute_error: 57.6343\n",
      "Epoch 465/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1884.3804 - mean_absolute_error: 39.3370\n",
      "Epoch 465: loss improved from 2312.43384 to 2293.61011, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2293.6101 - mean_absolute_error: 43.7560 - val_loss: 3348.9893 - val_mean_absolute_error: 57.4662\n",
      "Epoch 466/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2511.5034 - mean_absolute_error: 47.5268\n",
      "Epoch 466: loss improved from 2293.61011 to 2280.82886, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2280.8289 - mean_absolute_error: 43.5883 - val_loss: 3329.4614 - val_mean_absolute_error: 57.2960\n",
      "Epoch 467/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2516.3923 - mean_absolute_error: 46.7834\n",
      "Epoch 467: loss improved from 2280.82886 to 2264.67603, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2264.6760 - mean_absolute_error: 43.4190 - val_loss: 3309.8025 - val_mean_absolute_error: 57.1242\n",
      "Epoch 468/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2258.6104 - mean_absolute_error: 43.6531\n",
      "Epoch 468: loss improved from 2264.67603 to 2249.39258, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2249.3926 - mean_absolute_error: 43.2321 - val_loss: 3290.1960 - val_mean_absolute_error: 56.9524\n",
      "Epoch 469/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2254.9937 - mean_absolute_error: 43.8282\n",
      "Epoch 469: loss improved from 2249.39258 to 2235.56567, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2235.5657 - mean_absolute_error: 43.0708 - val_loss: 3270.8757 - val_mean_absolute_error: 56.7825\n",
      "Epoch 470/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2156.7817 - mean_absolute_error: 43.2887\n",
      "Epoch 470: loss improved from 2235.56567 to 2220.31885, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2220.3188 - mean_absolute_error: 42.9041 - val_loss: 3251.4504 - val_mean_absolute_error: 56.6112\n",
      "Epoch 471/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2257.2563 - mean_absolute_error: 44.7144\n",
      "Epoch 471: loss improved from 2220.31885 to 2204.54199, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2204.5420 - mean_absolute_error: 42.7195 - val_loss: 3231.8730 - val_mean_absolute_error: 56.4380\n",
      "Epoch 472/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2380.4648 - mean_absolute_error: 45.0370\n",
      "Epoch 472: loss improved from 2204.54199 to 2192.67456, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2192.6746 - mean_absolute_error: 42.5721 - val_loss: 3212.4463 - val_mean_absolute_error: 56.2656\n",
      "Epoch 473/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2048.4685 - mean_absolute_error: 41.4676\n",
      "Epoch 473: loss improved from 2192.67456 to 2180.78467, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2180.7847 - mean_absolute_error: 42.4137 - val_loss: 3193.3586 - val_mean_absolute_error: 56.0958\n",
      "Epoch 474/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2615.1357 - mean_absolute_error: 47.9007\n",
      "Epoch 474: loss improved from 2180.78467 to 2162.54321, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2162.5432 - mean_absolute_error: 42.2157 - val_loss: 3174.4099 - val_mean_absolute_error: 55.9266\n",
      "Epoch 475/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2191.5146 - mean_absolute_error: 42.8537\n",
      "Epoch 475: loss improved from 2162.54321 to 2148.81470, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2148.8147 - mean_absolute_error: 42.0504 - val_loss: 3155.7959 - val_mean_absolute_error: 55.7599\n",
      "Epoch 476/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1911.5039 - mean_absolute_error: 38.0930\n",
      "Epoch 476: loss improved from 2148.81470 to 2133.69971, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2133.6997 - mean_absolute_error: 41.8781 - val_loss: 3137.4050 - val_mean_absolute_error: 55.5948\n",
      "Epoch 477/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2250.2466 - mean_absolute_error: 43.2768\n",
      "Epoch 477: loss improved from 2133.69971 to 2121.95435, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2121.9543 - mean_absolute_error: 41.7329 - val_loss: 3118.8147 - val_mean_absolute_error: 55.4273\n",
      "Epoch 478/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1786.9792 - mean_absolute_error: 38.0328\n",
      "Epoch 478: loss improved from 2121.95435 to 2107.84717, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2107.8472 - mean_absolute_error: 41.5578 - val_loss: 3100.3093 - val_mean_absolute_error: 55.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2168.2214 - mean_absolute_error: 42.4537\n",
      "Epoch 479: loss improved from 2107.84717 to 2092.57227, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2092.5723 - mean_absolute_error: 41.3861 - val_loss: 3081.9907 - val_mean_absolute_error: 55.0942\n",
      "Epoch 480/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2101.8970 - mean_absolute_error: 41.2174\n",
      "Epoch 480: loss improved from 2092.57227 to 2081.95874, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2081.9587 - mean_absolute_error: 41.2448 - val_loss: 3063.4932 - val_mean_absolute_error: 54.9260\n",
      "Epoch 481/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1765.1173 - mean_absolute_error: 36.7025\n",
      "Epoch 481: loss improved from 2081.95874 to 2066.16895, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2066.1689 - mean_absolute_error: 41.0550 - val_loss: 3045.4639 - val_mean_absolute_error: 54.7617\n",
      "Epoch 482/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2107.3154 - mean_absolute_error: 41.4314\n",
      "Epoch 482: loss improved from 2066.16895 to 2053.87695, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2053.8770 - mean_absolute_error: 40.8989 - val_loss: 3027.4932 - val_mean_absolute_error: 54.5973\n",
      "Epoch 483/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1693.1833 - mean_absolute_error: 36.2643\n",
      "Epoch 483: loss improved from 2053.87695 to 2039.08923, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2039.0892 - mean_absolute_error: 40.7229 - val_loss: 3009.4368 - val_mean_absolute_error: 54.4317\n",
      "Epoch 484/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2074.6243 - mean_absolute_error: 41.3917\n",
      "Epoch 484: loss improved from 2039.08923 to 2025.94922, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2025.9492 - mean_absolute_error: 40.5637 - val_loss: 2991.3523 - val_mean_absolute_error: 54.2653\n",
      "Epoch 485/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2206.6865 - mean_absolute_error: 43.3815\n",
      "Epoch 485: loss improved from 2025.94922 to 2010.58826, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2010.5883 - mean_absolute_error: 40.3852 - val_loss: 2973.7905 - val_mean_absolute_error: 54.1033\n",
      "Epoch 486/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2371.8433 - mean_absolute_error: 45.6892\n",
      "Epoch 486: loss improved from 2010.58826 to 1998.70752, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1998.7075 - mean_absolute_error: 40.2402 - val_loss: 2956.0361 - val_mean_absolute_error: 53.9390\n",
      "Epoch 487/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1760.6819 - mean_absolute_error: 37.9498\n",
      "Epoch 487: loss improved from 1998.70752 to 1983.17859, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1983.1786 - mean_absolute_error: 40.0505 - val_loss: 2938.6069 - val_mean_absolute_error: 53.7772\n",
      "Epoch 488/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1756.0387 - mean_absolute_error: 35.5090\n",
      "Epoch 488: loss improved from 1983.17859 to 1972.93372, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1972.9337 - mean_absolute_error: 39.9234 - val_loss: 2921.1692 - val_mean_absolute_error: 53.6148\n",
      "Epoch 489/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1921.7228 - mean_absolute_error: 38.1624\n",
      "Epoch 489: loss improved from 1972.93372 to 1960.09045, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1960.0905 - mean_absolute_error: 39.7470 - val_loss: 2903.4731 - val_mean_absolute_error: 53.4495\n",
      "Epoch 490/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1822.3054 - mean_absolute_error: 39.1868\n",
      "Epoch 490: loss improved from 1960.09045 to 1948.85364, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1948.8536 - mean_absolute_error: 39.5980 - val_loss: 2885.7751 - val_mean_absolute_error: 53.2837\n",
      "Epoch 491/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1725.9506 - mean_absolute_error: 36.3670\n",
      "Epoch 491: loss improved from 1948.85364 to 1932.05432, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1932.0543 - mean_absolute_error: 39.4035 - val_loss: 2868.3586 - val_mean_absolute_error: 53.1200\n",
      "Epoch 492/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2221.6487 - mean_absolute_error: 43.6657\n",
      "Epoch 492: loss improved from 1932.05432 to 1919.16052, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1919.1605 - mean_absolute_error: 39.2454 - val_loss: 2851.0293 - val_mean_absolute_error: 52.9566\n",
      "Epoch 493/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1887.6833 - mean_absolute_error: 38.8226\n",
      "Epoch 493: loss improved from 1919.16052 to 1907.95312, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1907.9531 - mean_absolute_error: 39.1081 - val_loss: 2833.9578 - val_mean_absolute_error: 52.7952\n",
      "Epoch 494/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2031.6172 - mean_absolute_error: 40.3744\n",
      "Epoch 494: loss improved from 1907.95312 to 1896.15222, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1896.1522 - mean_absolute_error: 38.9378 - val_loss: 2817.0232 - val_mean_absolute_error: 52.6346\n",
      "Epoch 495/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2098.3887 - mean_absolute_error: 41.2737\n",
      "Epoch 495: loss improved from 1896.15222 to 1884.18652, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1884.1865 - mean_absolute_error: 38.7879 - val_loss: 2800.1848 - val_mean_absolute_error: 52.4744\n",
      "Epoch 496/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2103.2031 - mean_absolute_error: 42.2919\n",
      "Epoch 496: loss improved from 1884.18652 to 1870.82275, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1870.8228 - mean_absolute_error: 38.6392 - val_loss: 2783.4038 - val_mean_absolute_error: 52.3142\n",
      "Epoch 497/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1780.1570 - mean_absolute_error: 36.0031\n",
      "Epoch 497: loss improved from 1870.82275 to 1855.88623, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1855.8862 - mean_absolute_error: 38.4460 - val_loss: 2766.5610 - val_mean_absolute_error: 52.1530\n",
      "Epoch 498/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1922.9978 - mean_absolute_error: 38.9377\n",
      "Epoch 498: loss improved from 1855.88623 to 1846.06421, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1846.0642 - mean_absolute_error: 38.3202 - val_loss: 2749.7102 - val_mean_absolute_error: 51.9912\n",
      "Epoch 499/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1834.7339 - mean_absolute_error: 37.9209\n",
      "Epoch 499: loss improved from 1846.06421 to 1835.37659, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1835.3766 - mean_absolute_error: 38.1813 - val_loss: 2732.9558 - val_mean_absolute_error: 51.8298\n",
      "Epoch 500/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1912.9207 - mean_absolute_error: 40.2044\n",
      "Epoch 500: loss improved from 1835.37659 to 1822.52246, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1822.5225 - mean_absolute_error: 38.0252 - val_loss: 2716.3616 - val_mean_absolute_error: 51.6695\n",
      "Epoch 501/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1730.1754 - mean_absolute_error: 38.7837\n",
      "Epoch 501: loss improved from 1822.52246 to 1808.49316, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1808.4932 - mean_absolute_error: 37.8386 - val_loss: 2699.9136 - val_mean_absolute_error: 51.5101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1884.5476 - mean_absolute_error: 38.0917\n",
      "Epoch 502: loss improved from 1808.49316 to 1805.17859, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1805.1786 - mean_absolute_error: 37.7529 - val_loss: 2683.8186 - val_mean_absolute_error: 51.3536\n",
      "Epoch 503/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1864.3940 - mean_absolute_error: 39.2693\n",
      "Epoch 503: loss improved from 1805.17859 to 1785.94678, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1785.9468 - mean_absolute_error: 37.5717 - val_loss: 2667.6550 - val_mean_absolute_error: 51.1960\n",
      "Epoch 504/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2287.7292 - mean_absolute_error: 44.6148\n",
      "Epoch 504: loss improved from 1785.94678 to 1775.18677, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1775.1868 - mean_absolute_error: 37.4200 - val_loss: 2651.3621 - val_mean_absolute_error: 51.0366\n",
      "Epoch 505/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1617.2765 - mean_absolute_error: 34.3259\n",
      "Epoch 505: loss improved from 1775.18677 to 1761.79468, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1761.7947 - mean_absolute_error: 37.2452 - val_loss: 2635.4456 - val_mean_absolute_error: 50.8805\n",
      "Epoch 506/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1484.5234 - mean_absolute_error: 32.9387\n",
      "Epoch 506: loss improved from 1761.79468 to 1749.72839, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1749.7284 - mean_absolute_error: 37.1004 - val_loss: 2619.4148 - val_mean_absolute_error: 50.7227\n",
      "Epoch 507/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1757.9421 - mean_absolute_error: 36.8897\n",
      "Epoch 507: loss improved from 1749.72839 to 1739.08105, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1739.0811 - mean_absolute_error: 36.9455 - val_loss: 2603.4700 - val_mean_absolute_error: 50.5653\n",
      "Epoch 508/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1608.1783 - mean_absolute_error: 35.8896\n",
      "Epoch 508: loss improved from 1739.08105 to 1724.92090, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1724.9209 - mean_absolute_error: 36.7745 - val_loss: 2587.5925 - val_mean_absolute_error: 50.4080\n",
      "Epoch 509/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1703.5098 - mean_absolute_error: 35.6254\n",
      "Epoch 509: loss improved from 1724.92090 to 1713.52856, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1713.5286 - mean_absolute_error: 36.6262 - val_loss: 2571.9426 - val_mean_absolute_error: 50.2525\n",
      "Epoch 510/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1696.9622 - mean_absolute_error: 37.1102\n",
      "Epoch 510: loss improved from 1713.52856 to 1705.68591, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1705.6859 - mean_absolute_error: 36.5068 - val_loss: 2556.1990 - val_mean_absolute_error: 50.0956\n",
      "Epoch 511/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2051.5398 - mean_absolute_error: 41.0863\n",
      "Epoch 511: loss improved from 1705.68591 to 1694.63855, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1694.6385 - mean_absolute_error: 36.3564 - val_loss: 2540.5256 - val_mean_absolute_error: 49.9390\n",
      "Epoch 512/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1630.9048 - mean_absolute_error: 35.0589\n",
      "Epoch 512: loss improved from 1694.63855 to 1678.94568, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1678.9457 - mean_absolute_error: 36.1698 - val_loss: 2525.0293 - val_mean_absolute_error: 49.7836\n",
      "Epoch 513/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 2247.1462 - mean_absolute_error: 42.7475\n",
      "Epoch 513: loss improved from 1678.94568 to 1670.43994, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1670.4399 - mean_absolute_error: 36.0523 - val_loss: 2509.6753 - val_mean_absolute_error: 49.6291\n",
      "Epoch 514/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1853.2717 - mean_absolute_error: 37.5015\n",
      "Epoch 514: loss improved from 1670.43994 to 1660.49670, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1660.4967 - mean_absolute_error: 35.9112 - val_loss: 2494.5408 - val_mean_absolute_error: 49.4764\n",
      "Epoch 515/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1894.8289 - mean_absolute_error: 38.4621\n",
      "Epoch 515: loss improved from 1660.49670 to 1648.64404, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1648.6440 - mean_absolute_error: 35.7520 - val_loss: 2479.4937 - val_mean_absolute_error: 49.3241\n",
      "Epoch 516/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1932.3687 - mean_absolute_error: 38.7805\n",
      "Epoch 516: loss improved from 1648.64404 to 1635.81104, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1635.8110 - mean_absolute_error: 35.5921 - val_loss: 2464.3638 - val_mean_absolute_error: 49.1705\n",
      "Epoch 517/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1463.4751 - mean_absolute_error: 32.9309\n",
      "Epoch 517: loss improved from 1635.81104 to 1625.35583, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1625.3558 - mean_absolute_error: 35.4511 - val_loss: 2449.1960 - val_mean_absolute_error: 49.0160\n",
      "Epoch 518/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1575.7504 - mean_absolute_error: 34.2450\n",
      "Epoch 518: loss improved from 1625.35583 to 1615.64734, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1615.6473 - mean_absolute_error: 35.3090 - val_loss: 2434.0537 - val_mean_absolute_error: 48.8613\n",
      "Epoch 519/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1482.9087 - mean_absolute_error: 33.9036\n",
      "Epoch 519: loss improved from 1615.64734 to 1604.24280, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1604.2428 - mean_absolute_error: 35.1578 - val_loss: 2418.9321 - val_mean_absolute_error: 48.7063\n",
      "Epoch 520/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1763.4189 - mean_absolute_error: 35.6309\n",
      "Epoch 520: loss improved from 1604.24280 to 1593.96704, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1593.9670 - mean_absolute_error: 35.0136 - val_loss: 2403.8201 - val_mean_absolute_error: 48.5510\n",
      "Epoch 521/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1583.3998 - mean_absolute_error: 33.9924\n",
      "Epoch 521: loss improved from 1593.96704 to 1583.22339, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1583.2234 - mean_absolute_error: 34.8734 - val_loss: 2388.6990 - val_mean_absolute_error: 48.3950\n",
      "Epoch 522/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1479.6099 - mean_absolute_error: 31.9496\n",
      "Epoch 522: loss improved from 1583.22339 to 1571.32629, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1571.3263 - mean_absolute_error: 34.7141 - val_loss: 2373.6074 - val_mean_absolute_error: 48.2388\n",
      "Epoch 523/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1617.5238 - mean_absolute_error: 34.7441\n",
      "Epoch 523: loss improved from 1571.32629 to 1561.46985, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1561.4698 - mean_absolute_error: 34.5870 - val_loss: 2358.8374 - val_mean_absolute_error: 48.0855\n",
      "Epoch 524/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1499.6973 - mean_absolute_error: 33.8650\n",
      "Epoch 524: loss improved from 1561.46985 to 1549.63684, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1549.6368 - mean_absolute_error: 34.4317 - val_loss: 2344.2637 - val_mean_absolute_error: 47.9337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1653.4531 - mean_absolute_error: 36.7795\n",
      "Epoch 525: loss improved from 1549.63684 to 1540.92810, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1540.9281 - mean_absolute_error: 34.3200 - val_loss: 2329.5989 - val_mean_absolute_error: 47.7805\n",
      "Epoch 526/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1623.4800 - mean_absolute_error: 35.7443\n",
      "Epoch 526: loss improved from 1540.92810 to 1530.79395, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1530.7939 - mean_absolute_error: 34.1817 - val_loss: 2315.0425 - val_mean_absolute_error: 47.6279\n",
      "Epoch 527/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1839.8474 - mean_absolute_error: 38.7592\n",
      "Epoch 527: loss improved from 1530.79395 to 1518.59924, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1518.5992 - mean_absolute_error: 34.0175 - val_loss: 2300.5193 - val_mean_absolute_error: 47.4752\n",
      "Epoch 528/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1661.4924 - mean_absolute_error: 36.7005\n",
      "Epoch 528: loss improved from 1518.59924 to 1509.11475, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1509.1147 - mean_absolute_error: 33.9010 - val_loss: 2286.2693 - val_mean_absolute_error: 47.3249\n",
      "Epoch 529/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1545.9965 - mean_absolute_error: 34.5471\n",
      "Epoch 529: loss improved from 1509.11475 to 1498.68982, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1498.6898 - mean_absolute_error: 33.7461 - val_loss: 2272.1729 - val_mean_absolute_error: 47.1757\n",
      "Epoch 530/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1445.9495 - mean_absolute_error: 34.3531\n",
      "Epoch 530: loss improved from 1498.68982 to 1489.34045, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1489.3405 - mean_absolute_error: 33.6214 - val_loss: 2257.6914 - val_mean_absolute_error: 47.0220\n",
      "Epoch 531/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1405.8170 - mean_absolute_error: 33.2349\n",
      "Epoch 531: loss improved from 1489.34045 to 1477.76831, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1477.7683 - mean_absolute_error: 33.4730 - val_loss: 2243.7168 - val_mean_absolute_error: 46.8731\n",
      "Epoch 532/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1681.4961 - mean_absolute_error: 35.7813\n",
      "Epoch 532: loss improved from 1477.76831 to 1469.05090, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1469.0509 - mean_absolute_error: 33.3457 - val_loss: 2229.5110 - val_mean_absolute_error: 46.7214\n",
      "Epoch 533/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1135.9934 - mean_absolute_error: 29.3794\n",
      "Epoch 533: loss improved from 1469.05090 to 1459.79810, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1459.7981 - mean_absolute_error: 33.2318 - val_loss: 2215.3855 - val_mean_absolute_error: 46.5700\n",
      "Epoch 534/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 883.7362 - mean_absolute_error: 25.7159\n",
      "Epoch 534: loss improved from 1459.79810 to 1448.18604, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1448.1860 - mean_absolute_error: 33.0711 - val_loss: 2201.2803 - val_mean_absolute_error: 46.4183\n",
      "Epoch 535/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1474.3811 - mean_absolute_error: 32.6759\n",
      "Epoch 535: loss improved from 1448.18604 to 1438.69714, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1438.6971 - mean_absolute_error: 32.9536 - val_loss: 2187.3511 - val_mean_absolute_error: 46.2680\n",
      "Epoch 536/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1336.6388 - mean_absolute_error: 31.1201\n",
      "Epoch 536: loss improved from 1438.69714 to 1428.62891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1428.6289 - mean_absolute_error: 32.8027 - val_loss: 2173.2896 - val_mean_absolute_error: 46.1158\n",
      "Epoch 537/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1334.5060 - mean_absolute_error: 29.6038\n",
      "Epoch 537: loss improved from 1428.62891 to 1421.36621, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1421.3662 - mean_absolute_error: 32.7166 - val_loss: 2159.2815 - val_mean_absolute_error: 45.9636\n",
      "Epoch 538/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1324.8191 - mean_absolute_error: 30.7472\n",
      "Epoch 538: loss improved from 1421.36621 to 1410.96338, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1410.9634 - mean_absolute_error: 32.5656 - val_loss: 2145.3772 - val_mean_absolute_error: 45.8121\n",
      "Epoch 539/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1532.9867 - mean_absolute_error: 34.4806\n",
      "Epoch 539: loss improved from 1410.96338 to 1399.91846, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1399.9185 - mean_absolute_error: 32.4188 - val_loss: 2132.3477 - val_mean_absolute_error: 45.6697\n",
      "Epoch 540/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1286.7133 - mean_absolute_error: 29.6673\n",
      "Epoch 540: loss improved from 1399.91846 to 1391.10376, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1391.1038 - mean_absolute_error: 32.2997 - val_loss: 2119.1687 - val_mean_absolute_error: 45.5252\n",
      "Epoch 541/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1369.7660 - mean_absolute_error: 30.7269\n",
      "Epoch 541: loss improved from 1391.10376 to 1381.07812, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1381.0781 - mean_absolute_error: 32.1547 - val_loss: 2105.7280 - val_mean_absolute_error: 45.3773\n",
      "Epoch 542/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1370.8441 - mean_absolute_error: 32.6638\n",
      "Epoch 542: loss improved from 1381.07812 to 1372.57410, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1372.5741 - mean_absolute_error: 32.0442 - val_loss: 2092.6238 - val_mean_absolute_error: 45.2327\n",
      "Epoch 543/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1342.9055 - mean_absolute_error: 32.1090\n",
      "Epoch 543: loss improved from 1372.57410 to 1362.60950, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1362.6095 - mean_absolute_error: 31.9183 - val_loss: 2079.8213 - val_mean_absolute_error: 45.0910\n",
      "Epoch 544/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1465.9122 - mean_absolute_error: 33.6523\n",
      "Epoch 544: loss improved from 1362.60950 to 1354.67090, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1354.6709 - mean_absolute_error: 31.7950 - val_loss: 2067.0317 - val_mean_absolute_error: 44.9489\n",
      "Epoch 545/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1374.4448 - mean_absolute_error: 31.3373\n",
      "Epoch 545: loss improved from 1354.67090 to 1343.84302, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1343.8430 - mean_absolute_error: 31.6546 - val_loss: 2054.2195 - val_mean_absolute_error: 44.8062\n",
      "Epoch 546/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1440.8865 - mean_absolute_error: 33.5717\n",
      "Epoch 546: loss improved from 1343.84302 to 1339.68994, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1339.6899 - mean_absolute_error: 31.6077 - val_loss: 2041.1483 - val_mean_absolute_error: 44.6601\n",
      "Epoch 547/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1164.5421 - mean_absolute_error: 28.7488\n",
      "Epoch 547: loss improved from 1339.68994 to 1328.08521, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1328.0852 - mean_absolute_error: 31.4478 - val_loss: 2028.3438 - val_mean_absolute_error: 44.5165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1398.4901 - mean_absolute_error: 33.8520\n",
      "Epoch 548: loss improved from 1328.08521 to 1321.60217, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1321.6022 - mean_absolute_error: 31.3411 - val_loss: 2015.3707 - val_mean_absolute_error: 44.3706\n",
      "Epoch 549/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1499.3870 - mean_absolute_error: 35.3924\n",
      "Epoch 549: loss improved from 1321.60217 to 1309.98120, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1309.9812 - mean_absolute_error: 31.1904 - val_loss: 2002.5739 - val_mean_absolute_error: 44.2261\n",
      "Epoch 550/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1105.9697 - mean_absolute_error: 27.8290\n",
      "Epoch 550: loss improved from 1309.98120 to 1303.07520, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1303.0752 - mean_absolute_error: 31.0980 - val_loss: 1989.8781 - val_mean_absolute_error: 44.0823\n",
      "Epoch 551/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1203.5427 - mean_absolute_error: 28.9020\n",
      "Epoch 551: loss improved from 1303.07520 to 1292.38403, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1292.3840 - mean_absolute_error: 30.9449 - val_loss: 1977.0677 - val_mean_absolute_error: 43.9368\n",
      "Epoch 552/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1159.7292 - mean_absolute_error: 29.3293\n",
      "Epoch 552: loss improved from 1292.38403 to 1283.99683, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1283.9968 - mean_absolute_error: 30.8419 - val_loss: 1964.1997 - val_mean_absolute_error: 43.7901\n",
      "Epoch 553/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1120.9106 - mean_absolute_error: 30.1021\n",
      "Epoch 553: loss improved from 1283.99683 to 1275.12097, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1275.1210 - mean_absolute_error: 30.7086 - val_loss: 1951.6371 - val_mean_absolute_error: 43.6464\n",
      "Epoch 554/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1367.4102 - mean_absolute_error: 31.4783\n",
      "Epoch 554: loss improved from 1275.12097 to 1265.63245, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1265.6324 - mean_absolute_error: 30.5804 - val_loss: 1939.0759 - val_mean_absolute_error: 43.5023\n",
      "Epoch 555/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1460.7073 - mean_absolute_error: 33.3629\n",
      "Epoch 555: loss improved from 1265.63245 to 1257.69128, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1257.6913 - mean_absolute_error: 30.4754 - val_loss: 1926.6569 - val_mean_absolute_error: 43.3593\n",
      "Epoch 556/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1464.1052 - mean_absolute_error: 32.5972\n",
      "Epoch 556: loss improved from 1257.69128 to 1250.16956, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1250.1696 - mean_absolute_error: 30.3596 - val_loss: 1914.5228 - val_mean_absolute_error: 43.2192\n",
      "Epoch 557/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1548.0045 - mean_absolute_error: 34.0963\n",
      "Epoch 557: loss improved from 1250.16956 to 1242.06604, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1242.0660 - mean_absolute_error: 30.2526 - val_loss: 1902.2794 - val_mean_absolute_error: 43.0773\n",
      "Epoch 558/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1296.1689 - mean_absolute_error: 31.5426\n",
      "Epoch 558: loss improved from 1242.06604 to 1234.31775, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1234.3177 - mean_absolute_error: 30.1503 - val_loss: 1890.2310 - val_mean_absolute_error: 42.9372\n",
      "Epoch 559/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1020.0417 - mean_absolute_error: 28.2711\n",
      "Epoch 559: loss improved from 1234.31775 to 1224.69568, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1224.6957 - mean_absolute_error: 30.0271 - val_loss: 1878.3744 - val_mean_absolute_error: 42.7989\n",
      "Epoch 560/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1300.1213 - mean_absolute_error: 31.1284\n",
      "Epoch 560: loss improved from 1224.69568 to 1218.67139, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1218.6714 - mean_absolute_error: 29.9313 - val_loss: 1866.3453 - val_mean_absolute_error: 42.6582\n",
      "Epoch 561/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 891.1876 - mean_absolute_error: 24.0750\n",
      "Epoch 561: loss improved from 1218.67139 to 1208.76611, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1208.7661 - mean_absolute_error: 29.8149 - val_loss: 1854.4091 - val_mean_absolute_error: 42.5180\n",
      "Epoch 562/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1240.5911 - mean_absolute_error: 30.9229\n",
      "Epoch 562: loss improved from 1208.76611 to 1200.87988, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1200.8799 - mean_absolute_error: 29.6977 - val_loss: 1842.1678 - val_mean_absolute_error: 42.3738\n",
      "Epoch 563/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1394.8209 - mean_absolute_error: 33.1940\n",
      "Epoch 563: loss improved from 1200.87988 to 1191.53528, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1191.5353 - mean_absolute_error: 29.5811 - val_loss: 1829.8459 - val_mean_absolute_error: 42.2282\n",
      "Epoch 564/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1192.0300 - mean_absolute_error: 29.3476\n",
      "Epoch 564: loss improved from 1191.53528 to 1184.14783, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1184.1478 - mean_absolute_error: 29.4753 - val_loss: 1817.6615 - val_mean_absolute_error: 42.0837\n",
      "Epoch 565/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 919.2129 - mean_absolute_error: 24.7076\n",
      "Epoch 565: loss improved from 1184.14783 to 1178.24658, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1178.2466 - mean_absolute_error: 29.3758 - val_loss: 1805.6750 - val_mean_absolute_error: 41.9410\n",
      "Epoch 566/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1014.8010 - mean_absolute_error: 27.4240\n",
      "Epoch 566: loss improved from 1178.24658 to 1167.56934, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1167.5693 - mean_absolute_error: 29.2354 - val_loss: 1793.4933 - val_mean_absolute_error: 41.7956\n",
      "Epoch 567/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1001.4128 - mean_absolute_error: 26.1168\n",
      "Epoch 567: loss improved from 1167.56934 to 1160.00061, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1160.0006 - mean_absolute_error: 29.1388 - val_loss: 1781.7109 - val_mean_absolute_error: 41.6544\n",
      "Epoch 568/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1509.4521 - mean_absolute_error: 33.9186\n",
      "Epoch 568: loss improved from 1160.00061 to 1153.21167, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1153.2117 - mean_absolute_error: 29.0279 - val_loss: 1769.9003 - val_mean_absolute_error: 41.5124\n",
      "Epoch 569/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 954.7316 - mean_absolute_error: 26.0433\n",
      "Epoch 569: loss improved from 1153.21167 to 1145.07544, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1145.0754 - mean_absolute_error: 28.9171 - val_loss: 1758.6298 - val_mean_absolute_error: 41.3764\n",
      "Epoch 570/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 877.2826 - mean_absolute_error: 24.3589\n",
      "Epoch 570: loss improved from 1145.07544 to 1137.08887, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1137.0889 - mean_absolute_error: 28.8240 - val_loss: 1747.3208 - val_mean_absolute_error: 41.2395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 880.9353 - mean_absolute_error: 24.5750\n",
      "Epoch 571: loss improved from 1137.08887 to 1128.24792, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1128.2479 - mean_absolute_error: 28.6935 - val_loss: 1735.9026 - val_mean_absolute_error: 41.1008\n",
      "Epoch 572/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1044.4187 - mean_absolute_error: 27.9228\n",
      "Epoch 572: loss improved from 1128.24792 to 1122.49182, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1122.4918 - mean_absolute_error: 28.6080 - val_loss: 1724.4415 - val_mean_absolute_error: 40.9612\n",
      "Epoch 573/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1073.3467 - mean_absolute_error: 27.6558\n",
      "Epoch 573: loss improved from 1122.49182 to 1115.47961, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1115.4796 - mean_absolute_error: 28.5187 - val_loss: 1713.4016 - val_mean_absolute_error: 40.8262\n",
      "Epoch 574/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1282.6838 - mean_absolute_error: 31.0628\n",
      "Epoch 574: loss improved from 1115.47961 to 1105.99536, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1105.9954 - mean_absolute_error: 28.3748 - val_loss: 1702.1240 - val_mean_absolute_error: 40.6878\n",
      "Epoch 575/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1358.7988 - mean_absolute_error: 31.6188\n",
      "Epoch 575: loss improved from 1105.99536 to 1098.68347, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1098.6835 - mean_absolute_error: 28.2725 - val_loss: 1690.9691 - val_mean_absolute_error: 40.5505\n",
      "Epoch 576/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 875.7035 - mean_absolute_error: 24.8107\n",
      "Epoch 576: loss improved from 1098.68347 to 1090.82544, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1090.8254 - mean_absolute_error: 28.1675 - val_loss: 1679.9319 - val_mean_absolute_error: 40.4142\n",
      "Epoch 577/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1240.6760 - mean_absolute_error: 31.4230\n",
      "Epoch 577: loss improved from 1090.82544 to 1084.76807, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1084.7681 - mean_absolute_error: 28.0703 - val_loss: 1668.9513 - val_mean_absolute_error: 40.2781\n",
      "Epoch 578/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1011.5305 - mean_absolute_error: 26.7535\n",
      "Epoch 578: loss improved from 1084.76807 to 1077.76538, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1077.7654 - mean_absolute_error: 27.9732 - val_loss: 1658.0974 - val_mean_absolute_error: 40.1432\n",
      "Epoch 579/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1419.2288 - mean_absolute_error: 33.9320\n",
      "Epoch 579: loss improved from 1077.76538 to 1069.83887, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1069.8389 - mean_absolute_error: 27.8680 - val_loss: 1647.1931 - val_mean_absolute_error: 40.0071\n",
      "Epoch 580/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1158.4857 - mean_absolute_error: 29.6502\n",
      "Epoch 580: loss improved from 1069.83887 to 1064.16296, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1064.1630 - mean_absolute_error: 27.7741 - val_loss: 1636.6278 - val_mean_absolute_error: 39.8748\n",
      "Epoch 581/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1025.3787 - mean_absolute_error: 26.4931\n",
      "Epoch 581: loss improved from 1064.16296 to 1055.40955, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1055.4095 - mean_absolute_error: 27.6414 - val_loss: 1626.0378 - val_mean_absolute_error: 39.7418\n",
      "Epoch 582/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1176.1145 - mean_absolute_error: 29.9989\n",
      "Epoch 582: loss improved from 1055.40955 to 1049.29871, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1049.2987 - mean_absolute_error: 27.5594 - val_loss: 1615.0978 - val_mean_absolute_error: 39.6040\n",
      "Epoch 583/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 828.6034 - mean_absolute_error: 23.8798\n",
      "Epoch 583: loss improved from 1049.29871 to 1042.81958, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1042.8196 - mean_absolute_error: 27.4678 - val_loss: 1604.2825 - val_mean_absolute_error: 39.4672\n",
      "Epoch 584/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1023.1497 - mean_absolute_error: 26.6048\n",
      "Epoch 584: loss improved from 1042.81958 to 1035.26599, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1035.2660 - mean_absolute_error: 27.3549 - val_loss: 1593.8033 - val_mean_absolute_error: 39.3342\n",
      "Epoch 585/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1063.5917 - mean_absolute_error: 27.9547\n",
      "Epoch 585: loss improved from 1035.26599 to 1028.03857, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1028.0386 - mean_absolute_error: 27.2519 - val_loss: 1583.3237 - val_mean_absolute_error: 39.2008\n",
      "Epoch 586/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1018.5674 - mean_absolute_error: 28.2602\n",
      "Epoch 586: loss improved from 1028.03857 to 1022.74408, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1022.7441 - mean_absolute_error: 27.1629 - val_loss: 1572.9110 - val_mean_absolute_error: 39.0677\n",
      "Epoch 587/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1107.4899 - mean_absolute_error: 27.8045\n",
      "Epoch 587: loss improved from 1022.74408 to 1015.61829, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1015.6183 - mean_absolute_error: 27.0569 - val_loss: 1562.7985 - val_mean_absolute_error: 38.9381\n",
      "Epoch 588/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 961.1561 - mean_absolute_error: 25.8530\n",
      "Epoch 588: loss improved from 1015.61829 to 1010.73853, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1010.7385 - mean_absolute_error: 26.9754 - val_loss: 1552.6838 - val_mean_absolute_error: 38.8080\n",
      "Epoch 589/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1146.1069 - mean_absolute_error: 29.3011\n",
      "Epoch 589: loss improved from 1010.73853 to 1002.03674, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1002.0367 - mean_absolute_error: 26.8500 - val_loss: 1542.3011 - val_mean_absolute_error: 38.6740\n",
      "Epoch 590/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1171.6107 - mean_absolute_error: 29.4633\n",
      "Epoch 590: loss improved from 1002.03674 to 996.44055, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 996.4406 - mean_absolute_error: 26.7609 - val_loss: 1532.0049 - val_mean_absolute_error: 38.5406\n",
      "Epoch 591/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 908.7823 - mean_absolute_error: 25.1808\n",
      "Epoch 591: loss improved from 996.44055 to 988.79736, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 988.7974 - mean_absolute_error: 26.6562 - val_loss: 1522.0852 - val_mean_absolute_error: 38.4117\n",
      "Epoch 592/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 978.4208 - mean_absolute_error: 25.3973\n",
      "Epoch 592: loss improved from 988.79736 to 982.90424, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 982.9042 - mean_absolute_error: 26.5682 - val_loss: 1511.8612 - val_mean_absolute_error: 38.2784\n",
      "Epoch 593/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1291.0110 - mean_absolute_error: 31.4182\n",
      "Epoch 593: loss improved from 982.90424 to 975.93378, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 975.9338 - mean_absolute_error: 26.4487 - val_loss: 1501.6599 - val_mean_absolute_error: 38.1449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1168.4666 - mean_absolute_error: 30.5880\n",
      "Epoch 594: loss improved from 975.93378 to 971.24945, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 971.2495 - mean_absolute_error: 26.3870 - val_loss: 1491.5000 - val_mean_absolute_error: 38.0115\n",
      "Epoch 595/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 601.4928 - mean_absolute_error: 19.0084\n",
      "Epoch 595: loss improved from 971.24945 to 961.93164, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 961.9316 - mean_absolute_error: 26.2399 - val_loss: 1481.6948 - val_mean_absolute_error: 37.8823\n",
      "Epoch 596/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1273.5522 - mean_absolute_error: 31.9699\n",
      "Epoch 596: loss improved from 961.93164 to 957.28638, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 957.2864 - mean_absolute_error: 26.1612 - val_loss: 1471.6510 - val_mean_absolute_error: 37.7495\n",
      "Epoch 597/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1014.7689 - mean_absolute_error: 27.7044\n",
      "Epoch 597: loss improved from 957.28638 to 949.73291, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 949.7329 - mean_absolute_error: 26.0415 - val_loss: 1461.8103 - val_mean_absolute_error: 37.6189\n",
      "Epoch 598/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 756.8815 - mean_absolute_error: 23.9255\n",
      "Epoch 598: loss improved from 949.73291 to 945.99280, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 945.9928 - mean_absolute_error: 25.9773 - val_loss: 1452.4086 - val_mean_absolute_error: 37.4938\n",
      "Epoch 599/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 981.4313 - mean_absolute_error: 27.4945\n",
      "Epoch 599: loss improved from 945.99280 to 937.18408, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 937.1841 - mean_absolute_error: 25.8327 - val_loss: 1442.8409 - val_mean_absolute_error: 37.3660\n",
      "Epoch 600/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 903.1672 - mean_absolute_error: 26.0061\n",
      "Epoch 600: loss improved from 937.18408 to 931.72583, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 931.7258 - mean_absolute_error: 25.7555 - val_loss: 1433.4980 - val_mean_absolute_error: 37.2407\n",
      "Epoch 601/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 965.9368 - mean_absolute_error: 27.1690\n",
      "Epoch 601: loss improved from 931.72583 to 925.59265, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 925.5927 - mean_absolute_error: 25.6757 - val_loss: 1424.3890 - val_mean_absolute_error: 37.1182\n",
      "Epoch 602/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 971.5447 - mean_absolute_error: 26.6647\n",
      "Epoch 602: loss improved from 925.59265 to 920.53552, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 920.5355 - mean_absolute_error: 25.5941 - val_loss: 1415.3082 - val_mean_absolute_error: 36.9957\n",
      "Epoch 603/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1043.9049 - mean_absolute_error: 27.1550\n",
      "Epoch 603: loss improved from 920.53552 to 914.72815, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 914.7281 - mean_absolute_error: 25.4825 - val_loss: 1406.0941 - val_mean_absolute_error: 36.8710\n",
      "Epoch 604/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 947.3056 - mean_absolute_error: 26.6229\n",
      "Epoch 604: loss improved from 914.72815 to 909.00189, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 909.0019 - mean_absolute_error: 25.4153 - val_loss: 1396.8425 - val_mean_absolute_error: 36.7453\n",
      "Epoch 605/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 789.2115 - mean_absolute_error: 23.1560\n",
      "Epoch 605: loss improved from 909.00189 to 903.88837, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 903.8884 - mean_absolute_error: 25.3231 - val_loss: 1387.5377 - val_mean_absolute_error: 36.6185\n",
      "Epoch 606/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 823.2305 - mean_absolute_error: 23.9501\n",
      "Epoch 606: loss improved from 903.88837 to 897.34601, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 897.3460 - mean_absolute_error: 25.2165 - val_loss: 1378.2094 - val_mean_absolute_error: 36.4909\n",
      "Epoch 607/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 969.5253 - mean_absolute_error: 26.8705\n",
      "Epoch 607: loss improved from 897.34601 to 891.94891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 891.9489 - mean_absolute_error: 25.1261 - val_loss: 1368.8749 - val_mean_absolute_error: 36.3628\n",
      "Epoch 608/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 988.3433 - mean_absolute_error: 27.9438\n",
      "Epoch 608: loss improved from 891.94891 to 886.47516, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 886.4752 - mean_absolute_error: 25.0396 - val_loss: 1359.5122 - val_mean_absolute_error: 36.2338\n",
      "Epoch 609/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 848.6687 - mean_absolute_error: 25.3702\n",
      "Epoch 609: loss improved from 886.47516 to 880.08630, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 880.0863 - mean_absolute_error: 24.9475 - val_loss: 1350.3558 - val_mean_absolute_error: 36.1072\n",
      "Epoch 610/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1216.6213 - mean_absolute_error: 31.6485\n",
      "Epoch 610: loss improved from 880.08630 to 874.48126, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 874.4813 - mean_absolute_error: 24.8582 - val_loss: 1341.0330 - val_mean_absolute_error: 35.9779\n",
      "Epoch 611/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 668.8552 - mean_absolute_error: 21.7784\n",
      "Epoch 611: loss improved from 874.48126 to 868.87378, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 868.8738 - mean_absolute_error: 24.7602 - val_loss: 1332.0103 - val_mean_absolute_error: 35.8523\n",
      "Epoch 612/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 962.0466 - mean_absolute_error: 26.1747\n",
      "Epoch 612: loss improved from 868.87378 to 863.29810, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 863.2981 - mean_absolute_error: 24.6797 - val_loss: 1323.0967 - val_mean_absolute_error: 35.7277\n",
      "Epoch 613/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 833.6723 - mean_absolute_error: 24.5565\n",
      "Epoch 613: loss improved from 863.29810 to 857.79053, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 857.7905 - mean_absolute_error: 24.5839 - val_loss: 1314.5302 - val_mean_absolute_error: 35.6077\n",
      "Epoch 614/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 700.0768 - mean_absolute_error: 22.1421\n",
      "Epoch 614: loss improved from 857.79053 to 851.95721, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 851.9572 - mean_absolute_error: 24.4933 - val_loss: 1306.4376 - val_mean_absolute_error: 35.4938\n",
      "Epoch 615/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 894.3181 - mean_absolute_error: 24.2444\n",
      "Epoch 615: loss improved from 851.95721 to 849.52789, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 849.5279 - mean_absolute_error: 24.4672 - val_loss: 1297.9297 - val_mean_absolute_error: 35.3738\n",
      "Epoch 616/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 767.5685 - mean_absolute_error: 23.5900\n",
      "Epoch 616: loss improved from 849.52789 to 843.79083, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 843.7908 - mean_absolute_error: 24.3739 - val_loss: 1289.0383 - val_mean_absolute_error: 35.2479\n",
      "Epoch 617/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 706.3630 - mean_absolute_error: 21.5985\n",
      "Epoch 617: loss improved from 843.79083 to 838.55109, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 838.5511 - mean_absolute_error: 24.2987 - val_loss: 1279.9827 - val_mean_absolute_error: 35.1192\n",
      "Epoch 618/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 975.9211 - mean_absolute_error: 26.7430\n",
      "Epoch 618: loss improved from 838.55109 to 832.83459, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 832.8346 - mean_absolute_error: 24.2085 - val_loss: 1271.1843 - val_mean_absolute_error: 34.9937\n",
      "Epoch 619/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1002.0922 - mean_absolute_error: 26.3072\n",
      "Epoch 619: loss improved from 832.83459 to 826.46729, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 826.4673 - mean_absolute_error: 24.0995 - val_loss: 1262.6718 - val_mean_absolute_error: 34.8719\n",
      "Epoch 620/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 650.6314 - mean_absolute_error: 20.5802\n",
      "Epoch 620: loss improved from 826.46729 to 821.79474, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 821.7947 - mean_absolute_error: 24.0370 - val_loss: 1254.2749 - val_mean_absolute_error: 34.7513\n",
      "Epoch 621/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 785.0629 - mean_absolute_error: 23.8809\n",
      "Epoch 621: loss improved from 821.79474 to 816.61963, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 816.6196 - mean_absolute_error: 23.9609 - val_loss: 1245.8986 - val_mean_absolute_error: 34.6305\n",
      "Epoch 622/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 574.1065 - mean_absolute_error: 19.2555\n",
      "Epoch 622: loss improved from 816.61963 to 810.61243, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 810.6124 - mean_absolute_error: 23.8511 - val_loss: 1237.7653 - val_mean_absolute_error: 34.5129\n",
      "Epoch 623/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 864.0184 - mean_absolute_error: 24.4549\n",
      "Epoch 623: loss improved from 810.61243 to 806.50342, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 806.5034 - mean_absolute_error: 23.7971 - val_loss: 1229.5032 - val_mean_absolute_error: 34.3930\n",
      "Epoch 624/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 582.3036 - mean_absolute_error: 20.1940\n",
      "Epoch 624: loss improved from 806.50342 to 800.99683, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 800.9968 - mean_absolute_error: 23.6913 - val_loss: 1221.7092 - val_mean_absolute_error: 34.2795\n",
      "Epoch 625/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 737.3446 - mean_absolute_error: 22.7266\n",
      "Epoch 625: loss improved from 800.99683 to 796.82092, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 796.8209 - mean_absolute_error: 23.6338 - val_loss: 1213.5206 - val_mean_absolute_error: 34.1599\n",
      "Epoch 626/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 703.9373 - mean_absolute_error: 20.9244\n",
      "Epoch 626: loss improved from 796.82092 to 792.50854, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 792.5085 - mean_absolute_error: 23.5651 - val_loss: 1205.4391 - val_mean_absolute_error: 34.0414\n",
      "Epoch 627/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 570.6377 - mean_absolute_error: 18.3040\n",
      "Epoch 627: loss improved from 792.50854 to 788.27905, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 788.2791 - mean_absolute_error: 23.4950 - val_loss: 1197.4183 - val_mean_absolute_error: 33.9233\n",
      "Epoch 628/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 978.3530 - mean_absolute_error: 27.0200\n",
      "Epoch 628: loss improved from 788.27905 to 782.94086, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 782.9409 - mean_absolute_error: 23.4132 - val_loss: 1189.4019 - val_mean_absolute_error: 33.8050\n",
      "Epoch 629/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 717.1964 - mean_absolute_error: 22.7531\n",
      "Epoch 629: loss improved from 782.94086 to 777.28491, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 777.2849 - mean_absolute_error: 23.3394 - val_loss: 1181.8185 - val_mean_absolute_error: 33.6926\n",
      "Epoch 630/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 857.9606 - mean_absolute_error: 25.3265\n",
      "Epoch 630: loss improved from 777.28491 to 773.30469, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 773.3047 - mean_absolute_error: 23.2705 - val_loss: 1173.9232 - val_mean_absolute_error: 33.5753\n",
      "Epoch 631/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 769.7422 - mean_absolute_error: 23.1939\n",
      "Epoch 631: loss improved from 773.30469 to 768.05780, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 768.0578 - mean_absolute_error: 23.1814 - val_loss: 1165.9094 - val_mean_absolute_error: 33.4557\n",
      "Epoch 632/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 921.0318 - mean_absolute_error: 26.7002\n",
      "Epoch 632: loss improved from 768.05780 to 764.04370, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 764.0437 - mean_absolute_error: 23.1212 - val_loss: 1157.8776 - val_mean_absolute_error: 33.3355\n",
      "Epoch 633/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 675.0388 - mean_absolute_error: 21.2463\n",
      "Epoch 633: loss improved from 764.04370 to 759.74823, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 759.7482 - mean_absolute_error: 23.0529 - val_loss: 1150.0551 - val_mean_absolute_error: 33.2179\n",
      "Epoch 634/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 834.0787 - mean_absolute_error: 23.6951\n",
      "Epoch 634: loss improved from 759.74823 to 754.39447, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 754.3945 - mean_absolute_error: 22.9461 - val_loss: 1142.3136 - val_mean_absolute_error: 33.1012\n",
      "Epoch 635/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 948.4849 - mean_absolute_error: 26.8865\n",
      "Epoch 635: loss improved from 754.39447 to 750.67896, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 750.6790 - mean_absolute_error: 22.8967 - val_loss: 1134.7001 - val_mean_absolute_error: 32.9860\n",
      "Epoch 636/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 730.2351 - mean_absolute_error: 23.3720\n",
      "Epoch 636: loss improved from 750.67896 to 745.87299, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 745.8730 - mean_absolute_error: 22.8413 - val_loss: 1127.1382 - val_mean_absolute_error: 32.8712\n",
      "Epoch 637/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 880.8653 - mean_absolute_error: 25.9368\n",
      "Epoch 637: loss improved from 745.87299 to 741.69177, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 741.6918 - mean_absolute_error: 22.7599 - val_loss: 1119.4996 - val_mean_absolute_error: 32.7548\n",
      "Epoch 638/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 832.2775 - mean_absolute_error: 25.5320\n",
      "Epoch 638: loss improved from 741.69177 to 738.65594, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 738.6559 - mean_absolute_error: 22.7185 - val_loss: 1112.2499 - val_mean_absolute_error: 32.6439\n",
      "Epoch 639/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 968.2964 - mean_absolute_error: 26.9017\n",
      "Epoch 639: loss improved from 738.65594 to 732.83911, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 732.8391 - mean_absolute_error: 22.6276 - val_loss: 1104.8341 - val_mean_absolute_error: 32.5301\n",
      "Epoch 640/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 532.0642 - mean_absolute_error: 18.9543\n",
      "Epoch 640: loss improved from 732.83911 to 727.72552, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 727.7255 - mean_absolute_error: 22.5363 - val_loss: 1097.6530 - val_mean_absolute_error: 32.4196\n",
      "Epoch 641/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 770.8370 - mean_absolute_error: 22.7881\n",
      "Epoch 641: loss improved from 727.72552 to 724.56445, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 724.5645 - mean_absolute_error: 22.4908 - val_loss: 1090.0161 - val_mean_absolute_error: 32.3016\n",
      "Epoch 642/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 614.3925 - mean_absolute_error: 20.9740\n",
      "Epoch 642: loss improved from 724.56445 to 720.00427, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 720.0043 - mean_absolute_error: 22.4268 - val_loss: 1082.7500 - val_mean_absolute_error: 32.1889\n",
      "Epoch 643/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 628.8839 - mean_absolute_error: 20.1851\n",
      "Epoch 643: loss improved from 720.00427 to 717.19110, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 717.1911 - mean_absolute_error: 22.3858 - val_loss: 1075.3662 - val_mean_absolute_error: 32.0740\n",
      "Epoch 644/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 548.7067 - mean_absolute_error: 18.5396\n",
      "Epoch 644: loss improved from 717.19110 to 710.80542, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 710.8054 - mean_absolute_error: 22.2838 - val_loss: 1067.9347 - val_mean_absolute_error: 31.9579\n",
      "Epoch 645/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 733.1410 - mean_absolute_error: 23.5893\n",
      "Epoch 645: loss improved from 710.80542 to 707.64471, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 707.6447 - mean_absolute_error: 22.2378 - val_loss: 1060.6342 - val_mean_absolute_error: 31.8435\n",
      "Epoch 646/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 537.3779 - mean_absolute_error: 18.4449\n",
      "Epoch 646: loss improved from 707.64471 to 704.41217, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 704.4122 - mean_absolute_error: 22.1704 - val_loss: 1053.7327 - val_mean_absolute_error: 31.7350\n",
      "Epoch 647/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 672.3105 - mean_absolute_error: 21.9382\n",
      "Epoch 647: loss improved from 704.41217 to 699.22491, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 699.2249 - mean_absolute_error: 22.0784 - val_loss: 1046.6261 - val_mean_absolute_error: 31.6228\n",
      "Epoch 648/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 778.0120 - mean_absolute_error: 23.5632\n",
      "Epoch 648: loss improved from 699.22491 to 695.43359, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 695.4336 - mean_absolute_error: 22.0318 - val_loss: 1039.4156 - val_mean_absolute_error: 31.5086\n",
      "Epoch 649/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 573.8335 - mean_absolute_error: 20.7785\n",
      "Epoch 649: loss improved from 695.43359 to 691.63898, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 691.6390 - mean_absolute_error: 21.9750 - val_loss: 1032.4662 - val_mean_absolute_error: 31.3981\n",
      "Epoch 650/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 941.1351 - mean_absolute_error: 26.5301\n",
      "Epoch 650: loss improved from 691.63898 to 687.36578, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 687.3658 - mean_absolute_error: 21.9104 - val_loss: 1025.3759 - val_mean_absolute_error: 31.2850\n",
      "Epoch 651/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 810.7876 - mean_absolute_error: 23.9196\n",
      "Epoch 651: loss improved from 687.36578 to 684.12250, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 684.1225 - mean_absolute_error: 21.8570 - val_loss: 1018.2827 - val_mean_absolute_error: 31.1714\n",
      "Epoch 652/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 763.5565 - mean_absolute_error: 23.6590\n",
      "Epoch 652: loss improved from 684.12250 to 679.79889, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 679.7989 - mean_absolute_error: 21.7854 - val_loss: 1011.4739 - val_mean_absolute_error: 31.0620\n",
      "Epoch 653/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 706.0370 - mean_absolute_error: 22.0109\n",
      "Epoch 653: loss improved from 679.79889 to 675.64172, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 675.6417 - mean_absolute_error: 21.7180 - val_loss: 1004.9973 - val_mean_absolute_error: 30.9576\n",
      "Epoch 654/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 784.3744 - mean_absolute_error: 23.9114\n",
      "Epoch 654: loss improved from 675.64172 to 673.70312, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 673.7031 - mean_absolute_error: 21.6870 - val_loss: 998.4254 - val_mean_absolute_error: 30.8513\n",
      "Epoch 655/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 725.1383 - mean_absolute_error: 22.4434\n",
      "Epoch 655: loss improved from 673.70312 to 669.02881, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 669.0288 - mean_absolute_error: 21.6206 - val_loss: 991.8398 - val_mean_absolute_error: 30.7443\n",
      "Epoch 656/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 599.6984 - mean_absolute_error: 20.7002\n",
      "Epoch 656: loss improved from 669.02881 to 664.10889, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 664.1089 - mean_absolute_error: 21.5353 - val_loss: 985.0544 - val_mean_absolute_error: 30.6338\n",
      "Epoch 657/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 549.3147 - mean_absolute_error: 19.6432\n",
      "Epoch 657: loss improved from 664.10889 to 661.06366, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 661.0637 - mean_absolute_error: 21.4993 - val_loss: 978.3885 - val_mean_absolute_error: 30.5248\n",
      "Epoch 658/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 698.3941 - mean_absolute_error: 22.8100\n",
      "Epoch 658: loss improved from 661.06366 to 658.58368, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 658.5837 - mean_absolute_error: 21.4457 - val_loss: 971.6554 - val_mean_absolute_error: 30.4143\n",
      "Epoch 659/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 744.7064 - mean_absolute_error: 22.4143\n",
      "Epoch 659: loss improved from 658.58368 to 653.66003, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 653.6600 - mean_absolute_error: 21.3783 - val_loss: 965.0716 - val_mean_absolute_error: 30.3059\n",
      "Epoch 660/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 649.6990 - mean_absolute_error: 21.1750\n",
      "Epoch 660: loss improved from 653.66003 to 650.42328, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 650.4233 - mean_absolute_error: 21.3169 - val_loss: 958.7527 - val_mean_absolute_error: 30.2015\n",
      "Epoch 661/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 823.0520 - mean_absolute_error: 25.2895\n",
      "Epoch 661: loss improved from 650.42328 to 646.91376, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 646.9138 - mean_absolute_error: 21.2676 - val_loss: 952.3895 - val_mean_absolute_error: 30.0959\n",
      "Epoch 662/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 743.9269 - mean_absolute_error: 24.0253\n",
      "Epoch 662: loss improved from 646.91376 to 642.98260, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 642.9826 - mean_absolute_error: 21.2072 - val_loss: 945.9041 - val_mean_absolute_error: 29.9880\n",
      "Epoch 663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 673.5809 - mean_absolute_error: 21.2016\n",
      "Epoch 663: loss improved from 642.98260 to 641.42566, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 641.4257 - mean_absolute_error: 21.1778 - val_loss: 939.6278 - val_mean_absolute_error: 29.8832\n",
      "Epoch 664/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 688.9136 - mean_absolute_error: 21.6637\n",
      "Epoch 664: loss improved from 641.42566 to 636.49506, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 636.4951 - mean_absolute_error: 21.1054 - val_loss: 933.5664 - val_mean_absolute_error: 29.7816\n",
      "Epoch 665/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 803.0723 - mean_absolute_error: 24.2068\n",
      "Epoch 665: loss improved from 636.49506 to 633.58746, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 633.5875 - mean_absolute_error: 21.0626 - val_loss: 927.1724 - val_mean_absolute_error: 29.6740\n",
      "Epoch 666/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 692.8254 - mean_absolute_error: 21.2654\n",
      "Epoch 666: loss improved from 633.58746 to 630.43756, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 630.4376 - mean_absolute_error: 21.0155 - val_loss: 920.7869 - val_mean_absolute_error: 29.5662\n",
      "Epoch 667/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 553.5542 - mean_absolute_error: 19.5835\n",
      "Epoch 667: loss improved from 630.43756 to 627.05933, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 627.0593 - mean_absolute_error: 20.9613 - val_loss: 914.5731 - val_mean_absolute_error: 29.4610\n",
      "Epoch 668/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 554.3302 - mean_absolute_error: 18.8706\n",
      "Epoch 668: loss improved from 627.05933 to 624.13788, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 624.1379 - mean_absolute_error: 20.9171 - val_loss: 908.4316 - val_mean_absolute_error: 29.3565\n",
      "Epoch 669/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 682.4692 - mean_absolute_error: 21.3264\n",
      "Epoch 669: loss improved from 624.13788 to 619.18890, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 619.1889 - mean_absolute_error: 20.8414 - val_loss: 902.4565 - val_mean_absolute_error: 29.2546\n",
      "Epoch 670/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 481.1829 - mean_absolute_error: 17.1435\n",
      "Epoch 670: loss improved from 619.18890 to 618.16779, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 618.1678 - mean_absolute_error: 20.8180 - val_loss: 896.6873 - val_mean_absolute_error: 29.1558\n",
      "Epoch 671/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 531.5831 - mean_absolute_error: 20.0543\n",
      "Epoch 671: loss improved from 618.16779 to 613.53729, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 613.5373 - mean_absolute_error: 20.7500 - val_loss: 890.7328 - val_mean_absolute_error: 29.0535\n",
      "Epoch 672/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 541.6653 - mean_absolute_error: 18.1411\n",
      "Epoch 672: loss improved from 613.53729 to 610.69293, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 610.6929 - mean_absolute_error: 20.7008 - val_loss: 884.8593 - val_mean_absolute_error: 28.9523\n",
      "Epoch 673/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 700.8514 - mean_absolute_error: 21.9726\n",
      "Epoch 673: loss improved from 610.69293 to 607.75189, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 607.7519 - mean_absolute_error: 20.6661 - val_loss: 878.9341 - val_mean_absolute_error: 28.8498\n",
      "Epoch 674/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 727.9805 - mean_absolute_error: 22.1525\n",
      "Epoch 674: loss improved from 607.75189 to 606.15448, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 606.1545 - mean_absolute_error: 20.6417 - val_loss: 873.0518 - val_mean_absolute_error: 28.7476\n",
      "Epoch 675/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 491.2309 - mean_absolute_error: 18.4510\n",
      "Epoch 675: loss improved from 606.15448 to 601.90076, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 601.9008 - mean_absolute_error: 20.5753 - val_loss: 867.2079 - val_mean_absolute_error: 28.6458\n",
      "Epoch 676/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 552.2610 - mean_absolute_error: 19.3046\n",
      "Epoch 676: loss improved from 601.90076 to 598.39618, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 598.3962 - mean_absolute_error: 20.5250 - val_loss: 861.5886 - val_mean_absolute_error: 28.5476\n",
      "Epoch 677/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 636.2383 - mean_absolute_error: 20.1384\n",
      "Epoch 677: loss improved from 598.39618 to 596.35651, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 596.3565 - mean_absolute_error: 20.4837 - val_loss: 855.8211 - val_mean_absolute_error: 28.4464\n",
      "Epoch 678/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 617.4114 - mean_absolute_error: 20.9346\n",
      "Epoch 678: loss improved from 596.35651 to 592.83331, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 592.8333 - mean_absolute_error: 20.4277 - val_loss: 849.9390 - val_mean_absolute_error: 28.3428\n",
      "Epoch 679/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 530.5999 - mean_absolute_error: 18.3014\n",
      "Epoch 679: loss improved from 592.83331 to 590.32245, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 590.3224 - mean_absolute_error: 20.3811 - val_loss: 844.1784 - val_mean_absolute_error: 28.2410\n",
      "Epoch 680/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 663.9596 - mean_absolute_error: 22.4094\n",
      "Epoch 680: loss improved from 590.32245 to 586.88660, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 586.8866 - mean_absolute_error: 20.3429 - val_loss: 838.3535 - val_mean_absolute_error: 28.1377\n",
      "Epoch 681/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 639.2180 - mean_absolute_error: 22.3840\n",
      "Epoch 681: loss improved from 586.88660 to 585.08130, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 585.0813 - mean_absolute_error: 20.2947 - val_loss: 832.8691 - val_mean_absolute_error: 28.0400\n",
      "Epoch 682/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 616.4974 - mean_absolute_error: 20.6570\n",
      "Epoch 682: loss improved from 585.08130 to 580.63788, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 580.6379 - mean_absolute_error: 20.2222 - val_loss: 827.2374 - val_mean_absolute_error: 27.9394\n",
      "Epoch 683/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 660.8748 - mean_absolute_error: 22.1687\n",
      "Epoch 683: loss improved from 580.63788 to 577.76746, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 577.7675 - mean_absolute_error: 20.1822 - val_loss: 821.6805 - val_mean_absolute_error: 27.8398\n",
      "Epoch 684/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 502.3783 - mean_absolute_error: 18.4830\n",
      "Epoch 684: loss improved from 577.76746 to 574.84802, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 574.8480 - mean_absolute_error: 20.1349 - val_loss: 816.4930 - val_mean_absolute_error: 27.7465\n",
      "Epoch 685/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 779.3551 - mean_absolute_error: 24.2426\n",
      "Epoch 685: loss improved from 574.84802 to 572.66266, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 572.6627 - mean_absolute_error: 20.1012 - val_loss: 811.1449 - val_mean_absolute_error: 27.6500\n",
      "Epoch 686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 659.0219 - mean_absolute_error: 22.4779\n",
      "Epoch 686: loss improved from 572.66266 to 571.34155, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 571.3416 - mean_absolute_error: 20.0787 - val_loss: 805.9332 - val_mean_absolute_error: 27.5555\n",
      "Epoch 687/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 596.8712 - mean_absolute_error: 21.3680\n",
      "Epoch 687: loss improved from 571.34155 to 567.72437, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 567.7244 - mean_absolute_error: 20.0167 - val_loss: 800.7025 - val_mean_absolute_error: 27.4605\n",
      "Epoch 688/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 600.3661 - mean_absolute_error: 20.8000\n",
      "Epoch 688: loss improved from 567.72437 to 565.34003, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 565.3400 - mean_absolute_error: 19.9939 - val_loss: 795.3886 - val_mean_absolute_error: 27.3636\n",
      "Epoch 689/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 732.9073 - mean_absolute_error: 23.6929\n",
      "Epoch 689: loss improved from 565.34003 to 563.28363, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 563.2836 - mean_absolute_error: 19.9554 - val_loss: 789.9888 - val_mean_absolute_error: 27.2647\n",
      "Epoch 690/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 650.9077 - mean_absolute_error: 22.6832\n",
      "Epoch 690: loss improved from 563.28363 to 561.12482, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 561.1248 - mean_absolute_error: 19.9201 - val_loss: 784.5779 - val_mean_absolute_error: 27.1653\n",
      "Epoch 691/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 459.0944 - mean_absolute_error: 17.3379\n",
      "Epoch 691: loss improved from 561.12482 to 556.34735, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 556.3474 - mean_absolute_error: 19.8511 - val_loss: 779.1942 - val_mean_absolute_error: 27.0660\n",
      "Epoch 692/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 716.3733 - mean_absolute_error: 23.4918\n",
      "Epoch 692: loss improved from 556.34735 to 554.79846, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 554.7985 - mean_absolute_error: 19.8389 - val_loss: 773.7545 - val_mean_absolute_error: 26.9653\n",
      "Epoch 693/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 667.8291 - mean_absolute_error: 22.6689\n",
      "Epoch 693: loss improved from 554.79846 to 551.60651, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 551.6065 - mean_absolute_error: 19.7730 - val_loss: 768.8040 - val_mean_absolute_error: 26.8734\n",
      "Epoch 694/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 480.3564 - mean_absolute_error: 18.1911\n",
      "Epoch 694: loss improved from 551.60651 to 549.35339, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 549.3534 - mean_absolute_error: 19.7416 - val_loss: 764.0682 - val_mean_absolute_error: 26.7851\n",
      "Epoch 695/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 561.4569 - mean_absolute_error: 19.5266\n",
      "Epoch 695: loss did not improve from 549.35339\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 549.7822 - mean_absolute_error: 19.7414 - val_loss: 759.1494 - val_mean_absolute_error: 26.6932\n",
      "Epoch 696/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 524.8186 - mean_absolute_error: 19.8612\n",
      "Epoch 696: loss improved from 549.35339 to 545.32648, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 545.3265 - mean_absolute_error: 19.6886 - val_loss: 754.1710 - val_mean_absolute_error: 26.5997\n",
      "Epoch 697/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 563.9258 - mean_absolute_error: 20.5872\n",
      "Epoch 697: loss improved from 545.32648 to 542.79706, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 542.7971 - mean_absolute_error: 19.6497 - val_loss: 749.5192 - val_mean_absolute_error: 26.5122\n",
      "Epoch 698/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 549.6388 - mean_absolute_error: 20.1424\n",
      "Epoch 698: loss improved from 542.79706 to 540.30237, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 540.3024 - mean_absolute_error: 19.6095 - val_loss: 744.8174 - val_mean_absolute_error: 26.4233\n",
      "Epoch 699/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 686.2335 - mean_absolute_error: 23.4124\n",
      "Epoch 699: loss improved from 540.30237 to 539.58691, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 539.5869 - mean_absolute_error: 19.6005 - val_loss: 739.8654 - val_mean_absolute_error: 26.3295\n",
      "Epoch 700/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 483.6472 - mean_absolute_error: 18.7064\n",
      "Epoch 700: loss improved from 539.58691 to 534.91406, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 534.9141 - mean_absolute_error: 19.5205 - val_loss: 735.3611 - val_mean_absolute_error: 26.2438\n",
      "Epoch 701/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 596.2194 - mean_absolute_error: 20.6460\n",
      "Epoch 701: loss improved from 534.91406 to 533.30652, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 533.3065 - mean_absolute_error: 19.4954 - val_loss: 730.7148 - val_mean_absolute_error: 26.1551\n",
      "Epoch 702/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 446.7320 - mean_absolute_error: 18.7870\n",
      "Epoch 702: loss improved from 533.30652 to 531.21967, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 531.2197 - mean_absolute_error: 19.4463 - val_loss: 726.0399 - val_mean_absolute_error: 26.0656\n",
      "Epoch 703/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 513.8930 - mean_absolute_error: 18.5977\n",
      "Epoch 703: loss improved from 531.21967 to 530.43909, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 530.4391 - mean_absolute_error: 19.4720 - val_loss: 721.4784 - val_mean_absolute_error: 25.9779\n",
      "Epoch 704/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 581.1764 - mean_absolute_error: 19.7322\n",
      "Epoch 704: loss improved from 530.43909 to 526.46600, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 526.4660 - mean_absolute_error: 19.3928 - val_loss: 716.9078 - val_mean_absolute_error: 25.8898\n",
      "Epoch 705/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 545.7037 - mean_absolute_error: 20.3002\n",
      "Epoch 705: loss improved from 526.46600 to 525.46057, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 525.4606 - mean_absolute_error: 19.3910 - val_loss: 712.1898 - val_mean_absolute_error: 25.7985\n",
      "Epoch 706/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 485.4705 - mean_absolute_error: 18.9090\n",
      "Epoch 706: loss improved from 525.46057 to 523.43451, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 523.4345 - mean_absolute_error: 19.3484 - val_loss: 707.6187 - val_mean_absolute_error: 25.7098\n",
      "Epoch 707/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 478.9844 - mean_absolute_error: 18.8180\n",
      "Epoch 707: loss improved from 523.43451 to 520.37634, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 520.3763 - mean_absolute_error: 19.3130 - val_loss: 703.1619 - val_mean_absolute_error: 25.6230\n",
      "Epoch 708/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 373.2500 - mean_absolute_error: 15.3676\n",
      "Epoch 708: loss improved from 520.37634 to 518.48450, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 518.4845 - mean_absolute_error: 19.2825 - val_loss: 698.6649 - val_mean_absolute_error: 25.5351\n",
      "Epoch 709/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 537.4549 - mean_absolute_error: 19.7247\n",
      "Epoch 709: loss improved from 518.48450 to 515.97064, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 515.9706 - mean_absolute_error: 19.2359 - val_loss: 694.1319 - val_mean_absolute_error: 25.4462\n",
      "Epoch 710/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 439.9975 - mean_absolute_error: 17.4645\n",
      "Epoch 710: loss improved from 515.97064 to 514.36798, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 514.3680 - mean_absolute_error: 19.2197 - val_loss: 689.6024 - val_mean_absolute_error: 25.3570\n",
      "Epoch 711/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 556.6074 - mean_absolute_error: 20.6287\n",
      "Epoch 711: loss improved from 514.36798 to 512.59570, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 512.5957 - mean_absolute_error: 19.1881 - val_loss: 685.4305 - val_mean_absolute_error: 25.2746\n",
      "Epoch 712/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 553.5272 - mean_absolute_error: 20.5608\n",
      "Epoch 712: loss improved from 512.59570 to 510.98392, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 510.9839 - mean_absolute_error: 19.1733 - val_loss: 681.4221 - val_mean_absolute_error: 25.1952\n",
      "Epoch 713/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 348.5482 - mean_absolute_error: 16.4281\n",
      "Epoch 713: loss improved from 510.98392 to 508.72415, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 508.7242 - mean_absolute_error: 19.1226 - val_loss: 677.3642 - val_mean_absolute_error: 25.1145\n",
      "Epoch 714/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 538.3528 - mean_absolute_error: 19.1610\n",
      "Epoch 714: loss improved from 508.72415 to 506.31934, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 506.3193 - mean_absolute_error: 19.0929 - val_loss: 673.1864 - val_mean_absolute_error: 25.0312\n",
      "Epoch 715/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 590.2218 - mean_absolute_error: 22.0615\n",
      "Epoch 715: loss improved from 506.31934 to 506.08777, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 506.0878 - mean_absolute_error: 19.0976 - val_loss: 668.7067 - val_mean_absolute_error: 24.9416\n",
      "Epoch 716/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 487.4926 - mean_absolute_error: 18.6471\n",
      "Epoch 716: loss improved from 506.08777 to 503.21753, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 503.2175 - mean_absolute_error: 19.0537 - val_loss: 664.1404 - val_mean_absolute_error: 24.8499\n",
      "Epoch 717/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 496.0778 - mean_absolute_error: 19.3609\n",
      "Epoch 717: loss improved from 503.21753 to 500.71609, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 500.7161 - mean_absolute_error: 19.0120 - val_loss: 659.6788 - val_mean_absolute_error: 24.7599\n",
      "Epoch 718/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 442.7841 - mean_absolute_error: 16.5604\n",
      "Epoch 718: loss improved from 500.71609 to 498.72501, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 498.7250 - mean_absolute_error: 18.9887 - val_loss: 655.3478 - val_mean_absolute_error: 24.6723\n",
      "Epoch 719/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 453.5721 - mean_absolute_error: 18.5456\n",
      "Epoch 719: loss improved from 498.72501 to 496.70578, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 496.7058 - mean_absolute_error: 18.9566 - val_loss: 651.1949 - val_mean_absolute_error: 24.5880\n",
      "Epoch 720/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 472.8126 - mean_absolute_error: 18.8320\n",
      "Epoch 720: loss improved from 496.70578 to 495.34650, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 495.3465 - mean_absolute_error: 18.9363 - val_loss: 646.9897 - val_mean_absolute_error: 24.5023\n",
      "Epoch 721/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 508.2984 - mean_absolute_error: 19.4489\n",
      "Epoch 721: loss improved from 495.34650 to 493.73032, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 493.7303 - mean_absolute_error: 18.9202 - val_loss: 643.1636 - val_mean_absolute_error: 24.4241\n",
      "Epoch 722/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 494.8556 - mean_absolute_error: 19.0604\n",
      "Epoch 722: loss improved from 493.73032 to 491.37091, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 491.3709 - mean_absolute_error: 18.8820 - val_loss: 639.3764 - val_mean_absolute_error: 24.3465\n",
      "Epoch 723/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 497.7775 - mean_absolute_error: 18.1822\n",
      "Epoch 723: loss improved from 491.37091 to 489.94373, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 489.9437 - mean_absolute_error: 18.8733 - val_loss: 635.6924 - val_mean_absolute_error: 24.2707\n",
      "Epoch 724/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 302.4952 - mean_absolute_error: 13.2752\n",
      "Epoch 724: loss improved from 489.94373 to 488.77301, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 488.7730 - mean_absolute_error: 18.8563 - val_loss: 632.0516 - val_mean_absolute_error: 24.1956\n",
      "Epoch 725/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 455.3957 - mean_absolute_error: 17.6711\n",
      "Epoch 725: loss improved from 488.77301 to 486.96140, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 486.9614 - mean_absolute_error: 18.8321 - val_loss: 628.3185 - val_mean_absolute_error: 24.1183\n",
      "Epoch 726/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 503.1087 - mean_absolute_error: 20.4568\n",
      "Epoch 726: loss improved from 486.96140 to 485.50211, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 485.5021 - mean_absolute_error: 18.8014 - val_loss: 624.6969 - val_mean_absolute_error: 24.0431\n",
      "Epoch 727/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 469.8522 - mean_absolute_error: 18.2263\n",
      "Epoch 727: loss improved from 485.50211 to 484.46405, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 484.4641 - mean_absolute_error: 18.7879 - val_loss: 620.6597 - val_mean_absolute_error: 23.9590\n",
      "Epoch 728/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 572.4315 - mean_absolute_error: 21.4360\n",
      "Epoch 728: loss improved from 484.46405 to 482.46542, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 482.4654 - mean_absolute_error: 18.7626 - val_loss: 616.8005 - val_mean_absolute_error: 23.8783\n",
      "Epoch 729/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 482.1818 - mean_absolute_error: 19.5636\n",
      "Epoch 729: loss improved from 482.46542 to 479.96249, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 479.9625 - mean_absolute_error: 18.7186 - val_loss: 613.0197 - val_mean_absolute_error: 23.7990\n",
      "Epoch 730/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 573.2788 - mean_absolute_error: 20.1147\n",
      "Epoch 730: loss improved from 479.96249 to 478.93384, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 478.9338 - mean_absolute_error: 18.7131 - val_loss: 609.3976 - val_mean_absolute_error: 23.7228\n",
      "Epoch 731/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 530.3867 - mean_absolute_error: 19.5891\n",
      "Epoch 731: loss improved from 478.93384 to 477.52982, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 477.5298 - mean_absolute_error: 18.6954 - val_loss: 605.9676 - val_mean_absolute_error: 23.6504\n",
      "Epoch 732/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 569.1215 - mean_absolute_error: 21.1756\n",
      "Epoch 732: loss improved from 477.52982 to 476.65829, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 476.6583 - mean_absolute_error: 18.6821 - val_loss: 602.3015 - val_mean_absolute_error: 23.5728\n",
      "Epoch 733/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 494.2833 - mean_absolute_error: 18.8990\n",
      "Epoch 733: loss improved from 476.65829 to 475.10657, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 475.1066 - mean_absolute_error: 18.6545 - val_loss: 598.4702 - val_mean_absolute_error: 23.4914\n",
      "Epoch 734/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.6943 - mean_absolute_error: 16.9676\n",
      "Epoch 734: loss improved from 475.10657 to 472.84933, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 472.8493 - mean_absolute_error: 18.6204 - val_loss: 594.6121 - val_mean_absolute_error: 23.4091\n",
      "Epoch 735/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 468.4844 - mean_absolute_error: 18.7591\n",
      "Epoch 735: loss improved from 472.84933 to 470.43661, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 470.4366 - mean_absolute_error: 18.5815 - val_loss: 590.9804 - val_mean_absolute_error: 23.3314\n",
      "Epoch 736/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 441.0628 - mean_absolute_error: 17.1944\n",
      "Epoch 736: loss did not improve from 470.43661\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 470.9991 - mean_absolute_error: 18.6023 - val_loss: 587.1232 - val_mean_absolute_error: 23.2486\n",
      "Epoch 737/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 525.8542 - mean_absolute_error: 20.0234\n",
      "Epoch 737: loss improved from 470.43661 to 468.57495, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 468.5750 - mean_absolute_error: 18.5633 - val_loss: 583.3694 - val_mean_absolute_error: 23.1677\n",
      "Epoch 738/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 462.5108 - mean_absolute_error: 17.7914\n",
      "Epoch 738: loss improved from 468.57495 to 467.72235, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 467.7224 - mean_absolute_error: 18.5542 - val_loss: 579.6858 - val_mean_absolute_error: 23.0881\n",
      "Epoch 739/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 393.9238 - mean_absolute_error: 17.1153\n",
      "Epoch 739: loss improved from 467.72235 to 466.37149, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 466.3715 - mean_absolute_error: 18.5431 - val_loss: 576.3056 - val_mean_absolute_error: 23.0148\n",
      "Epoch 740/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 473.3941 - mean_absolute_error: 18.2880\n",
      "Epoch 740: loss improved from 466.37149 to 464.72668, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 464.7267 - mean_absolute_error: 18.5195 - val_loss: 572.5610 - val_mean_absolute_error: 22.9333\n",
      "Epoch 741/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 515.8615 - mean_absolute_error: 19.4997\n",
      "Epoch 741: loss improved from 464.72668 to 462.21301, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 462.2130 - mean_absolute_error: 18.4671 - val_loss: 569.1609 - val_mean_absolute_error: 22.8590\n",
      "Epoch 742/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 653.3882 - mean_absolute_error: 22.7828\n",
      "Epoch 742: loss improved from 462.21301 to 460.95471, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 460.9547 - mean_absolute_error: 18.4409 - val_loss: 565.6732 - val_mean_absolute_error: 22.7826\n",
      "Epoch 743/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 465.8362 - mean_absolute_error: 18.4151\n",
      "Epoch 743: loss improved from 460.95471 to 460.31418, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 460.3142 - mean_absolute_error: 18.4536 - val_loss: 562.3031 - val_mean_absolute_error: 22.7085\n",
      "Epoch 744/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 326.6020 - mean_absolute_error: 15.0412\n",
      "Epoch 744: loss improved from 460.31418 to 458.47098, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 458.4710 - mean_absolute_error: 18.4220 - val_loss: 558.7817 - val_mean_absolute_error: 22.6309\n",
      "Epoch 745/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 472.0664 - mean_absolute_error: 18.0777\n",
      "Epoch 745: loss improved from 458.47098 to 457.01379, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 457.0138 - mean_absolute_error: 18.3899 - val_loss: 555.3667 - val_mean_absolute_error: 22.5553\n",
      "Epoch 746/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 421.0318 - mean_absolute_error: 17.7163\n",
      "Epoch 746: loss improved from 457.01379 to 456.19214, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 456.1921 - mean_absolute_error: 18.3813 - val_loss: 552.0330 - val_mean_absolute_error: 22.4813\n",
      "Epoch 747/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 390.3535 - mean_absolute_error: 16.4274\n",
      "Epoch 747: loss improved from 456.19214 to 454.33090, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 454.3309 - mean_absolute_error: 18.3452 - val_loss: 548.7562 - val_mean_absolute_error: 22.4083\n",
      "Epoch 748/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 495.9976 - mean_absolute_error: 19.1820\n",
      "Epoch 748: loss improved from 454.33090 to 453.23212, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 453.2321 - mean_absolute_error: 18.3451 - val_loss: 545.4055 - val_mean_absolute_error: 22.3334\n",
      "Epoch 749/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 409.2040 - mean_absolute_error: 17.9777\n",
      "Epoch 749: loss improved from 453.23212 to 451.94012, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 451.9401 - mean_absolute_error: 18.3321 - val_loss: 542.2501 - val_mean_absolute_error: 22.2626\n",
      "Epoch 750/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 347.5309 - mean_absolute_error: 15.7459\n",
      "Epoch 750: loss improved from 451.94012 to 451.05261, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 451.0526 - mean_absolute_error: 18.3144 - val_loss: 538.9713 - val_mean_absolute_error: 22.1889\n",
      "Epoch 751/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 426.5481 - mean_absolute_error: 17.4296\n",
      "Epoch 751: loss improved from 451.05261 to 449.47125, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 449.4713 - mean_absolute_error: 18.2846 - val_loss: 535.9700 - val_mean_absolute_error: 22.1211\n",
      "Epoch 752/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 432.7942 - mean_absolute_error: 17.9629\n",
      "Epoch 752: loss improved from 449.47125 to 448.29703, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 448.2970 - mean_absolute_error: 18.2558 - val_loss: 532.9315 - val_mean_absolute_error: 22.0524\n",
      "Epoch 753/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 469.0928 - mean_absolute_error: 18.7322\n",
      "Epoch 753: loss improved from 448.29703 to 447.28949, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 447.2895 - mean_absolute_error: 18.2557 - val_loss: 529.9769 - val_mean_absolute_error: 21.9853\n",
      "Epoch 754/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 354.8348 - mean_absolute_error: 16.1449\n",
      "Epoch 754: loss improved from 447.28949 to 445.78430, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 445.7843 - mean_absolute_error: 18.2336 - val_loss: 526.8413 - val_mean_absolute_error: 21.9138\n",
      "Epoch 755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 369.2104 - mean_absolute_error: 16.4138\n",
      "Epoch 755: loss improved from 445.78430 to 445.19797, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 445.1980 - mean_absolute_error: 18.2303 - val_loss: 523.9026 - val_mean_absolute_error: 21.8467\n",
      "Epoch 756/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 466.8790 - mean_absolute_error: 18.9923\n",
      "Epoch 756: loss improved from 445.19797 to 444.81030, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 444.8103 - mean_absolute_error: 18.2188 - val_loss: 520.9490 - val_mean_absolute_error: 21.7790\n",
      "Epoch 757/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 408.7410 - mean_absolute_error: 17.4264\n",
      "Epoch 757: loss improved from 444.81030 to 442.92218, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 442.9222 - mean_absolute_error: 18.1893 - val_loss: 517.5734 - val_mean_absolute_error: 21.7013\n",
      "Epoch 758/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 438.6836 - mean_absolute_error: 18.1115\n",
      "Epoch 758: loss improved from 442.92218 to 442.30481, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 442.3048 - mean_absolute_error: 18.1705 - val_loss: 514.1068 - val_mean_absolute_error: 21.6213\n",
      "Epoch 759/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 361.1709 - mean_absolute_error: 16.4569\n",
      "Epoch 759: loss improved from 442.30481 to 439.95197, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 439.9520 - mean_absolute_error: 18.1332 - val_loss: 511.0239 - val_mean_absolute_error: 21.5499\n",
      "Epoch 760/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 459.3914 - mean_absolute_error: 19.2184\n",
      "Epoch 760: loss did not improve from 439.95197\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 440.1408 - mean_absolute_error: 18.1522 - val_loss: 508.0450 - val_mean_absolute_error: 21.4807\n",
      "Epoch 761/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 493.4922 - mean_absolute_error: 19.1804\n",
      "Epoch 761: loss improved from 439.95197 to 438.54593, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 438.5459 - mean_absolute_error: 18.1218 - val_loss: 504.9312 - val_mean_absolute_error: 21.4081\n",
      "Epoch 762/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 513.5641 - mean_absolute_error: 19.8523\n",
      "Epoch 762: loss improved from 438.54593 to 436.56323, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 436.5632 - mean_absolute_error: 18.0808 - val_loss: 501.9620 - val_mean_absolute_error: 21.3386\n",
      "Epoch 763/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 456.2552 - mean_absolute_error: 19.7292\n",
      "Epoch 763: loss improved from 436.56323 to 435.81723, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 435.8172 - mean_absolute_error: 18.0701 - val_loss: 499.0656 - val_mean_absolute_error: 21.2707\n",
      "Epoch 764/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.1476 - mean_absolute_error: 16.2977\n",
      "Epoch 764: loss improved from 435.81723 to 434.46591, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 434.4659 - mean_absolute_error: 18.0417 - val_loss: 496.1796 - val_mean_absolute_error: 21.2027\n",
      "Epoch 765/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 513.6186 - mean_absolute_error: 19.3178\n",
      "Epoch 765: loss improved from 434.46591 to 433.99957, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 433.9996 - mean_absolute_error: 18.0446 - val_loss: 493.4222 - val_mean_absolute_error: 21.1376\n",
      "Epoch 766/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 357.8041 - mean_absolute_error: 16.2153\n",
      "Epoch 766: loss did not improve from 433.99957\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 434.6852 - mean_absolute_error: 18.0485 - val_loss: 490.6720 - val_mean_absolute_error: 21.0724\n",
      "Epoch 767/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 527.3166 - mean_absolute_error: 20.0829\n",
      "Epoch 767: loss improved from 433.99957 to 432.25879, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 432.2588 - mean_absolute_error: 18.0086 - val_loss: 487.7604 - val_mean_absolute_error: 21.0032\n",
      "Epoch 768/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 409.3601 - mean_absolute_error: 16.9428\n",
      "Epoch 768: loss improved from 432.25879 to 431.62677, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 431.6268 - mean_absolute_error: 17.9953 - val_loss: 484.8923 - val_mean_absolute_error: 20.9348\n",
      "Epoch 769/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 507.6487 - mean_absolute_error: 20.2655\n",
      "Epoch 769: loss improved from 431.62677 to 429.96936, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 429.9694 - mean_absolute_error: 17.9779 - val_loss: 482.1297 - val_mean_absolute_error: 20.8687\n",
      "Epoch 770/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 457.0603 - mean_absolute_error: 18.9019\n",
      "Epoch 770: loss improved from 429.96936 to 429.90433, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 429.9043 - mean_absolute_error: 17.9718 - val_loss: 479.4608 - val_mean_absolute_error: 20.8047\n",
      "Epoch 771/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 535.9001 - mean_absolute_error: 20.7347\n",
      "Epoch 771: loss improved from 429.90433 to 428.64484, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 428.6448 - mean_absolute_error: 17.9512 - val_loss: 476.7218 - val_mean_absolute_error: 20.7388\n",
      "Epoch 772/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 466.6735 - mean_absolute_error: 18.5206\n",
      "Epoch 772: loss improved from 428.64484 to 428.58618, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 428.5862 - mean_absolute_error: 17.9620 - val_loss: 474.1851 - val_mean_absolute_error: 20.6775\n",
      "Epoch 773/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 525.3860 - mean_absolute_error: 20.0935\n",
      "Epoch 773: loss improved from 428.58618 to 427.72177, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 427.7218 - mean_absolute_error: 17.9459 - val_loss: 471.9044 - val_mean_absolute_error: 20.6223\n",
      "Epoch 774/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 504.4611 - mean_absolute_error: 19.7633\n",
      "Epoch 774: loss improved from 427.72177 to 425.38547, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 425.3855 - mean_absolute_error: 17.8967 - val_loss: 469.5766 - val_mean_absolute_error: 20.5658\n",
      "Epoch 775/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 486.4293 - mean_absolute_error: 19.6014\n",
      "Epoch 775: loss did not improve from 425.38547\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 425.9385 - mean_absolute_error: 17.9128 - val_loss: 467.2626 - val_mean_absolute_error: 20.5095\n",
      "Epoch 776/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 509.9635 - mean_absolute_error: 19.5046\n",
      "Epoch 776: loss improved from 425.38547 to 424.04645, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 424.0464 - mean_absolute_error: 17.8639 - val_loss: 464.8863 - val_mean_absolute_error: 20.4514\n",
      "Epoch 777/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 554.0067 - mean_absolute_error: 20.5792\n",
      "Epoch 777: loss improved from 424.04645 to 423.27673, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 423.2767 - mean_absolute_error: 17.8587 - val_loss: 462.3866 - val_mean_absolute_error: 20.3902\n",
      "Epoch 778/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 522.7951 - mean_absolute_error: 20.7175\n",
      "Epoch 778: loss improved from 423.27673 to 423.08533, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 14ms/step - loss: 423.0853 - mean_absolute_error: 17.8680 - val_loss: 460.0936 - val_mean_absolute_error: 20.3339\n",
      "Epoch 779/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.2021 - mean_absolute_error: 16.9453\n",
      "Epoch 779: loss improved from 423.08533 to 422.07288, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 422.0729 - mean_absolute_error: 17.8484 - val_loss: 457.7488 - val_mean_absolute_error: 20.2762\n",
      "Epoch 780/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 350.5880 - mean_absolute_error: 16.3804\n",
      "Epoch 780: loss improved from 422.07288 to 421.40839, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 421.4084 - mean_absolute_error: 17.8410 - val_loss: 455.2670 - val_mean_absolute_error: 20.2149\n",
      "Epoch 781/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 522.1072 - mean_absolute_error: 20.7192\n",
      "Epoch 781: loss improved from 421.40839 to 421.05765, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 421.0576 - mean_absolute_error: 17.8191 - val_loss: 452.9402 - val_mean_absolute_error: 20.1573\n",
      "Epoch 782/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 446.0827 - mean_absolute_error: 18.4606\n",
      "Epoch 782: loss improved from 421.05765 to 420.32013, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 420.3201 - mean_absolute_error: 17.8231 - val_loss: 450.6379 - val_mean_absolute_error: 20.1001\n",
      "Epoch 783/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.2662 - mean_absolute_error: 17.3908\n",
      "Epoch 783: loss improved from 420.32013 to 419.76810, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 419.7681 - mean_absolute_error: 17.8144 - val_loss: 448.1599 - val_mean_absolute_error: 20.0383\n",
      "Epoch 784/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 440.1661 - mean_absolute_error: 18.6132\n",
      "Epoch 784: loss improved from 419.76810 to 418.14343, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 418.1434 - mean_absolute_error: 17.7773 - val_loss: 445.7480 - val_mean_absolute_error: 19.9781\n",
      "Epoch 785/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 329.5153 - mean_absolute_error: 14.8104\n",
      "Epoch 785: loss improved from 418.14343 to 417.52026, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 417.5203 - mean_absolute_error: 17.7630 - val_loss: 443.1951 - val_mean_absolute_error: 19.9141\n",
      "Epoch 786/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 565.4075 - mean_absolute_error: 21.5978\n",
      "Epoch 786: loss improved from 417.52026 to 416.80222, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 416.8022 - mean_absolute_error: 17.7537 - val_loss: 440.5983 - val_mean_absolute_error: 19.8488\n",
      "Epoch 787/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 533.4296 - mean_absolute_error: 21.1612\n",
      "Epoch 787: loss did not improve from 416.80222\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 416.8169 - mean_absolute_error: 17.7582 - val_loss: 438.4007 - val_mean_absolute_error: 19.7933\n",
      "Epoch 788/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 436.5571 - mean_absolute_error: 17.5935\n",
      "Epoch 788: loss improved from 416.80222 to 414.90958, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 414.9096 - mean_absolute_error: 17.7235 - val_loss: 436.1027 - val_mean_absolute_error: 19.7352\n",
      "Epoch 789/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 500.6166 - mean_absolute_error: 20.1943\n",
      "Epoch 789: loss improved from 414.90958 to 414.69669, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 414.6967 - mean_absolute_error: 17.7212 - val_loss: 433.7754 - val_mean_absolute_error: 19.6761\n",
      "Epoch 790/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 395.3587 - mean_absolute_error: 16.5246\n",
      "Epoch 790: loss improved from 414.69669 to 414.02997, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 414.0300 - mean_absolute_error: 17.7012 - val_loss: 431.3730 - val_mean_absolute_error: 19.6150\n",
      "Epoch 791/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 503.1796 - mean_absolute_error: 18.9637\n",
      "Epoch 791: loss improved from 414.02997 to 413.60132, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 413.6013 - mean_absolute_error: 17.6895 - val_loss: 429.1321 - val_mean_absolute_error: 19.5578\n",
      "Epoch 792/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 393.9507 - mean_absolute_error: 16.6701\n",
      "Epoch 792: loss improved from 413.60132 to 412.51968, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 412.5197 - mean_absolute_error: 17.6826 - val_loss: 426.6812 - val_mean_absolute_error: 19.4950\n",
      "Epoch 793/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 359.0766 - mean_absolute_error: 16.5508\n",
      "Epoch 793: loss did not improve from 412.51968\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 412.7726 - mean_absolute_error: 17.6820 - val_loss: 424.6611 - val_mean_absolute_error: 19.4432\n",
      "Epoch 794/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 422.0610 - mean_absolute_error: 17.6658\n",
      "Epoch 794: loss improved from 412.51968 to 411.42966, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 411.4297 - mean_absolute_error: 17.6684 - val_loss: 422.8352 - val_mean_absolute_error: 19.3961\n",
      "Epoch 795/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 466.3945 - mean_absolute_error: 18.9690\n",
      "Epoch 795: loss improved from 411.42966 to 411.14957, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 411.1496 - mean_absolute_error: 17.6467 - val_loss: 420.4004 - val_mean_absolute_error: 19.3333\n",
      "Epoch 796/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 522.5980 - mean_absolute_error: 20.4647\n",
      "Epoch 796: loss improved from 411.14957 to 410.28458, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 410.2846 - mean_absolute_error: 17.6430 - val_loss: 418.2535 - val_mean_absolute_error: 19.2777\n",
      "Epoch 797/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 294.4460 - mean_absolute_error: 14.3806\n",
      "Epoch 797: loss improved from 410.28458 to 409.19388, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 409.1939 - mean_absolute_error: 17.6237 - val_loss: 416.0337 - val_mean_absolute_error: 19.2200\n",
      "Epoch 798/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 413.2060 - mean_absolute_error: 18.0264\n",
      "Epoch 798: loss improved from 409.19388 to 408.95483, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 408.9548 - mean_absolute_error: 17.6163 - val_loss: 413.8841 - val_mean_absolute_error: 19.1640\n",
      "Epoch 799/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 327.5790 - mean_absolute_error: 15.6543\n",
      "Epoch 799: loss improved from 408.95483 to 408.57266, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 408.5727 - mean_absolute_error: 17.6128 - val_loss: 411.8225 - val_mean_absolute_error: 19.1101\n",
      "Epoch 800/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 313.1041 - mean_absolute_error: 14.3173\n",
      "Epoch 800: loss improved from 408.57266 to 407.34171, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 407.3417 - mean_absolute_error: 17.5841 - val_loss: 409.8360 - val_mean_absolute_error: 19.0581\n",
      "Epoch 801/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 407.9542 - mean_absolute_error: 17.8654\n",
      "Epoch 801: loss improved from 407.34171 to 406.59332, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 406.5933 - mean_absolute_error: 17.5649 - val_loss: 407.7957 - val_mean_absolute_error: 19.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 426.0569 - mean_absolute_error: 17.9568\n",
      "Epoch 802: loss did not improve from 406.59332\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 406.8998 - mean_absolute_error: 17.5862 - val_loss: 405.7924 - val_mean_absolute_error: 18.9517\n",
      "Epoch 803/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 407.5381 - mean_absolute_error: 17.7089\n",
      "Epoch 803: loss improved from 406.59332 to 405.92310, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 405.9231 - mean_absolute_error: 17.5585 - val_loss: 404.1851 - val_mean_absolute_error: 18.9093\n",
      "Epoch 804/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 375.0644 - mean_absolute_error: 16.4138\n",
      "Epoch 804: loss improved from 405.92310 to 405.83633, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 405.8363 - mean_absolute_error: 17.5713 - val_loss: 402.4468 - val_mean_absolute_error: 18.8632\n",
      "Epoch 805/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 294.5000 - mean_absolute_error: 14.0609\n",
      "Epoch 805: loss improved from 405.83633 to 404.61038, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 404.6104 - mean_absolute_error: 17.5297 - val_loss: 400.4182 - val_mean_absolute_error: 18.8094\n",
      "Epoch 806/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 429.0322 - mean_absolute_error: 17.4841\n",
      "Epoch 806: loss did not improve from 404.61038\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 405.3354 - mean_absolute_error: 17.5505 - val_loss: 398.5116 - val_mean_absolute_error: 18.7586\n",
      "Epoch 807/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 372.8965 - mean_absolute_error: 17.2868\n",
      "Epoch 807: loss improved from 404.61038 to 404.04218, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 404.0422 - mean_absolute_error: 17.5254 - val_loss: 396.5143 - val_mean_absolute_error: 18.7053\n",
      "Epoch 808/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 441.9395 - mean_absolute_error: 17.9648\n",
      "Epoch 808: loss improved from 404.04218 to 403.64233, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 403.6423 - mean_absolute_error: 17.5150 - val_loss: 394.4338 - val_mean_absolute_error: 18.6496\n",
      "Epoch 809/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 437.3332 - mean_absolute_error: 18.0967\n",
      "Epoch 809: loss did not improve from 403.64233\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 404.6332 - mean_absolute_error: 17.5288 - val_loss: 392.5009 - val_mean_absolute_error: 18.5977\n",
      "Epoch 810/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 379.7898 - mean_absolute_error: 16.8341\n",
      "Epoch 810: loss improved from 403.64233 to 402.91074, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 402.9107 - mean_absolute_error: 17.5003 - val_loss: 390.8342 - val_mean_absolute_error: 18.5529\n",
      "Epoch 811/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 439.4428 - mean_absolute_error: 18.5155\n",
      "Epoch 811: loss improved from 402.91074 to 402.22589, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 402.2259 - mean_absolute_error: 17.4887 - val_loss: 389.0186 - val_mean_absolute_error: 18.5039\n",
      "Epoch 812/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 487.7817 - mean_absolute_error: 19.2933\n",
      "Epoch 812: loss improved from 402.22589 to 401.54126, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 401.5413 - mean_absolute_error: 17.4712 - val_loss: 387.2730 - val_mean_absolute_error: 18.4567\n",
      "Epoch 813/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.4880 - mean_absolute_error: 16.6288\n",
      "Epoch 813: loss improved from 401.54126 to 401.11646, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 401.1165 - mean_absolute_error: 17.4658 - val_loss: 385.6506 - val_mean_absolute_error: 18.4126\n",
      "Epoch 814/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 396.7256 - mean_absolute_error: 17.2485\n",
      "Epoch 814: loss did not improve from 401.11646\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 401.2671 - mean_absolute_error: 17.4710 - val_loss: 383.8980 - val_mean_absolute_error: 18.3650\n",
      "Epoch 815/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 404.7468 - mean_absolute_error: 17.4966\n",
      "Epoch 815: loss improved from 401.11646 to 399.92407, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 399.9241 - mean_absolute_error: 17.4391 - val_loss: 382.1607 - val_mean_absolute_error: 18.3176\n",
      "Epoch 816/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 375.9512 - mean_absolute_error: 15.7589\n",
      "Epoch 816: loss did not improve from 399.92407\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 400.3470 - mean_absolute_error: 17.4630 - val_loss: 380.3764 - val_mean_absolute_error: 18.2689\n",
      "Epoch 817/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 481.7513 - mean_absolute_error: 19.9751\n",
      "Epoch 817: loss improved from 399.92407 to 399.33926, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 399.3393 - mean_absolute_error: 17.4254 - val_loss: 378.4680 - val_mean_absolute_error: 18.2166\n",
      "Epoch 818/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 493.3237 - mean_absolute_error: 19.5425\n",
      "Epoch 818: loss did not improve from 399.33926\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 399.7063 - mean_absolute_error: 17.4377 - val_loss: 376.6592 - val_mean_absolute_error: 18.1668\n",
      "Epoch 819/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 303.2641 - mean_absolute_error: 14.7095\n",
      "Epoch 819: loss improved from 399.33926 to 398.59189, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 398.5919 - mean_absolute_error: 17.4158 - val_loss: 374.9931 - val_mean_absolute_error: 18.1209\n",
      "Epoch 820/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 446.3423 - mean_absolute_error: 18.5830\n",
      "Epoch 820: loss improved from 398.59189 to 398.26270, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 398.2627 - mean_absolute_error: 17.4089 - val_loss: 373.3169 - val_mean_absolute_error: 18.0746\n",
      "Epoch 821/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 399.9301 - mean_absolute_error: 17.8023\n",
      "Epoch 821: loss did not improve from 398.26270\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 398.2716 - mean_absolute_error: 17.4241 - val_loss: 371.4376 - val_mean_absolute_error: 18.0226\n",
      "Epoch 822/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 435.3116 - mean_absolute_error: 18.3197\n",
      "Epoch 822: loss improved from 398.26270 to 397.44110, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 397.4411 - mean_absolute_error: 17.3895 - val_loss: 369.6498 - val_mean_absolute_error: 17.9729\n",
      "Epoch 823/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.2049 - mean_absolute_error: 16.7448\n",
      "Epoch 823: loss improved from 397.44110 to 396.97842, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 396.9784 - mean_absolute_error: 17.3878 - val_loss: 368.0425 - val_mean_absolute_error: 17.9281\n",
      "Epoch 824/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 503.0620 - mean_absolute_error: 20.2032\n",
      "Epoch 824: loss improved from 396.97842 to 396.75427, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 396.7543 - mean_absolute_error: 17.3826 - val_loss: 366.4791 - val_mean_absolute_error: 17.8845\n",
      "Epoch 825/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 416.3681 - mean_absolute_error: 18.3715\n",
      "Epoch 825: loss improved from 396.75427 to 396.58264, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 396.5826 - mean_absolute_error: 17.3733 - val_loss: 364.8607 - val_mean_absolute_error: 17.8392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 255.5574 - mean_absolute_error: 14.0961\n",
      "Epoch 826: loss improved from 396.58264 to 395.98956, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 395.9896 - mean_absolute_error: 17.3674 - val_loss: 363.4099 - val_mean_absolute_error: 17.7985\n",
      "Epoch 827/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 382.9101 - mean_absolute_error: 17.1635\n",
      "Epoch 827: loss did not improve from 395.98956\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 396.0978 - mean_absolute_error: 17.3719 - val_loss: 361.8962 - val_mean_absolute_error: 17.7559\n",
      "Epoch 828/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.2642 - mean_absolute_error: 17.9129\n",
      "Epoch 828: loss improved from 395.98956 to 395.46487, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 395.4649 - mean_absolute_error: 17.3420 - val_loss: 360.6090 - val_mean_absolute_error: 17.7196\n",
      "Epoch 829/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 332.4516 - mean_absolute_error: 16.3780\n",
      "Epoch 829: loss improved from 395.46487 to 394.74942, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 394.7494 - mean_absolute_error: 17.3292 - val_loss: 359.3131 - val_mean_absolute_error: 17.6830\n",
      "Epoch 830/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 525.8235 - mean_absolute_error: 20.8578\n",
      "Epoch 830: loss improved from 394.74942 to 394.71866, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 394.7187 - mean_absolute_error: 17.3375 - val_loss: 358.1631 - val_mean_absolute_error: 17.6504\n",
      "Epoch 831/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 485.4160 - mean_absolute_error: 19.5812\n",
      "Epoch 831: loss did not improve from 394.71866\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 395.0611 - mean_absolute_error: 17.3473 - val_loss: 356.8072 - val_mean_absolute_error: 17.6120\n",
      "Epoch 832/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.5426 - mean_absolute_error: 16.4966\n",
      "Epoch 832: loss improved from 394.71866 to 394.31165, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 394.3116 - mean_absolute_error: 17.3362 - val_loss: 355.3781 - val_mean_absolute_error: 17.5714\n",
      "Epoch 833/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 431.4056 - mean_absolute_error: 18.3597\n",
      "Epoch 833: loss did not improve from 394.31165\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 394.6844 - mean_absolute_error: 17.3355 - val_loss: 353.4345 - val_mean_absolute_error: 17.5160\n",
      "Epoch 834/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 414.7374 - mean_absolute_error: 17.7683\n",
      "Epoch 834: loss improved from 394.31165 to 393.90891, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 393.9089 - mean_absolute_error: 17.3249 - val_loss: 351.9594 - val_mean_absolute_error: 17.4738\n",
      "Epoch 835/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 518.8668 - mean_absolute_error: 20.3631\n",
      "Epoch 835: loss improved from 393.90891 to 393.07504, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 393.0750 - mean_absolute_error: 17.3044 - val_loss: 350.4399 - val_mean_absolute_error: 17.4303\n",
      "Epoch 836/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 443.0857 - mean_absolute_error: 18.8449\n",
      "Epoch 836: loss did not improve from 393.07504\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 393.1125 - mean_absolute_error: 17.3103 - val_loss: 348.9810 - val_mean_absolute_error: 17.3884\n",
      "Epoch 837/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.4270 - mean_absolute_error: 16.6591\n",
      "Epoch 837: loss improved from 393.07504 to 392.49423, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 392.4942 - mean_absolute_error: 17.2913 - val_loss: 347.5017 - val_mean_absolute_error: 17.3458\n",
      "Epoch 838/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 425.7476 - mean_absolute_error: 17.8363\n",
      "Epoch 838: loss improved from 392.49423 to 392.46936, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 392.4694 - mean_absolute_error: 17.2939 - val_loss: 346.1075 - val_mean_absolute_error: 17.3056\n",
      "Epoch 839/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 507.2468 - mean_absolute_error: 20.3244\n",
      "Epoch 839: loss did not improve from 392.46936\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 392.6147 - mean_absolute_error: 17.2959 - val_loss: 344.6716 - val_mean_absolute_error: 17.2640\n",
      "Epoch 840/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 371.5276 - mean_absolute_error: 16.5438\n",
      "Epoch 840: loss did not improve from 392.46936\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 392.6078 - mean_absolute_error: 17.2929 - val_loss: 343.1415 - val_mean_absolute_error: 17.2197\n",
      "Epoch 841/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 393.6788 - mean_absolute_error: 17.5981\n",
      "Epoch 841: loss improved from 392.46936 to 391.36749, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 391.3675 - mean_absolute_error: 17.2627 - val_loss: 341.7039 - val_mean_absolute_error: 17.1779\n",
      "Epoch 842/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 516.2051 - mean_absolute_error: 20.3515\n",
      "Epoch 842: loss did not improve from 391.36749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 391.4834 - mean_absolute_error: 17.2709 - val_loss: 340.3179 - val_mean_absolute_error: 17.1375\n",
      "Epoch 843/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.0777 - mean_absolute_error: 18.0881\n",
      "Epoch 843: loss improved from 391.36749 to 390.80609, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 390.8061 - mean_absolute_error: 17.2546 - val_loss: 339.2394 - val_mean_absolute_error: 17.1060\n",
      "Epoch 844/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 417.6524 - mean_absolute_error: 17.8762\n",
      "Epoch 844: loss improved from 390.80609 to 390.66638, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 390.6664 - mean_absolute_error: 17.2580 - val_loss: 337.9545 - val_mean_absolute_error: 17.0684\n",
      "Epoch 845/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 354.2373 - mean_absolute_error: 16.0832\n",
      "Epoch 845: loss did not improve from 390.66638\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 390.7952 - mean_absolute_error: 17.2538 - val_loss: 336.7988 - val_mean_absolute_error: 17.0345\n",
      "Epoch 846/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 344.2883 - mean_absolute_error: 16.4589\n",
      "Epoch 846: loss did not improve from 390.66638\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 391.0919 - mean_absolute_error: 17.2655 - val_loss: 335.3819 - val_mean_absolute_error: 16.9929\n",
      "Epoch 847/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.1794 - mean_absolute_error: 16.8327\n",
      "Epoch 847: loss improved from 390.66638 to 390.36703, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 390.3670 - mean_absolute_error: 17.2382 - val_loss: 333.9001 - val_mean_absolute_error: 16.9492\n",
      "Epoch 848/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 312.8248 - mean_absolute_error: 14.6792\n",
      "Epoch 848: loss improved from 390.36703 to 389.74149, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 389.7415 - mean_absolute_error: 17.2297 - val_loss: 332.5579 - val_mean_absolute_error: 16.9096\n",
      "Epoch 849/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.0847 - mean_absolute_error: 16.9597\n",
      "Epoch 849: loss improved from 389.74149 to 389.40259, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 389.4026 - mean_absolute_error: 17.2202 - val_loss: 331.3244 - val_mean_absolute_error: 16.8730\n",
      "Epoch 850/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 436.9852 - mean_absolute_error: 18.2182\n",
      "Epoch 850: loss improved from 389.40259 to 389.10141, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 389.1014 - mean_absolute_error: 17.2182 - val_loss: 330.0508 - val_mean_absolute_error: 16.8353\n",
      "Epoch 851/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 425.3554 - mean_absolute_error: 18.1530\n",
      "Epoch 851: loss improved from 389.10141 to 388.57007, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 388.5701 - mean_absolute_error: 17.2018 - val_loss: 328.9534 - val_mean_absolute_error: 16.8026\n",
      "Epoch 852/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 339.7934 - mean_absolute_error: 15.8429\n",
      "Epoch 852: loss did not improve from 388.57007\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 388.8565 - mean_absolute_error: 17.2087 - val_loss: 327.6085 - val_mean_absolute_error: 16.7626\n",
      "Epoch 853/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 487.1727 - mean_absolute_error: 20.0557\n",
      "Epoch 853: loss did not improve from 388.57007\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 388.9967 - mean_absolute_error: 17.2209 - val_loss: 326.1341 - val_mean_absolute_error: 16.7185\n",
      "Epoch 854/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 314.2808 - mean_absolute_error: 15.4606\n",
      "Epoch 854: loss improved from 388.57007 to 387.93811, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 387.9381 - mean_absolute_error: 17.1818 - val_loss: 324.7338 - val_mean_absolute_error: 16.6766\n",
      "Epoch 855/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 374.3109 - mean_absolute_error: 16.6244\n",
      "Epoch 855: loss did not improve from 387.93811\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 389.0720 - mean_absolute_error: 17.2091 - val_loss: 323.4183 - val_mean_absolute_error: 16.6371\n",
      "Epoch 856/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.8832 - mean_absolute_error: 17.9504\n",
      "Epoch 856: loss did not improve from 387.93811\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 388.5291 - mean_absolute_error: 17.1954 - val_loss: 322.0491 - val_mean_absolute_error: 16.5959\n",
      "Epoch 857/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 358.8554 - mean_absolute_error: 16.4827\n",
      "Epoch 857: loss improved from 387.93811 to 387.76825, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 387.7682 - mean_absolute_error: 17.1803 - val_loss: 320.8587 - val_mean_absolute_error: 16.5600\n",
      "Epoch 858/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 332.5630 - mean_absolute_error: 15.5892\n",
      "Epoch 858: loss did not improve from 387.76825\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 389.1317 - mean_absolute_error: 17.2040 - val_loss: 319.5417 - val_mean_absolute_error: 16.5202\n",
      "Epoch 859/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 312.3184 - mean_absolute_error: 15.2356\n",
      "Epoch 859: loss improved from 387.76825 to 387.27109, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 387.2711 - mean_absolute_error: 17.1651 - val_loss: 317.9690 - val_mean_absolute_error: 16.4725\n",
      "Epoch 860/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 417.1326 - mean_absolute_error: 17.2966\n",
      "Epoch 860: loss improved from 387.27109 to 387.11765, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 387.1176 - mean_absolute_error: 17.1666 - val_loss: 316.5618 - val_mean_absolute_error: 16.4298\n",
      "Epoch 861/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 389.6241 - mean_absolute_error: 17.5093\n",
      "Epoch 861: loss did not improve from 387.11765\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 387.5734 - mean_absolute_error: 17.1720 - val_loss: 315.7682 - val_mean_absolute_error: 16.4056\n",
      "Epoch 862/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 350.5085 - mean_absolute_error: 16.5164\n",
      "Epoch 862: loss improved from 387.11765 to 386.55746, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 386.5575 - mean_absolute_error: 17.1536 - val_loss: 314.8762 - val_mean_absolute_error: 16.3784\n",
      "Epoch 863/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 354.4231 - mean_absolute_error: 16.5544\n",
      "Epoch 863: loss improved from 386.55746 to 385.56094, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 385.5609 - mean_absolute_error: 17.1184 - val_loss: 313.9888 - val_mean_absolute_error: 16.3513\n",
      "Epoch 864/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 374.3229 - mean_absolute_error: 17.3781\n",
      "Epoch 864: loss did not improve from 385.56094\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 387.1452 - mean_absolute_error: 17.1861 - val_loss: 313.0445 - val_mean_absolute_error: 16.3224\n",
      "Epoch 865/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 403.8862 - mean_absolute_error: 17.1022\n",
      "Epoch 865: loss did not improve from 385.56094\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 385.9788 - mean_absolute_error: 17.1413 - val_loss: 312.1362 - val_mean_absolute_error: 16.2945\n",
      "Epoch 866/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 394.2062 - mean_absolute_error: 17.2235\n",
      "Epoch 866: loss did not improve from 385.56094\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 386.1598 - mean_absolute_error: 17.1455 - val_loss: 311.1480 - val_mean_absolute_error: 16.2642\n",
      "Epoch 867/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 341.4223 - mean_absolute_error: 16.0711\n",
      "Epoch 867: loss did not improve from 385.56094\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 385.9901 - mean_absolute_error: 17.1373 - val_loss: 310.2118 - val_mean_absolute_error: 16.2354\n",
      "Epoch 868/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 479.0757 - mean_absolute_error: 18.6135\n",
      "Epoch 868: loss did not improve from 385.56094\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 385.6892 - mean_absolute_error: 17.1270 - val_loss: 309.0345 - val_mean_absolute_error: 16.1991\n",
      "Epoch 869/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 336.5319 - mean_absolute_error: 15.6098\n",
      "Epoch 869: loss improved from 385.56094 to 385.35620, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 385.3562 - mean_absolute_error: 17.1169 - val_loss: 307.9647 - val_mean_absolute_error: 16.1660\n",
      "Epoch 870/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 296.9996 - mean_absolute_error: 14.8722\n",
      "Epoch 870: loss did not improve from 385.35620\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 385.5675 - mean_absolute_error: 17.1211 - val_loss: 306.8076 - val_mean_absolute_error: 16.1302\n",
      "Epoch 871/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 345.2540 - mean_absolute_error: 15.5657\n",
      "Epoch 871: loss improved from 385.35620 to 385.16272, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 385.1627 - mean_absolute_error: 17.1227 - val_loss: 305.7911 - val_mean_absolute_error: 16.0986\n",
      "Epoch 872/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 382.6248 - mean_absolute_error: 16.7434\n",
      "Epoch 872: loss did not improve from 385.16272\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 385.2016 - mean_absolute_error: 17.1094 - val_loss: 304.8771 - val_mean_absolute_error: 16.0702\n",
      "Epoch 873/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 370.7300 - mean_absolute_error: 17.5243\n",
      "Epoch 873: loss did not improve from 385.16272\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 385.4222 - mean_absolute_error: 17.1132 - val_loss: 304.1303 - val_mean_absolute_error: 16.0470\n",
      "Epoch 874/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 405.7220 - mean_absolute_error: 17.8815\n",
      "Epoch 874: loss improved from 385.16272 to 385.08194, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 385.0819 - mean_absolute_error: 17.1111 - val_loss: 303.1581 - val_mean_absolute_error: 16.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 349.7911 - mean_absolute_error: 16.5868\n",
      "Epoch 875: loss did not improve from 385.08194\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 386.5455 - mean_absolute_error: 17.1363 - val_loss: 302.0293 - val_mean_absolute_error: 15.9814\n",
      "Epoch 876/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 429.9754 - mean_absolute_error: 18.1076\n",
      "Epoch 876: loss improved from 385.08194 to 384.94513, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 384.9451 - mean_absolute_error: 17.1062 - val_loss: 300.9273 - val_mean_absolute_error: 15.9469\n",
      "Epoch 877/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 379.3996 - mean_absolute_error: 16.7938\n",
      "Epoch 877: loss improved from 384.94513 to 384.14212, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 384.1421 - mean_absolute_error: 17.0869 - val_loss: 299.8218 - val_mean_absolute_error: 15.9122\n",
      "Epoch 878/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 432.9047 - mean_absolute_error: 18.0179\n",
      "Epoch 878: loss did not improve from 384.14212\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 384.6287 - mean_absolute_error: 17.0880 - val_loss: 299.0736 - val_mean_absolute_error: 15.8886\n",
      "Epoch 879/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 522.3484 - mean_absolute_error: 19.8346\n",
      "Epoch 879: loss did not improve from 384.14212\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 384.1872 - mean_absolute_error: 17.0778 - val_loss: 298.3342 - val_mean_absolute_error: 15.8653\n",
      "Epoch 880/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 343.0797 - mean_absolute_error: 15.2785\n",
      "Epoch 880: loss did not improve from 384.14212\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 384.6662 - mean_absolute_error: 17.0995 - val_loss: 297.6123 - val_mean_absolute_error: 15.8426\n",
      "Epoch 881/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 408.3868 - mean_absolute_error: 17.7998\n",
      "Epoch 881: loss improved from 384.14212 to 384.01581, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 384.0158 - mean_absolute_error: 17.0810 - val_loss: 296.6647 - val_mean_absolute_error: 15.8126\n",
      "Epoch 882/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 382.2235 - mean_absolute_error: 16.7619\n",
      "Epoch 882: loss improved from 384.01581 to 383.59125, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 383.5912 - mean_absolute_error: 17.0721 - val_loss: 295.7385 - val_mean_absolute_error: 15.7833\n",
      "Epoch 883/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 357.7787 - mean_absolute_error: 16.2131\n",
      "Epoch 883: loss did not improve from 383.59125\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 384.1171 - mean_absolute_error: 17.0753 - val_loss: 294.7506 - val_mean_absolute_error: 15.7520\n",
      "Epoch 884/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 440.3076 - mean_absolute_error: 18.2118\n",
      "Epoch 884: loss improved from 383.59125 to 383.43500, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 383.4350 - mean_absolute_error: 17.0586 - val_loss: 294.3302 - val_mean_absolute_error: 15.7387\n",
      "Epoch 885/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 314.0103 - mean_absolute_error: 15.4067\n",
      "Epoch 885: loss did not improve from 383.43500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 383.4365 - mean_absolute_error: 17.0571 - val_loss: 293.4755 - val_mean_absolute_error: 15.7115\n",
      "Epoch 886/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 372.3959 - mean_absolute_error: 16.3873\n",
      "Epoch 886: loss improved from 383.43500 to 382.65558, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 382.6556 - mean_absolute_error: 17.0393 - val_loss: 292.6984 - val_mean_absolute_error: 15.6867\n",
      "Epoch 887/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 334.6375 - mean_absolute_error: 15.1197\n",
      "Epoch 887: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 383.5469 - mean_absolute_error: 17.0578 - val_loss: 291.9928 - val_mean_absolute_error: 15.6642\n",
      "Epoch 888/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 255.5479 - mean_absolute_error: 13.4932\n",
      "Epoch 888: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 383.7461 - mean_absolute_error: 17.0618 - val_loss: 291.4767 - val_mean_absolute_error: 15.6477\n",
      "Epoch 889/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.8938 - mean_absolute_error: 15.9856\n",
      "Epoch 889: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 383.1952 - mean_absolute_error: 17.0470 - val_loss: 290.8817 - val_mean_absolute_error: 15.6287\n",
      "Epoch 890/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 379.8040 - mean_absolute_error: 17.0304\n",
      "Epoch 890: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 383.6750 - mean_absolute_error: 17.0597 - val_loss: 290.0829 - val_mean_absolute_error: 15.6031\n",
      "Epoch 891/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 423.1594 - mean_absolute_error: 17.5897\n",
      "Epoch 891: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 383.2834 - mean_absolute_error: 17.0432 - val_loss: 289.1353 - val_mean_absolute_error: 15.5727\n",
      "Epoch 892/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 365.7929 - mean_absolute_error: 17.2061\n",
      "Epoch 892: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 383.4431 - mean_absolute_error: 17.0487 - val_loss: 288.4457 - val_mean_absolute_error: 15.5506\n",
      "Epoch 893/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 324.9643 - mean_absolute_error: 15.6931\n",
      "Epoch 893: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 383.1529 - mean_absolute_error: 17.0348 - val_loss: 287.7373 - val_mean_absolute_error: 15.5278\n",
      "Epoch 894/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 484.1806 - mean_absolute_error: 18.9304\n",
      "Epoch 894: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 383.0758 - mean_absolute_error: 17.0517 - val_loss: 287.2262 - val_mean_absolute_error: 15.5113\n",
      "Epoch 895/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 368.1701 - mean_absolute_error: 16.9063\n",
      "Epoch 895: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 383.1934 - mean_absolute_error: 17.0321 - val_loss: 286.5309 - val_mean_absolute_error: 15.4889\n",
      "Epoch 896/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 461.8765 - mean_absolute_error: 18.9149\n",
      "Epoch 896: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 382.8875 - mean_absolute_error: 17.0321 - val_loss: 285.9385 - val_mean_absolute_error: 15.4698\n",
      "Epoch 897/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 475.1045 - mean_absolute_error: 19.8292\n",
      "Epoch 897: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 382.7701 - mean_absolute_error: 17.0251 - val_loss: 285.6591 - val_mean_absolute_error: 15.4607\n",
      "Epoch 898/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 295.6787 - mean_absolute_error: 14.0426\n",
      "Epoch 898: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 383.6265 - mean_absolute_error: 17.0462 - val_loss: 284.7663 - val_mean_absolute_error: 15.4318\n",
      "Epoch 899/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 274.3948 - mean_absolute_error: 14.2920\n",
      "Epoch 899: loss did not improve from 382.65558\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 382.9816 - mean_absolute_error: 17.0269 - val_loss: 283.8827 - val_mean_absolute_error: 15.4032\n",
      "Epoch 900/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 453.9323 - mean_absolute_error: 19.3530\n",
      "Epoch 900: loss improved from 382.65558 to 382.12070, saving model to model_aapl.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step - loss: 382.1207 - mean_absolute_error: 17.0144 - val_loss: 283.0795 - val_mean_absolute_error: 15.3771\n",
      "Epoch 901/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 313.7997 - mean_absolute_error: 15.6998\n",
      "Epoch 901: loss did not improve from 382.12070\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 382.5581 - mean_absolute_error: 17.0119 - val_loss: 282.3691 - val_mean_absolute_error: 15.3540\n",
      "Epoch 902/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 282.7968 - mean_absolute_error: 13.8321\n",
      "Epoch 902: loss did not improve from 382.12070\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 382.5649 - mean_absolute_error: 17.0197 - val_loss: 281.5878 - val_mean_absolute_error: 15.3285\n",
      "Epoch 903/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 327.0715 - mean_absolute_error: 15.5512\n",
      "Epoch 903: loss did not improve from 382.12070\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 382.2786 - mean_absolute_error: 17.0086 - val_loss: 281.2109 - val_mean_absolute_error: 15.3162\n",
      "Epoch 904/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 318.1649 - mean_absolute_error: 15.0559\n",
      "Epoch 904: loss did not improve from 382.12070\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 382.4516 - mean_absolute_error: 17.0122 - val_loss: 280.3722 - val_mean_absolute_error: 15.2888\n",
      "Epoch 905/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 429.4362 - mean_absolute_error: 17.8904\n",
      "Epoch 905: loss improved from 382.12070 to 381.81500, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 381.8150 - mean_absolute_error: 17.0007 - val_loss: 279.8177 - val_mean_absolute_error: 15.2707\n",
      "Epoch 906/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 318.5282 - mean_absolute_error: 14.9227\n",
      "Epoch 906: loss did not improve from 381.81500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 382.8642 - mean_absolute_error: 17.0152 - val_loss: 279.2607 - val_mean_absolute_error: 15.2524\n",
      "Epoch 907/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 438.0834 - mean_absolute_error: 18.6552\n",
      "Epoch 907: loss did not improve from 381.81500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 382.0441 - mean_absolute_error: 17.0009 - val_loss: 278.6286 - val_mean_absolute_error: 15.2317\n",
      "Epoch 908/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.2484 - mean_absolute_error: 15.8359\n",
      "Epoch 908: loss improved from 381.81500 to 381.45187, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 381.4519 - mean_absolute_error: 16.9906 - val_loss: 278.3186 - val_mean_absolute_error: 15.2215\n",
      "Epoch 909/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 380.2271 - mean_absolute_error: 16.8322\n",
      "Epoch 909: loss improved from 381.45187 to 381.40823, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 381.4082 - mean_absolute_error: 16.9880 - val_loss: 277.8710 - val_mean_absolute_error: 15.2068\n",
      "Epoch 910/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 359.8962 - mean_absolute_error: 16.3888\n",
      "Epoch 910: loss did not improve from 381.40823\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.5148 - mean_absolute_error: 16.9863 - val_loss: 277.3344 - val_mean_absolute_error: 15.1891\n",
      "Epoch 911/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 337.8745 - mean_absolute_error: 15.9114\n",
      "Epoch 911: loss did not improve from 381.40823\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.9436 - mean_absolute_error: 16.9923 - val_loss: 276.8387 - val_mean_absolute_error: 15.1728\n",
      "Epoch 912/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.7052 - mean_absolute_error: 16.6622\n",
      "Epoch 912: loss improved from 381.40823 to 381.26999, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 381.2700 - mean_absolute_error: 16.9775 - val_loss: 276.1590 - val_mean_absolute_error: 15.1504\n",
      "Epoch 913/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 446.5407 - mean_absolute_error: 19.1036\n",
      "Epoch 913: loss did not improve from 381.26999\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.9673 - mean_absolute_error: 16.9905 - val_loss: 275.1702 - val_mean_absolute_error: 15.1177\n",
      "Epoch 914/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 444.0947 - mean_absolute_error: 18.4321\n",
      "Epoch 914: loss did not improve from 381.26999\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 382.3656 - mean_absolute_error: 16.9991 - val_loss: 274.4524 - val_mean_absolute_error: 15.0940\n",
      "Epoch 915/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 495.7708 - mean_absolute_error: 19.8244\n",
      "Epoch 915: loss improved from 381.26999 to 380.96848, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 380.9685 - mean_absolute_error: 16.9612 - val_loss: 273.7859 - val_mean_absolute_error: 15.0719\n",
      "Epoch 916/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 380.8028 - mean_absolute_error: 16.5684\n",
      "Epoch 916: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 382.3623 - mean_absolute_error: 16.9820 - val_loss: 273.3620 - val_mean_absolute_error: 15.0578\n",
      "Epoch 917/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 291.2865 - mean_absolute_error: 14.9877\n",
      "Epoch 917: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.5505 - mean_absolute_error: 16.9740 - val_loss: 272.6792 - val_mean_absolute_error: 15.0351\n",
      "Epoch 918/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 279.1090 - mean_absolute_error: 14.2618\n",
      "Epoch 918: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.7416 - mean_absolute_error: 16.9786 - val_loss: 271.8330 - val_mean_absolute_error: 15.0069\n",
      "Epoch 919/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 338.0574 - mean_absolute_error: 16.2509\n",
      "Epoch 919: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 382.1820 - mean_absolute_error: 17.0046 - val_loss: 271.0995 - val_mean_absolute_error: 14.9825\n",
      "Epoch 920/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 312.2261 - mean_absolute_error: 15.8529\n",
      "Epoch 920: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.8138 - mean_absolute_error: 16.9760 - val_loss: 270.4032 - val_mean_absolute_error: 14.9592\n",
      "Epoch 921/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 271.5830 - mean_absolute_error: 13.5877\n",
      "Epoch 921: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.3104 - mean_absolute_error: 16.9597 - val_loss: 269.6948 - val_mean_absolute_error: 14.9355\n",
      "Epoch 922/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 431.5660 - mean_absolute_error: 17.9293\n",
      "Epoch 922: loss did not improve from 380.96848\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 381.1832 - mean_absolute_error: 16.9621 - val_loss: 269.1536 - val_mean_absolute_error: 14.9174\n",
      "Epoch 923/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 387.7952 - mean_absolute_error: 16.9186\n",
      "Epoch 923: loss improved from 380.96848 to 380.20749, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.2075 - mean_absolute_error: 16.9371 - val_loss: 268.5722 - val_mean_absolute_error: 14.8979\n",
      "Epoch 924/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 473.2437 - mean_absolute_error: 19.1634\n",
      "Epoch 924: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.2325 - mean_absolute_error: 16.9530 - val_loss: 267.7105 - val_mean_absolute_error: 14.8689\n",
      "Epoch 925/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 433.9917 - mean_absolute_error: 18.4588\n",
      "Epoch 925: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 380.2473 - mean_absolute_error: 16.9328 - val_loss: 266.9435 - val_mean_absolute_error: 14.8431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.5736 - mean_absolute_error: 17.6478\n",
      "Epoch 926: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7867 - mean_absolute_error: 16.9406 - val_loss: 266.4192 - val_mean_absolute_error: 14.8255\n",
      "Epoch 927/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 416.8658 - mean_absolute_error: 18.7673\n",
      "Epoch 927: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.3009 - mean_absolute_error: 16.9566 - val_loss: 265.9142 - val_mean_absolute_error: 14.8084\n",
      "Epoch 928/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.3841 - mean_absolute_error: 17.6801\n",
      "Epoch 928: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 381.2482 - mean_absolute_error: 16.9467 - val_loss: 265.3938 - val_mean_absolute_error: 14.7908\n",
      "Epoch 929/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 376.5017 - mean_absolute_error: 17.1852\n",
      "Epoch 929: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 381.1455 - mean_absolute_error: 16.9415 - val_loss: 264.9468 - val_mean_absolute_error: 14.7757\n",
      "Epoch 930/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 395.7046 - mean_absolute_error: 18.0407\n",
      "Epoch 930: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7104 - mean_absolute_error: 16.9332 - val_loss: 264.6168 - val_mean_absolute_error: 14.7645\n",
      "Epoch 931/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.1253 - mean_absolute_error: 17.8192\n",
      "Epoch 931: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.5194 - mean_absolute_error: 16.9624 - val_loss: 264.7443 - val_mean_absolute_error: 14.7689\n",
      "Epoch 932/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 345.3405 - mean_absolute_error: 16.6488\n",
      "Epoch 932: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.8731 - mean_absolute_error: 16.9406 - val_loss: 264.6046 - val_mean_absolute_error: 14.7641\n",
      "Epoch 933/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 341.6015 - mean_absolute_error: 14.9807\n",
      "Epoch 933: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.9364 - mean_absolute_error: 16.9390 - val_loss: 264.3502 - val_mean_absolute_error: 14.7555\n",
      "Epoch 934/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 334.9561 - mean_absolute_error: 15.5405\n",
      "Epoch 934: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.8516 - mean_absolute_error: 16.9241 - val_loss: 263.8578 - val_mean_absolute_error: 14.7388\n",
      "Epoch 935/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 323.5340 - mean_absolute_error: 15.5501\n",
      "Epoch 935: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 381.0839 - mean_absolute_error: 16.9423 - val_loss: 263.3166 - val_mean_absolute_error: 14.7204\n",
      "Epoch 936/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 333.8379 - mean_absolute_error: 15.5382\n",
      "Epoch 936: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.3688 - mean_absolute_error: 16.9204 - val_loss: 262.8056 - val_mean_absolute_error: 14.7031\n",
      "Epoch 937/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 370.9615 - mean_absolute_error: 17.0671\n",
      "Epoch 937: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.9524 - mean_absolute_error: 16.9290 - val_loss: 262.3863 - val_mean_absolute_error: 14.6888\n",
      "Epoch 938/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 361.8423 - mean_absolute_error: 16.4040\n",
      "Epoch 938: loss did not improve from 380.20749\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.1136 - mean_absolute_error: 16.9387 - val_loss: 262.1936 - val_mean_absolute_error: 14.6823\n",
      "Epoch 939/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 414.8151 - mean_absolute_error: 17.9415\n",
      "Epoch 939: loss improved from 380.20749 to 379.89310, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 379.8931 - mean_absolute_error: 16.8888 - val_loss: 261.6187 - val_mean_absolute_error: 14.6627\n",
      "Epoch 940/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 342.1371 - mean_absolute_error: 16.5842\n",
      "Epoch 940: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.3940 - mean_absolute_error: 16.9229 - val_loss: 261.1607 - val_mean_absolute_error: 14.6470\n",
      "Epoch 941/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 429.2278 - mean_absolute_error: 18.4118\n",
      "Epoch 941: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7202 - mean_absolute_error: 16.9370 - val_loss: 260.7948 - val_mean_absolute_error: 14.6345\n",
      "Epoch 942/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.3972 - mean_absolute_error: 16.7355\n",
      "Epoch 942: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2226 - mean_absolute_error: 16.9179 - val_loss: 260.6233 - val_mean_absolute_error: 14.6287\n",
      "Epoch 943/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 513.6664 - mean_absolute_error: 20.5001\n",
      "Epoch 943: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 380.7717 - mean_absolute_error: 16.9202 - val_loss: 260.3167 - val_mean_absolute_error: 14.6182\n",
      "Epoch 944/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 304.7518 - mean_absolute_error: 15.6703\n",
      "Epoch 944: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.5849 - mean_absolute_error: 16.9291 - val_loss: 260.3203 - val_mean_absolute_error: 14.6183\n",
      "Epoch 945/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 359.5585 - mean_absolute_error: 16.5097\n",
      "Epoch 945: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.3610 - mean_absolute_error: 16.9429 - val_loss: 260.1678 - val_mean_absolute_error: 14.6131\n",
      "Epoch 946/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.7471 - mean_absolute_error: 18.0989\n",
      "Epoch 946: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6825 - mean_absolute_error: 16.9297 - val_loss: 259.9685 - val_mean_absolute_error: 14.6063\n",
      "Epoch 947/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 451.7303 - mean_absolute_error: 18.5052\n",
      "Epoch 947: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1391 - mean_absolute_error: 16.9187 - val_loss: 259.8499 - val_mean_absolute_error: 14.6022\n",
      "Epoch 948/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 372.2679 - mean_absolute_error: 16.5840\n",
      "Epoch 948: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.3654 - mean_absolute_error: 16.9112 - val_loss: 259.5465 - val_mean_absolute_error: 14.5918\n",
      "Epoch 949/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 265.1297 - mean_absolute_error: 13.4544\n",
      "Epoch 949: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.1476 - mean_absolute_error: 16.9387 - val_loss: 259.0748 - val_mean_absolute_error: 14.5757\n",
      "Epoch 950/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 383.2088 - mean_absolute_error: 16.4168\n",
      "Epoch 950: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.5851 - mean_absolute_error: 16.9129 - val_loss: 258.7720 - val_mean_absolute_error: 14.5653\n",
      "Epoch 951/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 356.7515 - mean_absolute_error: 15.9723\n",
      "Epoch 951: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 379.9102 - mean_absolute_error: 16.9082 - val_loss: 258.8684 - val_mean_absolute_error: 14.5686\n",
      "Epoch 952/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 351.5550 - mean_absolute_error: 16.1821\n",
      "Epoch 952: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4706 - mean_absolute_error: 16.9112 - val_loss: 258.8240 - val_mean_absolute_error: 14.5671\n",
      "Epoch 953/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.2566 - mean_absolute_error: 17.3271\n",
      "Epoch 953: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3654 - mean_absolute_error: 16.9142 - val_loss: 258.6506 - val_mean_absolute_error: 14.5611\n",
      "Epoch 954/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 390.4242 - mean_absolute_error: 17.4804\n",
      "Epoch 954: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2625 - mean_absolute_error: 16.9163 - val_loss: 258.6009 - val_mean_absolute_error: 14.5594\n",
      "Epoch 955/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 349.2076 - mean_absolute_error: 16.1253\n",
      "Epoch 955: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.7761 - mean_absolute_error: 16.9177 - val_loss: 258.3242 - val_mean_absolute_error: 14.5499\n",
      "Epoch 956/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 454.2513 - mean_absolute_error: 18.9104\n",
      "Epoch 956: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.5775 - mean_absolute_error: 16.9174 - val_loss: 257.6125 - val_mean_absolute_error: 14.5254\n",
      "Epoch 957/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 376.3188 - mean_absolute_error: 16.8775\n",
      "Epoch 957: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.7845 - mean_absolute_error: 16.9260 - val_loss: 257.2027 - val_mean_absolute_error: 14.5113\n",
      "Epoch 958/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.4329 - mean_absolute_error: 17.5816\n",
      "Epoch 958: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6151 - mean_absolute_error: 16.9187 - val_loss: 256.7145 - val_mean_absolute_error: 14.4945\n",
      "Epoch 959/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 316.2920 - mean_absolute_error: 15.3295\n",
      "Epoch 959: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.4499 - mean_absolute_error: 16.9107 - val_loss: 256.5146 - val_mean_absolute_error: 14.4876\n",
      "Epoch 960/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 477.8396 - mean_absolute_error: 19.0040\n",
      "Epoch 960: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.8495 - mean_absolute_error: 16.9170 - val_loss: 256.1633 - val_mean_absolute_error: 14.4754\n",
      "Epoch 961/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 447.1332 - mean_absolute_error: 18.1765\n",
      "Epoch 961: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.7183 - mean_absolute_error: 16.9210 - val_loss: 255.9544 - val_mean_absolute_error: 14.4682\n",
      "Epoch 962/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 296.3180 - mean_absolute_error: 14.2159\n",
      "Epoch 962: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.8264 - mean_absolute_error: 16.9144 - val_loss: 255.5289 - val_mean_absolute_error: 14.4535\n",
      "Epoch 963/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.0560 - mean_absolute_error: 17.4649\n",
      "Epoch 963: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.7704 - mean_absolute_error: 16.9194 - val_loss: 255.2173 - val_mean_absolute_error: 14.4427\n",
      "Epoch 964/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 406.5506 - mean_absolute_error: 18.5284\n",
      "Epoch 964: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.1356 - mean_absolute_error: 16.9020 - val_loss: 254.8582 - val_mean_absolute_error: 14.4303\n",
      "Epoch 965/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 523.8956 - mean_absolute_error: 20.7478\n",
      "Epoch 965: loss did not improve from 379.89310\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6485 - mean_absolute_error: 16.9100 - val_loss: 254.5421 - val_mean_absolute_error: 14.4193\n",
      "Epoch 966/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 425.3496 - mean_absolute_error: 18.3895\n",
      "Epoch 966: loss improved from 379.89310 to 379.76740, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 379.7674 - mean_absolute_error: 16.8943 - val_loss: 254.0939 - val_mean_absolute_error: 14.4038\n",
      "Epoch 967/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 414.2946 - mean_absolute_error: 18.5021\n",
      "Epoch 967: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.6376 - mean_absolute_error: 16.9003 - val_loss: 253.6405 - val_mean_absolute_error: 14.3880\n",
      "Epoch 968/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 372.0813 - mean_absolute_error: 16.8645\n",
      "Epoch 968: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4663 - mean_absolute_error: 16.9018 - val_loss: 253.1105 - val_mean_absolute_error: 14.3696\n",
      "Epoch 969/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.9653 - mean_absolute_error: 17.2256\n",
      "Epoch 969: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.9648 - mean_absolute_error: 16.9096 - val_loss: 252.9947 - val_mean_absolute_error: 14.3656\n",
      "Epoch 970/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 328.1632 - mean_absolute_error: 15.7846\n",
      "Epoch 970: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7758 - mean_absolute_error: 16.9046 - val_loss: 252.9689 - val_mean_absolute_error: 14.3647\n",
      "Epoch 971/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 354.6801 - mean_absolute_error: 15.9096\n",
      "Epoch 971: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.8394 - mean_absolute_error: 16.9209 - val_loss: 252.7822 - val_mean_absolute_error: 14.3582\n",
      "Epoch 972/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 474.9255 - mean_absolute_error: 19.3964\n",
      "Epoch 972: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.6135 - mean_absolute_error: 16.9055 - val_loss: 252.6367 - val_mean_absolute_error: 14.3531\n",
      "Epoch 973/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 444.7393 - mean_absolute_error: 18.2969\n",
      "Epoch 973: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4888 - mean_absolute_error: 16.9022 - val_loss: 252.3797 - val_mean_absolute_error: 14.3442\n",
      "Epoch 974/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 314.3936 - mean_absolute_error: 14.6677\n",
      "Epoch 974: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8591 - mean_absolute_error: 16.8878 - val_loss: 251.9190 - val_mean_absolute_error: 14.3281\n",
      "Epoch 975/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 416.0154 - mean_absolute_error: 16.6782\n",
      "Epoch 975: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4594 - mean_absolute_error: 16.8938 - val_loss: 252.1350 - val_mean_absolute_error: 14.3356\n",
      "Epoch 976/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 479.0091 - mean_absolute_error: 20.0831\n",
      "Epoch 976: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.0912 - mean_absolute_error: 16.8827 - val_loss: 251.7170 - val_mean_absolute_error: 14.3210\n",
      "Epoch 977/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 499.7292 - mean_absolute_error: 19.4661\n",
      "Epoch 977: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.5471 - mean_absolute_error: 16.9190 - val_loss: 251.3186 - val_mean_absolute_error: 14.3071\n",
      "Epoch 978/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 324.8122 - mean_absolute_error: 14.9453\n",
      "Epoch 978: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.9717 - mean_absolute_error: 16.9013 - val_loss: 250.8033 - val_mean_absolute_error: 14.2891\n",
      "Epoch 979/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 306.8315 - mean_absolute_error: 15.4324\n",
      "Epoch 979: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8567 - mean_absolute_error: 16.8774 - val_loss: 250.4180 - val_mean_absolute_error: 14.2756\n",
      "Epoch 980/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 302.0899 - mean_absolute_error: 14.5788\n",
      "Epoch 980: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0284 - mean_absolute_error: 16.8895 - val_loss: 250.3082 - val_mean_absolute_error: 14.2718\n",
      "Epoch 981/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 368.6996 - mean_absolute_error: 16.9549\n",
      "Epoch 981: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1093 - mean_absolute_error: 16.8883 - val_loss: 250.0992 - val_mean_absolute_error: 14.2644\n",
      "Epoch 982/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 349.5934 - mean_absolute_error: 16.6979\n",
      "Epoch 982: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1536 - mean_absolute_error: 16.8900 - val_loss: 250.0021 - val_mean_absolute_error: 14.2610\n",
      "Epoch 983/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 374.5707 - mean_absolute_error: 16.5776\n",
      "Epoch 983: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7263 - mean_absolute_error: 16.8990 - val_loss: 250.1449 - val_mean_absolute_error: 14.2660\n",
      "Epoch 984/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 413.2839 - mean_absolute_error: 17.5798\n",
      "Epoch 984: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.8136 - mean_absolute_error: 16.9048 - val_loss: 250.3126 - val_mean_absolute_error: 14.2719\n",
      "Epoch 985/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 375.8490 - mean_absolute_error: 16.5657\n",
      "Epoch 985: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4907 - mean_absolute_error: 16.8954 - val_loss: 250.0761 - val_mean_absolute_error: 14.2636\n",
      "Epoch 986/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 382.8617 - mean_absolute_error: 17.4140\n",
      "Epoch 986: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.5259 - mean_absolute_error: 16.8971 - val_loss: 249.9625 - val_mean_absolute_error: 14.2597\n",
      "Epoch 987/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 385.2485 - mean_absolute_error: 17.7466\n",
      "Epoch 987: loss did not improve from 379.76740\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.6228 - mean_absolute_error: 16.8933 - val_loss: 249.7442 - val_mean_absolute_error: 14.2520\n",
      "Epoch 988/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 357.7053 - mean_absolute_error: 15.2984\n",
      "Epoch 988: loss improved from 379.76740 to 379.57663, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 379.5766 - mean_absolute_error: 16.8772 - val_loss: 249.4737 - val_mean_absolute_error: 14.2425\n",
      "Epoch 989/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 407.8792 - mean_absolute_error: 18.1166\n",
      "Epoch 989: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 380.3694 - mean_absolute_error: 16.8965 - val_loss: 249.1826 - val_mean_absolute_error: 14.2323\n",
      "Epoch 990/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 357.1224 - mean_absolute_error: 15.1129\n",
      "Epoch 990: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1992 - mean_absolute_error: 16.8889 - val_loss: 249.2752 - val_mean_absolute_error: 14.2355\n",
      "Epoch 991/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 455.7119 - mean_absolute_error: 18.4156\n",
      "Epoch 991: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.6361 - mean_absolute_error: 16.8881 - val_loss: 249.5072 - val_mean_absolute_error: 14.2437\n",
      "Epoch 992/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 399.5859 - mean_absolute_error: 16.5752\n",
      "Epoch 992: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0956 - mean_absolute_error: 16.8798 - val_loss: 249.5872 - val_mean_absolute_error: 14.2465\n",
      "Epoch 993/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 404.2304 - mean_absolute_error: 17.4282\n",
      "Epoch 993: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0274 - mean_absolute_error: 16.8748 - val_loss: 249.2430 - val_mean_absolute_error: 14.2344\n",
      "Epoch 994/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 324.4119 - mean_absolute_error: 15.9302\n",
      "Epoch 994: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0009 - mean_absolute_error: 16.8853 - val_loss: 248.3942 - val_mean_absolute_error: 14.2046\n",
      "Epoch 995/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 349.1761 - mean_absolute_error: 15.6961\n",
      "Epoch 995: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4761 - mean_absolute_error: 16.8896 - val_loss: 247.6735 - val_mean_absolute_error: 14.1792\n",
      "Epoch 996/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 402.9234 - mean_absolute_error: 18.0516\n",
      "Epoch 996: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3774 - mean_absolute_error: 16.8817 - val_loss: 247.3504 - val_mean_absolute_error: 14.1678\n",
      "Epoch 997/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 374.4311 - mean_absolute_error: 17.0147\n",
      "Epoch 997: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4596 - mean_absolute_error: 16.8872 - val_loss: 246.8889 - val_mean_absolute_error: 14.1515\n",
      "Epoch 998/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 482.3638 - mean_absolute_error: 18.8422\n",
      "Epoch 998: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2509 - mean_absolute_error: 16.8746 - val_loss: 246.3878 - val_mean_absolute_error: 14.1338\n",
      "Epoch 999/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 395.2694 - mean_absolute_error: 16.9041\n",
      "Epoch 999: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4859 - mean_absolute_error: 16.8770 - val_loss: 246.0451 - val_mean_absolute_error: 14.1216\n",
      "Epoch 1000/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 400.3135 - mean_absolute_error: 17.4242\n",
      "Epoch 1000: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.4184 - mean_absolute_error: 16.8979 - val_loss: 245.8033 - val_mean_absolute_error: 14.1131\n",
      "Epoch 1001/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 334.1243 - mean_absolute_error: 15.4582\n",
      "Epoch 1001: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.6547 - mean_absolute_error: 16.8594 - val_loss: 245.4499 - val_mean_absolute_error: 14.1005\n",
      "Epoch 1002/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 449.1564 - mean_absolute_error: 18.4851\n",
      "Epoch 1002: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2617 - mean_absolute_error: 16.8759 - val_loss: 245.5351 - val_mean_absolute_error: 14.1036\n",
      "Epoch 1003/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 368.6759 - mean_absolute_error: 16.7852\n",
      "Epoch 1003: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3670 - mean_absolute_error: 16.8730 - val_loss: 245.7280 - val_mean_absolute_error: 14.1104\n",
      "Epoch 1004/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 421.4388 - mean_absolute_error: 18.0327\n",
      "Epoch 1004: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8633 - mean_absolute_error: 16.8609 - val_loss: 245.6191 - val_mean_absolute_error: 14.1065\n",
      "Epoch 1005/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 365.4299 - mean_absolute_error: 16.8152\n",
      "Epoch 1005: loss did not improve from 379.57663\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.0692 - mean_absolute_error: 16.8765 - val_loss: 245.7185 - val_mean_absolute_error: 14.1101\n",
      "Epoch 1006/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 378.2474 - mean_absolute_error: 16.8074\n",
      "Epoch 1006: loss improved from 379.57663 to 379.35226, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 379.3523 - mean_absolute_error: 16.8620 - val_loss: 245.7306 - val_mean_absolute_error: 14.1105\n",
      "Epoch 1007/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 255.7530 - mean_absolute_error: 13.3297\n",
      "Epoch 1007: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2221 - mean_absolute_error: 16.8825 - val_loss: 245.4994 - val_mean_absolute_error: 14.1023\n",
      "Epoch 1008/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 360.4793 - mean_absolute_error: 16.9637\n",
      "Epoch 1008: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8578 - mean_absolute_error: 16.8703 - val_loss: 245.3054 - val_mean_absolute_error: 14.0954\n",
      "Epoch 1009/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 418.6439 - mean_absolute_error: 17.5846\n",
      "Epoch 1009: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4742 - mean_absolute_error: 16.8777 - val_loss: 245.3604 - val_mean_absolute_error: 14.0974\n",
      "Epoch 1010/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 360.9359 - mean_absolute_error: 16.0404\n",
      "Epoch 1010: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 381.0332 - mean_absolute_error: 16.9006 - val_loss: 245.4112 - val_mean_absolute_error: 14.0992\n",
      "Epoch 1011/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 335.5222 - mean_absolute_error: 15.9735\n",
      "Epoch 1011: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.7143 - mean_absolute_error: 16.8642 - val_loss: 245.2610 - val_mean_absolute_error: 14.0938\n",
      "Epoch 1012/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 404.8220 - mean_absolute_error: 17.4958\n",
      "Epoch 1012: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.0466 - mean_absolute_error: 16.8923 - val_loss: 245.3806 - val_mean_absolute_error: 14.0981\n",
      "Epoch 1013/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 243.2923 - mean_absolute_error: 12.1535\n",
      "Epoch 1013: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1119 - mean_absolute_error: 16.8757 - val_loss: 245.6862 - val_mean_absolute_error: 14.1089\n",
      "Epoch 1014/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 352.1162 - mean_absolute_error: 16.7263\n",
      "Epoch 1014: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.3008 - mean_absolute_error: 16.8735 - val_loss: 245.5812 - val_mean_absolute_error: 14.1052\n",
      "Epoch 1015/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 425.1020 - mean_absolute_error: 18.0695\n",
      "Epoch 1015: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4655 - mean_absolute_error: 16.8801 - val_loss: 245.4538 - val_mean_absolute_error: 14.1007\n",
      "Epoch 1016/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 384.2092 - mean_absolute_error: 16.7473\n",
      "Epoch 1016: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2889 - mean_absolute_error: 16.8689 - val_loss: 245.4538 - val_mean_absolute_error: 14.1007\n",
      "Epoch 1017/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.8853 - mean_absolute_error: 16.5588\n",
      "Epoch 1017: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9168 - mean_absolute_error: 16.8763 - val_loss: 245.4387 - val_mean_absolute_error: 14.1001\n",
      "Epoch 1018/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 416.2514 - mean_absolute_error: 17.2496\n",
      "Epoch 1018: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.6801 - mean_absolute_error: 16.8742 - val_loss: 245.4783 - val_mean_absolute_error: 14.1015\n",
      "Epoch 1019/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.7441 - mean_absolute_error: 16.0179\n",
      "Epoch 1019: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2705 - mean_absolute_error: 16.8755 - val_loss: 245.1669 - val_mean_absolute_error: 14.0905\n",
      "Epoch 1020/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.0250 - mean_absolute_error: 16.0930\n",
      "Epoch 1020: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.5247 - mean_absolute_error: 16.8623 - val_loss: 244.8634 - val_mean_absolute_error: 14.0797\n",
      "Epoch 1021/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 430.5793 - mean_absolute_error: 18.2353\n",
      "Epoch 1021: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.3428 - mean_absolute_error: 16.8719 - val_loss: 244.2387 - val_mean_absolute_error: 14.0575\n",
      "Epoch 1022/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 319.1748 - mean_absolute_error: 14.9583\n",
      "Epoch 1022: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.0667 - mean_absolute_error: 16.8879 - val_loss: 243.8541 - val_mean_absolute_error: 14.0438\n",
      "Epoch 1023/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 386.2596 - mean_absolute_error: 17.0081\n",
      "Epoch 1023: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4451 - mean_absolute_error: 16.8772 - val_loss: 243.5405 - val_mean_absolute_error: 14.0327\n",
      "Epoch 1024/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 303.7840 - mean_absolute_error: 15.2184\n",
      "Epoch 1024: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2743 - mean_absolute_error: 16.8707 - val_loss: 243.3166 - val_mean_absolute_error: 14.0247\n",
      "Epoch 1025/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 332.5595 - mean_absolute_error: 15.2976\n",
      "Epoch 1025: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8552 - mean_absolute_error: 16.8549 - val_loss: 243.1835 - val_mean_absolute_error: 14.0199\n",
      "Epoch 1026/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 381.1996 - mean_absolute_error: 17.0660\n",
      "Epoch 1026: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4454 - mean_absolute_error: 16.8683 - val_loss: 243.2610 - val_mean_absolute_error: 14.0227\n",
      "Epoch 1027/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 302.7074 - mean_absolute_error: 14.4556\n",
      "Epoch 1027: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1910 - mean_absolute_error: 16.8581 - val_loss: 242.9243 - val_mean_absolute_error: 14.0107\n",
      "Epoch 1028/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 411.9015 - mean_absolute_error: 17.7989\n",
      "Epoch 1028: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.6510 - mean_absolute_error: 16.8431 - val_loss: 242.7080 - val_mean_absolute_error: 14.0030\n",
      "Epoch 1029/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 345.9459 - mean_absolute_error: 15.6586\n",
      "Epoch 1029: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9771 - mean_absolute_error: 16.8612 - val_loss: 242.8632 - val_mean_absolute_error: 14.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1030/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.7011 - mean_absolute_error: 17.1785\n",
      "Epoch 1030: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.7079 - mean_absolute_error: 16.8583 - val_loss: 242.9889 - val_mean_absolute_error: 14.0130\n",
      "Epoch 1031/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 365.5632 - mean_absolute_error: 16.6023\n",
      "Epoch 1031: loss did not improve from 379.35226\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.8970 - mean_absolute_error: 16.8542 - val_loss: 243.3525 - val_mean_absolute_error: 14.0260\n",
      "Epoch 1032/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.5463 - mean_absolute_error: 15.6978\n",
      "Epoch 1032: loss improved from 379.35226 to 378.56750, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 378.5675 - mean_absolute_error: 16.8084 - val_loss: 243.8121 - val_mean_absolute_error: 14.0423\n",
      "Epoch 1033/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.5037 - mean_absolute_error: 16.2786\n",
      "Epoch 1033: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8676 - mean_absolute_error: 16.8581 - val_loss: 243.8978 - val_mean_absolute_error: 14.0454\n",
      "Epoch 1034/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 340.6411 - mean_absolute_error: 16.1565\n",
      "Epoch 1034: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.7902 - mean_absolute_error: 16.8966 - val_loss: 243.4647 - val_mean_absolute_error: 14.0300\n",
      "Epoch 1035/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 428.8360 - mean_absolute_error: 18.2810\n",
      "Epoch 1035: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3468 - mean_absolute_error: 16.8644 - val_loss: 242.7828 - val_mean_absolute_error: 14.0056\n",
      "Epoch 1036/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 380.0674 - mean_absolute_error: 16.5997\n",
      "Epoch 1036: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4243 - mean_absolute_error: 16.8735 - val_loss: 242.4013 - val_mean_absolute_error: 13.9920\n",
      "Epoch 1037/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 385.8389 - mean_absolute_error: 16.6325\n",
      "Epoch 1037: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0910 - mean_absolute_error: 16.8569 - val_loss: 242.7948 - val_mean_absolute_error: 14.0061\n",
      "Epoch 1038/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 387.4128 - mean_absolute_error: 17.2965\n",
      "Epoch 1038: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0622 - mean_absolute_error: 16.8558 - val_loss: 242.6362 - val_mean_absolute_error: 14.0004\n",
      "Epoch 1039/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 331.1956 - mean_absolute_error: 16.0908\n",
      "Epoch 1039: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2807 - mean_absolute_error: 16.8769 - val_loss: 242.2737 - val_mean_absolute_error: 13.9874\n",
      "Epoch 1040/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 420.5479 - mean_absolute_error: 18.0797\n",
      "Epoch 1040: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1008 - mean_absolute_error: 16.8624 - val_loss: 241.8313 - val_mean_absolute_error: 13.9716\n",
      "Epoch 1041/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 449.3453 - mean_absolute_error: 18.6141\n",
      "Epoch 1041: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0480 - mean_absolute_error: 16.8554 - val_loss: 241.5128 - val_mean_absolute_error: 13.9602\n",
      "Epoch 1042/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.2454 - mean_absolute_error: 16.1928\n",
      "Epoch 1042: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.0046 - mean_absolute_error: 16.8494 - val_loss: 240.9467 - val_mean_absolute_error: 13.9399\n",
      "Epoch 1043/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 341.4150 - mean_absolute_error: 16.0062\n",
      "Epoch 1043: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1473 - mean_absolute_error: 16.8546 - val_loss: 240.5338 - val_mean_absolute_error: 13.9251\n",
      "Epoch 1044/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 354.8796 - mean_absolute_error: 16.5147\n",
      "Epoch 1044: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1355 - mean_absolute_error: 16.8503 - val_loss: 240.4361 - val_mean_absolute_error: 13.9216\n",
      "Epoch 1045/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.5667 - mean_absolute_error: 17.0435\n",
      "Epoch 1045: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4029 - mean_absolute_error: 16.8603 - val_loss: 240.3260 - val_mean_absolute_error: 13.9177\n",
      "Epoch 1046/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 321.1734 - mean_absolute_error: 15.5122\n",
      "Epoch 1046: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.9735 - mean_absolute_error: 16.8572 - val_loss: 240.2424 - val_mean_absolute_error: 13.9146\n",
      "Epoch 1047/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 400.5423 - mean_absolute_error: 18.2658\n",
      "Epoch 1047: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9527 - mean_absolute_error: 16.8496 - val_loss: 240.7268 - val_mean_absolute_error: 13.9320\n",
      "Epoch 1048/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 328.3179 - mean_absolute_error: 15.0837\n",
      "Epoch 1048: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8928 - mean_absolute_error: 16.8459 - val_loss: 240.7344 - val_mean_absolute_error: 13.9323\n",
      "Epoch 1049/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 446.7697 - mean_absolute_error: 18.5983\n",
      "Epoch 1049: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.7498 - mean_absolute_error: 16.8457 - val_loss: 240.6664 - val_mean_absolute_error: 13.9299\n",
      "Epoch 1050/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 427.1271 - mean_absolute_error: 18.7672\n",
      "Epoch 1050: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6268 - mean_absolute_error: 16.8458 - val_loss: 240.6749 - val_mean_absolute_error: 13.9302\n",
      "Epoch 1051/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.0541 - mean_absolute_error: 17.4156\n",
      "Epoch 1051: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8814 - mean_absolute_error: 16.8448 - val_loss: 240.5954 - val_mean_absolute_error: 13.9273\n",
      "Epoch 1052/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 339.6558 - mean_absolute_error: 15.7406\n",
      "Epoch 1052: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2662 - mean_absolute_error: 16.8639 - val_loss: 240.7842 - val_mean_absolute_error: 13.9341\n",
      "Epoch 1053/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 323.6672 - mean_absolute_error: 15.9168\n",
      "Epoch 1053: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6485 - mean_absolute_error: 16.8535 - val_loss: 241.1777 - val_mean_absolute_error: 13.9482\n",
      "Epoch 1054/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 335.6808 - mean_absolute_error: 15.9230\n",
      "Epoch 1054: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0641 - mean_absolute_error: 16.8549 - val_loss: 241.4698 - val_mean_absolute_error: 13.9587\n",
      "Epoch 1055/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.7205 - mean_absolute_error: 16.8970\n",
      "Epoch 1055: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 381.0943 - mean_absolute_error: 16.8735 - val_loss: 241.7698 - val_mean_absolute_error: 13.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1056/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 388.1047 - mean_absolute_error: 17.8756\n",
      "Epoch 1056: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3538 - mean_absolute_error: 16.8765 - val_loss: 241.6548 - val_mean_absolute_error: 13.9653\n",
      "Epoch 1057/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 415.4402 - mean_absolute_error: 17.5337\n",
      "Epoch 1057: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6127 - mean_absolute_error: 16.8744 - val_loss: 241.6522 - val_mean_absolute_error: 13.9652\n",
      "Epoch 1058/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 339.4760 - mean_absolute_error: 15.9696\n",
      "Epoch 1058: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8934 - mean_absolute_error: 16.8515 - val_loss: 241.8543 - val_mean_absolute_error: 13.9724\n",
      "Epoch 1059/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 432.5735 - mean_absolute_error: 18.6069\n",
      "Epoch 1059: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.7482 - mean_absolute_error: 16.8578 - val_loss: 242.1029 - val_mean_absolute_error: 13.9813\n",
      "Epoch 1060/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 333.1049 - mean_absolute_error: 15.0270\n",
      "Epoch 1060: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.5021 - mean_absolute_error: 16.8657 - val_loss: 241.9626 - val_mean_absolute_error: 13.9763\n",
      "Epoch 1061/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 351.7355 - mean_absolute_error: 15.7018\n",
      "Epoch 1061: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4346 - mean_absolute_error: 16.8639 - val_loss: 242.2881 - val_mean_absolute_error: 13.9880\n",
      "Epoch 1062/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 344.1124 - mean_absolute_error: 16.2659\n",
      "Epoch 1062: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.1839 - mean_absolute_error: 16.8610 - val_loss: 242.0197 - val_mean_absolute_error: 13.9784\n",
      "Epoch 1063/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 320.9327 - mean_absolute_error: 15.6281\n",
      "Epoch 1063: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.6142 - mean_absolute_error: 16.8745 - val_loss: 241.8061 - val_mean_absolute_error: 13.9707\n",
      "Epoch 1064/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 469.9959 - mean_absolute_error: 18.9227\n",
      "Epoch 1064: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6171 - mean_absolute_error: 16.8419 - val_loss: 241.2386 - val_mean_absolute_error: 13.9504\n",
      "Epoch 1065/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 348.8192 - mean_absolute_error: 15.7713\n",
      "Epoch 1065: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2008 - mean_absolute_error: 16.8596 - val_loss: 241.3076 - val_mean_absolute_error: 13.9529\n",
      "Epoch 1066/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 353.4980 - mean_absolute_error: 16.1896\n",
      "Epoch 1066: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4278 - mean_absolute_error: 16.8744 - val_loss: 241.2858 - val_mean_absolute_error: 13.9521\n",
      "Epoch 1067/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.4764 - mean_absolute_error: 16.6965\n",
      "Epoch 1067: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.6359 - mean_absolute_error: 16.8368 - val_loss: 240.9020 - val_mean_absolute_error: 13.9383\n",
      "Epoch 1068/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 372.8130 - mean_absolute_error: 16.4299\n",
      "Epoch 1068: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.3499 - mean_absolute_error: 16.8664 - val_loss: 241.0943 - val_mean_absolute_error: 13.9452\n",
      "Epoch 1069/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 399.0089 - mean_absolute_error: 16.5296\n",
      "Epoch 1069: loss did not improve from 378.56750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.7285 - mean_absolute_error: 16.8463 - val_loss: 240.8433 - val_mean_absolute_error: 13.9362\n",
      "Epoch 1070/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 455.5383 - mean_absolute_error: 18.1313\n",
      "Epoch 1070: loss improved from 378.56750 to 378.55750, saving model to model_aapl.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 378.5575 - mean_absolute_error: 16.8283 - val_loss: 240.8131 - val_mean_absolute_error: 13.9351\n",
      "Epoch 1071/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 390.0013 - mean_absolute_error: 17.1834\n",
      "Epoch 1071: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.1852 - mean_absolute_error: 16.8440 - val_loss: 240.3532 - val_mean_absolute_error: 13.9186\n",
      "Epoch 1072/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 326.4550 - mean_absolute_error: 15.5788\n",
      "Epoch 1072: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1826 - mean_absolute_error: 16.8592 - val_loss: 240.4875 - val_mean_absolute_error: 13.9235\n",
      "Epoch 1073/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 458.8620 - mean_absolute_error: 18.2720\n",
      "Epoch 1073: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.3123 - mean_absolute_error: 16.8564 - val_loss: 240.6171 - val_mean_absolute_error: 13.9281\n",
      "Epoch 1074/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 410.5944 - mean_absolute_error: 17.8554\n",
      "Epoch 1074: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.7091 - mean_absolute_error: 16.8449 - val_loss: 240.8305 - val_mean_absolute_error: 13.9358\n",
      "Epoch 1075/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 312.9290 - mean_absolute_error: 14.7756\n",
      "Epoch 1075: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.3855 - mean_absolute_error: 16.8608 - val_loss: 240.6167 - val_mean_absolute_error: 13.9281\n",
      "Epoch 1076/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.5443 - mean_absolute_error: 17.3402\n",
      "Epoch 1076: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.5264 - mean_absolute_error: 16.8616 - val_loss: 240.1422 - val_mean_absolute_error: 13.9110\n",
      "Epoch 1077/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.6094 - mean_absolute_error: 17.5295\n",
      "Epoch 1077: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.3758 - mean_absolute_error: 16.8624 - val_loss: 239.9423 - val_mean_absolute_error: 13.9039\n",
      "Epoch 1078/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 416.5881 - mean_absolute_error: 17.7199\n",
      "Epoch 1078: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9299 - mean_absolute_error: 16.8504 - val_loss: 239.7654 - val_mean_absolute_error: 13.8975\n",
      "Epoch 1079/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 400.8482 - mean_absolute_error: 17.1046\n",
      "Epoch 1079: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.3495 - mean_absolute_error: 16.8222 - val_loss: 239.5424 - val_mean_absolute_error: 13.8895\n",
      "Epoch 1080/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 325.1696 - mean_absolute_error: 15.1878\n",
      "Epoch 1080: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.7338 - mean_absolute_error: 16.8582 - val_loss: 238.9883 - val_mean_absolute_error: 13.8695\n",
      "Epoch 1081/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 441.9996 - mean_absolute_error: 18.4756\n",
      "Epoch 1081: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.9622 - mean_absolute_error: 16.8690 - val_loss: 238.8635 - val_mean_absolute_error: 13.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1082/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 260.8259 - mean_absolute_error: 13.3925\n",
      "Epoch 1082: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.4879 - mean_absolute_error: 16.8586 - val_loss: 239.1450 - val_mean_absolute_error: 13.8752\n",
      "Epoch 1083/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.8746 - mean_absolute_error: 16.8279\n",
      "Epoch 1083: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.5153 - mean_absolute_error: 16.8607 - val_loss: 239.4860 - val_mean_absolute_error: 13.8874\n",
      "Epoch 1084/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 267.2979 - mean_absolute_error: 14.3366\n",
      "Epoch 1084: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.5761 - mean_absolute_error: 16.8404 - val_loss: 239.2767 - val_mean_absolute_error: 13.8799\n",
      "Epoch 1085/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 438.4194 - mean_absolute_error: 16.9657\n",
      "Epoch 1085: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.6411 - mean_absolute_error: 16.8652 - val_loss: 239.7175 - val_mean_absolute_error: 13.8958\n",
      "Epoch 1086/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.1223 - mean_absolute_error: 16.9445\n",
      "Epoch 1086: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 378.9767 - mean_absolute_error: 16.8283 - val_loss: 239.6636 - val_mean_absolute_error: 13.8938\n",
      "Epoch 1087/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 300.9877 - mean_absolute_error: 14.5536\n",
      "Epoch 1087: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.7202 - mean_absolute_error: 16.8652 - val_loss: 239.5347 - val_mean_absolute_error: 13.8892\n",
      "Epoch 1088/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 410.6700 - mean_absolute_error: 17.5202\n",
      "Epoch 1088: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1031 - mean_absolute_error: 16.8518 - val_loss: 239.6581 - val_mean_absolute_error: 13.8936\n",
      "Epoch 1089/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.3152 - mean_absolute_error: 16.8432\n",
      "Epoch 1089: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0253 - mean_absolute_error: 16.8480 - val_loss: 239.6500 - val_mean_absolute_error: 13.8933\n",
      "Epoch 1090/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 326.0418 - mean_absolute_error: 15.8903\n",
      "Epoch 1090: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.8451 - mean_absolute_error: 16.8743 - val_loss: 240.0917 - val_mean_absolute_error: 13.9092\n",
      "Epoch 1091/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.6251 - mean_absolute_error: 17.0007\n",
      "Epoch 1091: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8199 - mean_absolute_error: 16.8516 - val_loss: 240.3889 - val_mean_absolute_error: 13.9199\n",
      "Epoch 1092/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 301.7369 - mean_absolute_error: 15.0679\n",
      "Epoch 1092: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6652 - mean_absolute_error: 16.8504 - val_loss: 240.3078 - val_mean_absolute_error: 13.9170\n",
      "Epoch 1093/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 402.3456 - mean_absolute_error: 17.3266\n",
      "Epoch 1093: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 379.8798 - mean_absolute_error: 16.8452 - val_loss: 240.4318 - val_mean_absolute_error: 13.9215\n",
      "Epoch 1094/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 357.3618 - mean_absolute_error: 16.2980\n",
      "Epoch 1094: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.3094 - mean_absolute_error: 16.8548 - val_loss: 240.5589 - val_mean_absolute_error: 13.9260\n",
      "Epoch 1095/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 401.0148 - mean_absolute_error: 17.7586\n",
      "Epoch 1095: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3778 - mean_absolute_error: 16.8697 - val_loss: 240.5015 - val_mean_absolute_error: 13.9240\n",
      "Epoch 1096/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 413.7524 - mean_absolute_error: 17.8993\n",
      "Epoch 1096: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2002 - mean_absolute_error: 16.8543 - val_loss: 240.6260 - val_mean_absolute_error: 13.9284\n",
      "Epoch 1097/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 371.5385 - mean_absolute_error: 16.2042\n",
      "Epoch 1097: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1482 - mean_absolute_error: 16.8590 - val_loss: 240.6061 - val_mean_absolute_error: 13.9277\n",
      "Epoch 1098/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.7184 - mean_absolute_error: 16.8894\n",
      "Epoch 1098: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.8028 - mean_absolute_error: 16.8574 - val_loss: 241.0615 - val_mean_absolute_error: 13.9441\n",
      "Epoch 1099/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 310.7633 - mean_absolute_error: 15.3391\n",
      "Epoch 1099: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.1494 - mean_absolute_error: 16.8370 - val_loss: 240.7523 - val_mean_absolute_error: 13.9330\n",
      "Epoch 1100/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 316.6777 - mean_absolute_error: 14.5887\n",
      "Epoch 1100: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.1731 - mean_absolute_error: 16.8515 - val_loss: 240.2003 - val_mean_absolute_error: 13.9131\n",
      "Epoch 1101/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 328.3431 - mean_absolute_error: 14.6692\n",
      "Epoch 1101: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.5028 - mean_absolute_error: 16.8431 - val_loss: 239.9011 - val_mean_absolute_error: 13.9024\n",
      "Epoch 1102/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 368.1349 - mean_absolute_error: 16.6873\n",
      "Epoch 1102: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.7278 - mean_absolute_error: 16.8424 - val_loss: 239.7573 - val_mean_absolute_error: 13.8972\n",
      "Epoch 1103/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 348.4837 - mean_absolute_error: 16.4753\n",
      "Epoch 1103: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.0836 - mean_absolute_error: 16.8587 - val_loss: 239.6810 - val_mean_absolute_error: 13.8945\n",
      "Epoch 1104/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 389.4594 - mean_absolute_error: 16.3349\n",
      "Epoch 1104: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.5023 - mean_absolute_error: 16.8353 - val_loss: 239.6636 - val_mean_absolute_error: 13.8938\n",
      "Epoch 1105/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 489.5942 - mean_absolute_error: 19.9582\n",
      "Epoch 1105: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6415 - mean_absolute_error: 16.8630 - val_loss: 239.2441 - val_mean_absolute_error: 13.8787\n",
      "Epoch 1106/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 345.6511 - mean_absolute_error: 16.0487\n",
      "Epoch 1106: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1756 - mean_absolute_error: 16.8598 - val_loss: 238.9765 - val_mean_absolute_error: 13.8691\n",
      "Epoch 1107/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 412.1645 - mean_absolute_error: 17.6051\n",
      "Epoch 1107: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6403 - mean_absolute_error: 16.8433 - val_loss: 239.3855 - val_mean_absolute_error: 13.8838\n",
      "Epoch 1108/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 336.8422 - mean_absolute_error: 15.6143\n",
      "Epoch 1108: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2223 - mean_absolute_error: 16.8504 - val_loss: 239.5152 - val_mean_absolute_error: 13.8885\n",
      "Epoch 1109/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 234.4134 - mean_absolute_error: 13.6143\n",
      "Epoch 1109: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.0406 - mean_absolute_error: 16.8546 - val_loss: 239.7052 - val_mean_absolute_error: 13.8953\n",
      "Epoch 1110/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 343.4648 - mean_absolute_error: 15.4065\n",
      "Epoch 1110: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.1040 - mean_absolute_error: 16.8559 - val_loss: 239.7578 - val_mean_absolute_error: 13.8972\n",
      "Epoch 1111/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 310.4807 - mean_absolute_error: 15.3161\n",
      "Epoch 1111: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1298 - mean_absolute_error: 16.8598 - val_loss: 239.0281 - val_mean_absolute_error: 13.8709\n",
      "Epoch 1112/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 293.4177 - mean_absolute_error: 14.2861\n",
      "Epoch 1112: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9410 - mean_absolute_error: 16.8479 - val_loss: 238.2538 - val_mean_absolute_error: 13.8430\n",
      "Epoch 1113/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 347.5833 - mean_absolute_error: 16.5704\n",
      "Epoch 1113: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0673 - mean_absolute_error: 16.8465 - val_loss: 237.9945 - val_mean_absolute_error: 13.8336\n",
      "Epoch 1114/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.3518 - mean_absolute_error: 16.3780\n",
      "Epoch 1114: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.8109 - mean_absolute_error: 16.8614 - val_loss: 237.6371 - val_mean_absolute_error: 13.8207\n",
      "Epoch 1115/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 321.5946 - mean_absolute_error: 14.5456\n",
      "Epoch 1115: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.3371 - mean_absolute_error: 16.8499 - val_loss: 237.4098 - val_mean_absolute_error: 13.8125\n",
      "Epoch 1116/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 316.3471 - mean_absolute_error: 14.8752\n",
      "Epoch 1116: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.7530 - mean_absolute_error: 16.8314 - val_loss: 237.5064 - val_mean_absolute_error: 13.8160\n",
      "Epoch 1117/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 268.5693 - mean_absolute_error: 13.6375\n",
      "Epoch 1117: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0243 - mean_absolute_error: 16.8388 - val_loss: 236.9477 - val_mean_absolute_error: 13.7958\n",
      "Epoch 1118/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 335.8464 - mean_absolute_error: 15.7809\n",
      "Epoch 1118: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9121 - mean_absolute_error: 16.8384 - val_loss: 236.9793 - val_mean_absolute_error: 13.7969\n",
      "Epoch 1119/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 362.5100 - mean_absolute_error: 17.1902\n",
      "Epoch 1119: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.7666 - mean_absolute_error: 16.8629 - val_loss: 237.4322 - val_mean_absolute_error: 13.8133\n",
      "Epoch 1120/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.4194 - mean_absolute_error: 16.7864\n",
      "Epoch 1120: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.7758 - mean_absolute_error: 16.8386 - val_loss: 237.7843 - val_mean_absolute_error: 13.8260\n",
      "Epoch 1121/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 345.6936 - mean_absolute_error: 15.5950\n",
      "Epoch 1121: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.2876 - mean_absolute_error: 16.8393 - val_loss: 237.8569 - val_mean_absolute_error: 13.8287\n",
      "Epoch 1122/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 444.3961 - mean_absolute_error: 18.5672\n",
      "Epoch 1122: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0363 - mean_absolute_error: 16.8381 - val_loss: 237.6338 - val_mean_absolute_error: 13.8206\n",
      "Epoch 1123/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 421.6905 - mean_absolute_error: 18.1176\n",
      "Epoch 1123: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.5078 - mean_absolute_error: 16.8291 - val_loss: 237.5772 - val_mean_absolute_error: 13.8185\n",
      "Epoch 1124/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 579.6267 - mean_absolute_error: 21.6978\n",
      "Epoch 1124: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8692 - mean_absolute_error: 16.8421 - val_loss: 237.4714 - val_mean_absolute_error: 13.8147\n",
      "Epoch 1125/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 377.7457 - mean_absolute_error: 16.7762\n",
      "Epoch 1125: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.3592 - mean_absolute_error: 16.8144 - val_loss: 237.8700 - val_mean_absolute_error: 13.8291\n",
      "Epoch 1126/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 400.9074 - mean_absolute_error: 17.1720\n",
      "Epoch 1126: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.7654 - mean_absolute_error: 16.8771 - val_loss: 237.7261 - val_mean_absolute_error: 13.8239\n",
      "Epoch 1127/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 465.4338 - mean_absolute_error: 18.5948\n",
      "Epoch 1127: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0059 - mean_absolute_error: 16.8450 - val_loss: 237.5734 - val_mean_absolute_error: 13.8184\n",
      "Epoch 1128/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 342.5128 - mean_absolute_error: 15.9095\n",
      "Epoch 1128: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2827 - mean_absolute_error: 16.8495 - val_loss: 236.9944 - val_mean_absolute_error: 13.7974\n",
      "Epoch 1129/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.4303 - mean_absolute_error: 16.6435\n",
      "Epoch 1129: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 379.8796 - mean_absolute_error: 16.8439 - val_loss: 236.7368 - val_mean_absolute_error: 13.7881\n",
      "Epoch 1130/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 415.1728 - mean_absolute_error: 18.3625\n",
      "Epoch 1130: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 380.0285 - mean_absolute_error: 16.8406 - val_loss: 236.1944 - val_mean_absolute_error: 13.7684\n",
      "Epoch 1131/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 342.9234 - mean_absolute_error: 16.1755\n",
      "Epoch 1131: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.3535 - mean_absolute_error: 16.8480 - val_loss: 236.5034 - val_mean_absolute_error: 13.7796\n",
      "Epoch 1132/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 442.4167 - mean_absolute_error: 18.2271\n",
      "Epoch 1132: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.6784 - mean_absolute_error: 16.8287 - val_loss: 236.5059 - val_mean_absolute_error: 13.7797\n",
      "Epoch 1133/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 328.1746 - mean_absolute_error: 15.6515\n",
      "Epoch 1133: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.6135 - mean_absolute_error: 16.8366 - val_loss: 236.2423 - val_mean_absolute_error: 13.7702\n",
      "Epoch 1134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 408.4546 - mean_absolute_error: 17.4596\n",
      "Epoch 1134: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9021 - mean_absolute_error: 16.8310 - val_loss: 236.2343 - val_mean_absolute_error: 13.7699\n",
      "Epoch 1135/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 434.9518 - mean_absolute_error: 18.5917\n",
      "Epoch 1135: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0014 - mean_absolute_error: 16.8379 - val_loss: 236.3882 - val_mean_absolute_error: 13.7755\n",
      "Epoch 1136/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 386.6128 - mean_absolute_error: 16.6894\n",
      "Epoch 1136: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.1583 - mean_absolute_error: 16.8434 - val_loss: 236.4138 - val_mean_absolute_error: 13.7764\n",
      "Epoch 1137/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 467.3578 - mean_absolute_error: 18.8973\n",
      "Epoch 1137: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.8924 - mean_absolute_error: 16.8358 - val_loss: 237.2885 - val_mean_absolute_error: 13.8081\n",
      "Epoch 1138/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 302.4968 - mean_absolute_error: 14.4702\n",
      "Epoch 1138: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0046 - mean_absolute_error: 16.8441 - val_loss: 237.5827 - val_mean_absolute_error: 13.8187\n",
      "Epoch 1139/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 369.6938 - mean_absolute_error: 15.9362\n",
      "Epoch 1139: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2438 - mean_absolute_error: 16.8471 - val_loss: 238.1377 - val_mean_absolute_error: 13.8388\n",
      "Epoch 1140/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 433.0735 - mean_absolute_error: 18.1384\n",
      "Epoch 1140: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 380.5696 - mean_absolute_error: 16.8616 - val_loss: 237.7544 - val_mean_absolute_error: 13.8250\n",
      "Epoch 1141/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 302.8383 - mean_absolute_error: 13.5754\n",
      "Epoch 1141: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.6691 - mean_absolute_error: 16.8200 - val_loss: 237.1440 - val_mean_absolute_error: 13.8029\n",
      "Epoch 1142/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 434.1581 - mean_absolute_error: 18.9048\n",
      "Epoch 1142: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.4841 - mean_absolute_error: 16.8589 - val_loss: 236.6947 - val_mean_absolute_error: 13.7866\n",
      "Epoch 1143/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 336.1176 - mean_absolute_error: 15.8523\n",
      "Epoch 1143: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 380.5173 - mean_absolute_error: 16.8486 - val_loss: 236.6241 - val_mean_absolute_error: 13.7840\n",
      "Epoch 1144/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 399.6945 - mean_absolute_error: 17.7358\n",
      "Epoch 1144: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 378.7653 - mean_absolute_error: 16.8206 - val_loss: 236.7941 - val_mean_absolute_error: 13.7902\n",
      "Epoch 1145/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 323.3293 - mean_absolute_error: 15.2719\n",
      "Epoch 1145: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.5815 - mean_absolute_error: 16.8334 - val_loss: 237.6236 - val_mean_absolute_error: 13.8202\n",
      "Epoch 1146/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 333.8323 - mean_absolute_error: 15.9330\n",
      "Epoch 1146: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9214 - mean_absolute_error: 16.8457 - val_loss: 238.2095 - val_mean_absolute_error: 13.8414\n",
      "Epoch 1147/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 376.4488 - mean_absolute_error: 17.2794\n",
      "Epoch 1147: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.8671 - mean_absolute_error: 16.8543 - val_loss: 238.6105 - val_mean_absolute_error: 13.8559\n",
      "Epoch 1148/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 340.9818 - mean_absolute_error: 16.1990\n",
      "Epoch 1148: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2367 - mean_absolute_error: 16.8468 - val_loss: 238.6782 - val_mean_absolute_error: 13.8583\n",
      "Epoch 1149/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 421.8500 - mean_absolute_error: 17.1582\n",
      "Epoch 1149: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 380.0723 - mean_absolute_error: 16.8590 - val_loss: 238.6592 - val_mean_absolute_error: 13.8576\n",
      "Epoch 1150/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 303.8922 - mean_absolute_error: 14.9444\n",
      "Epoch 1150: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.9342 - mean_absolute_error: 16.8620 - val_loss: 238.9193 - val_mean_absolute_error: 13.8670\n",
      "Epoch 1151/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 342.8657 - mean_absolute_error: 15.8309\n",
      "Epoch 1151: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2653 - mean_absolute_error: 16.8567 - val_loss: 238.7446 - val_mean_absolute_error: 13.8607\n",
      "Epoch 1152/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 404.5869 - mean_absolute_error: 18.0749\n",
      "Epoch 1152: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.6760 - mean_absolute_error: 16.8650 - val_loss: 238.8618 - val_mean_absolute_error: 13.8650\n",
      "Epoch 1153/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 320.4285 - mean_absolute_error: 16.1744\n",
      "Epoch 1153: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.2616 - mean_absolute_error: 16.8590 - val_loss: 238.3358 - val_mean_absolute_error: 13.8460\n",
      "Epoch 1154/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 343.5236 - mean_absolute_error: 16.6328\n",
      "Epoch 1154: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.9254 - mean_absolute_error: 16.8515 - val_loss: 237.3609 - val_mean_absolute_error: 13.8107\n",
      "Epoch 1155/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 328.2214 - mean_absolute_error: 15.2688\n",
      "Epoch 1155: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4227 - mean_absolute_error: 16.8537 - val_loss: 236.7697 - val_mean_absolute_error: 13.7893\n",
      "Epoch 1156/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 395.9048 - mean_absolute_error: 17.2019\n",
      "Epoch 1156: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.2284 - mean_absolute_error: 16.8380 - val_loss: 236.0293 - val_mean_absolute_error: 13.7624\n",
      "Epoch 1157/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 476.5483 - mean_absolute_error: 19.1162\n",
      "Epoch 1157: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 379.9509 - mean_absolute_error: 16.8414 - val_loss: 235.7203 - val_mean_absolute_error: 13.7512\n",
      "Epoch 1158/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 327.7381 - mean_absolute_error: 15.4778\n",
      "Epoch 1158: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.3697 - mean_absolute_error: 16.8520 - val_loss: 235.6444 - val_mean_absolute_error: 13.7484\n",
      "Epoch 1159/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 410.9879 - mean_absolute_error: 17.6986\n",
      "Epoch 1159: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.4569 - mean_absolute_error: 16.8464 - val_loss: 235.8559 - val_mean_absolute_error: 13.7561\n",
      "Epoch 1160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 294.9631 - mean_absolute_error: 13.7840\n",
      "Epoch 1160: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 380.2094 - mean_absolute_error: 16.8345 - val_loss: 235.4984 - val_mean_absolute_error: 13.7431\n",
      "Epoch 1161/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 309.0422 - mean_absolute_error: 15.3381\n",
      "Epoch 1161: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 381.6543 - mean_absolute_error: 16.8694 - val_loss: 235.2242 - val_mean_absolute_error: 13.7331\n",
      "Epoch 1162/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 413.0233 - mean_absolute_error: 17.8448\n",
      "Epoch 1162: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.0617 - mean_absolute_error: 16.8413 - val_loss: 235.0101 - val_mean_absolute_error: 13.7253\n",
      "Epoch 1163/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 429.8394 - mean_absolute_error: 18.1464\n",
      "Epoch 1163: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 379.7658 - mean_absolute_error: 16.8255 - val_loss: 235.2795 - val_mean_absolute_error: 13.7352\n",
      "Epoch 1164/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 444.3245 - mean_absolute_error: 19.1094\n",
      "Epoch 1164: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.2633 - mean_absolute_error: 16.8392 - val_loss: 234.9276 - val_mean_absolute_error: 13.7223\n",
      "Epoch 1165/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 391.7124 - mean_absolute_error: 17.6861\n",
      "Epoch 1165: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 379.3745 - mean_absolute_error: 16.8179 - val_loss: 235.2867 - val_mean_absolute_error: 13.7354\n",
      "Epoch 1166/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 375.7201 - mean_absolute_error: 17.4362\n",
      "Epoch 1166: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 379.7834 - mean_absolute_error: 16.8297 - val_loss: 235.1157 - val_mean_absolute_error: 13.7292\n",
      "Epoch 1167/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 398.6407 - mean_absolute_error: 17.8816\n",
      "Epoch 1167: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.0639 - mean_absolute_error: 16.8336 - val_loss: 234.9188 - val_mean_absolute_error: 13.7220\n",
      "Epoch 1168/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 367.3569 - mean_absolute_error: 17.5529\n",
      "Epoch 1168: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 380.5067 - mean_absolute_error: 16.8524 - val_loss: 235.2724 - val_mean_absolute_error: 13.7349\n",
      "Epoch 1169/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 202.8663 - mean_absolute_error: 12.0527\n",
      "Epoch 1169: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4901 - mean_absolute_error: 16.8544 - val_loss: 235.4540 - val_mean_absolute_error: 13.7415\n",
      "Epoch 1170/10000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 324.6631 - mean_absolute_error: 15.4436\n",
      "Epoch 1170: loss did not improve from 378.55750\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 381.0903 - mean_absolute_error: 16.8673 - val_loss: 234.9452 - val_mean_absolute_error: 13.7230\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=10000,validation_data=[X_test,y_test], callbacks = [checkpoint,ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30e57a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6b157a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHFCAYAAAD7ZFORAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnAklEQVR4nO3dd1gU1/oH8O/usoW69KaIDRUFe+wGe9eY5KaoQb0xmmaLmmZMNJqoMTfdmGJy1SQmJr+rJkYNsbeAiiixgB1FEQQpS19g9/z+MI4uiwoKDCzfz/PsE+bMOzPvHNF9c+bMjEIIIUBERERkg5RyJ0BERERUVVjoEBERkc1ioUNEREQ2i4UOERER2SwWOkRERGSzWOgQERGRzWKhQ0RERDaLhQ4RERHZLBY6REREZLNY6BCVg0KhKNdn165d93WcefPmQaFQ3NO2u3btqpQcyLaV9/dk5cqVUCgUuHDhQrXkRVRV7OROgKg2iIqKslhesGABdu7ciR07dli0t2zZ8r6O88wzz2DQoEH3tG379u0RFRV13zkQEdkSFjpE5dClSxeLZS8vLyiVSqv20vLz8+Hg4FDu49SvXx/169e/pxxdXFzumg9dV1BQAJ1Od8+jZ0RUe/DSFVEl6dWrF0JCQrBnzx5069YNDg4OePrppwEAP//8MwYMGAA/Pz/Y29sjODgYr732GvLy8iz2Udalq4YNG2LYsGGIiIhA+/btYW9vjxYtWuC///2vRVxZlyTGjx8PJycnnD17FkOGDIGTkxMCAgIwc+ZMGI1Gi+0vX76Mf/3rX3B2doarqyvGjBmD6OhoKBQKrFy58o7nnpaWhhdeeAEtW7aEk5MTvL290adPH+zdu9cq1mg0Yv78+QgODoZOp4OHhwd69+6NyMhIKcZsNuOzzz5D27ZtYW9vD1dXV3Tp0gUbNmyQYhQKBebNm2e1/4YNG2L8+PHS8o1LMFu2bMHTTz8NLy8vODg4wGg04uzZs/j3v/+NoKAgODg4oF69ehg+fDiOHTtmtd+srCzMnDkTjRs3hlarhbe3N4YMGYKTJ09CCIGgoCAMHDjQarvc3Fzo9Xq8+OKLd+zDzz//HA8++CC8vb3h6OiI0NBQLFmyBMXFxRZxN37PoqOj0bNnTzg4OKBx48ZYvHgxzGazRezJkycxaNAgODg4wNPTE8899xxycnLumMfd/Pe//0WbNm2g0+ng7u6Ohx9+GPHx8RYx58+fx5NPPgl/f39otVr4+Pigb9++iI2NlWJ27NiBXr16wcPDA/b29mjQoAEeffRR5Ofn31d+RKVxRIeoEiUnJ+Opp57CK6+8goULF0KpvP7/EmfOnMGQIUMwffp0ODo64uTJk3jvvfdw8OBBq8tfZfn7778xc+ZMvPbaa/Dx8cE333yDCRMmoGnTpnjwwQfvuG1xcTFGjBiBCRMmYObMmdizZw8WLFgAvV6Pt956CwCQl5eH3r17IyMjA++99x6aNm2KiIgIPPHEE+U674yMDADA3Llz4evri9zcXKxfvx69evXC9u3b0atXLwBASUkJBg8ejL1792L69Ono06cPSkpKsH//fiQmJqJbt24ArhdoP/zwAyZMmID58+dDo9Hg8OHD9zVf5Omnn8bQoUPx/fffIy8vD2q1GleuXIGHhwcWL14MLy8vZGRkYNWqVejcuTOOHDmC5s2bAwBycnLQo0cPXLhwAa+++io6d+6M3Nxc7NmzB8nJyWjRogWmTJmC6dOn48yZMwgKCpKO+9133yE7O/uuhc65c+cwevRoNGrUCBqNBn///TfeffddnDx50qqoTUlJwZgxYzBz5kzMnTsX69evx+uvvw5/f3+MHTsWAHD16lWEhYVBrVZj2bJl8PHxwerVqzF58uR77sNFixZh9uzZGDVqFBYtWoT09HTMmzcPXbt2RXR0tHTeQ4YMgclkwpIlS9CgQQNcu3YNkZGRyMrKAgBcuHABQ4cORc+ePfHf//4Xrq6uSEpKQkREBIqKiio0Ckp0V4KIKmzcuHHC0dHRoi0sLEwAENu3b7/jtmazWRQXF4vdu3cLAOLvv/+W1s2dO1eU/msZGBgodDqduHjxotRWUFAg3N3dxbPPPiu17dy5UwAQO3futMgTgPjll18s9jlkyBDRvHlzafnzzz8XAMQff/xhEffss88KAGLFihV3PKfSSkpKRHFxsejbt694+OGHpfbvvvtOABDLly+/7bZ79uwRAMQbb7xxx2MAEHPnzrVqDwwMFOPGjZOWV6xYIQCIsWPHlivvoqIiERQUJF566SWpff78+QKA2Lp16223zc7OFs7OzmLatGkW7S1bthS9e/e+67FvZTKZRHFxsfjuu++ESqUSGRkZ0robv2cHDhywOs7AgQOl5VdffVUoFAoRGxtrEde/f3+r35Oy3Oi3hIQEIYQQmZmZwt7eXgwZMsQiLjExUWi1WjF69GghhBDXrl0TAMTHH398233/73//EwCsciOqCrx0RVSJ3Nzc0KdPH6v28+fPY/To0fD19YVKpYJarUZYWBgAWA37l6Vt27Zo0KCBtKzT6dCsWTNcvHjxrtsqFAoMHz7coq1169YW2+7evRvOzs5WE6FHjRp11/3f8OWXX6J9+/bQ6XSws7ODWq3G9u3bLc7vjz/+gE6nky7pleWPP/4AgLuOgFTUo48+atVWUlKChQsXomXLltBoNLCzs4NGo8GZM2es8m7WrBn69et32/07Ozvj3//+N1auXCldktyxYwfi4uLKNYpy5MgRjBgxAh4eHtLvyNixY2EymXD69GmLWF9fX3Tq1MmirfSf6c6dO9GqVSu0adPGIm706NF3zaUsUVFRKCgosLgsCAABAQHo06cPtm/fDgBwd3dHkyZN8P777+PDDz/EkSNHrC6ptW3bFhqNBpMmTcKqVatw/vz5e8qJqDxY6BBVIj8/P6u23Nxc9OzZEwcOHMA777yDXbt2ITo6GuvWrQNwfWLs3Xh4eFi1abXacm3r4OAAnU5ntW1hYaG0nJ6eDh8fH6tty2ory4cffojnn38enTt3xtq1a7F//35ER0dj0KBBFjmmpaXB399fuqRXlrS0NKhUKvj6+pbr2OVV1p/NjBkz8Oabb2LkyJH4/fffceDAAURHR6NNmzZWeZdnkviUKVOQk5OD1atXAwCWLl2K+vXr46GHHrrjdomJiejZsyeSkpLwySefYO/evYiOjsbnn38OwPp3pDy/D+np6WX24b32a3p6OoCy+9Hf319ar1AosH37dgwcOBBLlixB+/bt4eXlhalTp0rzg5o0aYJt27bB29sbL774Ipo0aYImTZrgk08+uafciO6Ec3SIKlFZd/Hs2LEDV65cwa5du6RRHADSfIWawMPDAwcPHrRqT0lJKdf2P/zwA3r16oUvvvjCor30xFcvLy/s27cPZrP5tsWOl5cXTCYTUlJSyvxSvUGr1VpNqAZufiGXVtafzQ8//ICxY8di4cKFFu3Xrl2Dq6urRU6XL1++bS43NG3aFIMHD8bnn3+OwYMHY8OGDXj77behUqnuuN2vv/6KvLw8rFu3DoGBgVL7rZN3K8rDw6PMP7/y/pmWtT/g+jy00q5cuQJPT09pOTAwEN9++y0A4PTp0/jll18wb948FBUV4csvvwQA9OzZEz179oTJZMKhQ4fw2WefYfr06fDx8cGTTz55TzkSlYUjOkRV7MYXrFartWj/6quv5EinTGFhYcjJyZEuG92wZs2acm2vUCiszu/o0aNWzx8aPHgwCgsL73gX1+DBgwHAqmgqrWHDhjh69KhF244dO5Cbm1uunG+X96ZNm5CUlGSV0+nTp8s1cXzatGk4evQoxo0bB5VKhYkTJ5YrD8Dyd0QIgeXLl5fnNMrUu3dvnDhxAn///bdF+48//nhP++vatSvs7e3xww8/WLRfvnwZO3bsQN++fcvcrlmzZpgzZw5CQ0Nx+PBhq/UqlQqdO3eWRq/KiiG6HxzRIapi3bp1g5ubG5577jnMnTsXarUaq1evtvoCktO4cePw0Ucf4amnnsI777yDpk2b4o8//sCff/4JAHe81AQAw4YNw4IFCzB37lyEhYXh1KlTmD9/Pho1aoSSkhIpbtSoUVixYgWee+45nDp1Cr1794bZbMaBAwcQHByMJ598Ej179kR4eDjeeecdXL16FcOGDYNWq8WRI0fg4OCAKVOmAADCw8Px5ptv4q233kJYWBji4uKwdOlS6PX6cp/3sGHDsHLlSrRo0QKtW7dGTEwM3n//favLVNOnT8fPP/+Mhx56CK+99ho6deqEgoIC7N69G8OGDUPv3r2l2P79+6Nly5bYuXMnnnrqKXh7e981j/79+0Oj0WDUqFF45ZVXUFhYiC+++AKZmZnlPpfSpk+fjv/+978YOnQo3nnnHemuq5MnT97T/lxdXfHmm29i9uzZGDt2LEaNGoX09HS8/fbb0Ol0mDt3LoDrBe7kyZPx2GOPISgoCBqNBjt27MDRo0fx2muvAbg+n2vHjh0YOnQoGjRogMLCQunOsjvNgyK6J3LPhiaqjW5311WrVq3KjI+MjBRdu3YVDg4OwsvLSzzzzDPi8OHDVnc03e6uq6FDh1rtMywsTISFhUnLt7vrqnSetztOYmKieOSRR4STk5NwdnYWjz76qNi8ebMAIH777bfbdYUQQgij0ShmzZol6tWrJ3Q6nWjfvr349ddfxbhx40RgYKBFbEFBgXjrrbdEUFCQ0Gg0wsPDQ/Tp00dERkZKMSaTSXz00UciJCREaDQaodfrRdeuXcXvv/9uccxXXnlFBAQECHt7exEWFiZiY2Nve9dVdHS0Vd6ZmZliwoQJwtvbWzg4OIgePXqIvXv3WvXtjdhp06aJBg0aCLVaLby9vcXQoUPFyZMnrfY7b948AUDs37//jv12q99//120adNG6HQ6Ua9ePfHyyy+LP/74w+rP9Ha/Z2X1dVxcnOjfv7/Q6XTC3d1dTJgwQfz222/3dNfVDd98841o3bq19Ofy0EMPiRMnTkjrr169KsaPHy9atGghHB0dhZOTk2jdurX46KOPRElJiRBCiKioKPHwww+LwMBAodVqhYeHhwgLCxMbNmwod38RlZdCCCHkKrKIqGZbuHAh5syZg8TExHt+YnNd1LFjRygUCkRHR8udClGdx0tXRATg+h1CANCiRQsUFxdjx44d+PTTT/HUU0+xyCmH7OxsHD9+HBs3bkRMTAzWr18vd0pEBBY6RPQPBwcHfPTRR7hw4QKMRiMaNGiAV199FXPmzJE7tVrh8OHD6N27Nzw8PDB37lyMHDlS7pSICAAvXREREZHN4u3lREREZLNY6BAREZHNYqFDRERENqtOT0Y2m824cuUKnJ2dy3w8PBEREdU8Qgjk5OTc9d15QB0vdK5cuYKAgAC50yAiIqJ7cOnSpbs+/qJOFzrOzs4ArneUi4uLzNkQERFReWRnZyMgIED6Hr+TOl3o3Lhc5eLiwkKHiIiolinPtBNORiYiIiKbxUKHiIiIbBYLHSIiIrJZdXqOTnmZTCYUFxfLnQaRbNRqNVQqldxpEBFVGAudOxBCICUlBVlZWXKnQiQ7V1dX+Pr68plTRFSrsNC5gxtFjre3NxwcHPgPPNVJQgjk5+cjNTUVAODn5ydzRkRE5cdC5zZMJpNU5Hh4eMidDpGs7O3tAQCpqanw9vbmZSwiqjU4Gfk2bszJcXBwkDkToprhxt8FzlcjotqEhc5d8HIV0XX8u0BEtRELHSIiIrJZLHSIiIjIZrHQsUHjx4/HyJEj5U6DiIhIdrzrqgoIIVBsEgAENHa8O4WIiEguHNGpAmk5RpxMycbVbKPcqVjZvXs3OnXqBK1WCz8/P7z22msoKSmR1v/vf/9DaGgo7O3t4eHhgX79+iEvLw8AsGvXLnTq1AmOjo5wdXVF9+7dcfHiRblOhYiI6K44olMBQggUFJvuGmcSAoXFJmTmF8HDSXPfx7VXqyrljpekpCQMGTIE48ePx3fffYeTJ09i4sSJ0Ol0mDdvHpKTkzFq1CgsWbIEDz/8MHJycrB3714IIVBSUoKRI0di4sSJ+Omnn1BUVISDBw/yThwiIqrRWOhUQEGxCS3f+rPajxs3fyAcNPf/R7Vs2TIEBARg6dKlUCgUaNGiBa5cuYJXX30Vb731FpKTk1FSUoJHHnkEgYGBAIDQ0FAAQEZGBgwGA4YNG4YmTZoAAIKDg+87JyIioqrES1d1SHx8PLp27WoxCtO9e3fk5ubi8uXLaNOmDfr27YvQ0FA89thjWL58OTIzMwEA7u7uGD9+PAYOHIjhw4fjk08+QXJyslynQkREVC4c0akAe7UKcfMHliv2ZHIOSsxmNPF2gr36/iYk3+/2NwghrC41CSEAXH8YnEqlwtatWxEZGYktW7bgs88+wxtvvIEDBw6gUaNGWLFiBaZOnYqIiAj8/PPPmDNnDrZu3YouXbpUSn5ERESVjSM6FaBQKOCgsSvfR6uCTq2C2Sxgr1aVf7syPpU1D6Zly5aIjIyUihsAiIyMhLOzM+rVqyedY/fu3fH222/jyJEj0Gg0WL9+vRTfrl07vP7664iMjERISAh+/PHHSsmNiIioKnBEp4oocL04STYUQqtWwUWnrtbjGwwGxMbGWrRNmjQJH3/8MaZMmYLJkyfj1KlTmDt3LmbMmAGlUokDBw5g+/btGDBgALy9vXHgwAGkpaUhODgYCQkJ+PrrrzFixAj4+/vj1KlTOH36NMaOHVut50VERFQRLHSqSLHJLP1sLDYDuuo9/q5du9CuXTuLtnHjxmHz5s14+eWX0aZNG7i7u2PChAmYM2cOAMDFxQV79uzBxx9/jOzsbAQGBuKDDz7A4MGDcfXqVZw8eRKrVq1Ceno6/Pz8MHnyZDz77LPVe2JEREQVoBC3XseoY7Kzs6HX62EwGODi4mKxrrCwEAkJCWjUqBF0uopXKUcvZ0k/ezlr4ae3v990iWR1v38niIgqy52+v0vjHJ1qUGKqs7UkERGRrFjoVIMSMwsdIiIiObDQqSL13Rykn2+dr0NERETVh4VOFXF31CDI2wkAUFhsQh2eCkVERCQbFjpVSHvLg/6SDYUyZkJERFQ3sdCpQspbHvRXWI6XgRIREVHlYqFTxfz012/D5Vu+iYiIqh8LnSqmsbt++arYZOY8HSIiomrGQqeKqf4ZyCksNiExI1/eZIiIiOoYFjpVTKm8ecnKUFAMM0d17lmvXr0wffr0Ktv/rl27oFAokJWVVWXHICKi6sVCp4qpSs3NKSrhM3Vsyfjx4zFy5Ei50yAiottgoVPFbh3RAQAjCx2qAsXFxVZtRUVF97Sve92OiKgmYqFTxUqP6JjMVV/o9OrVC1OmTMH06dPh5uYGHx8ffP3118jLy8O///1vODs7o0mTJvjjjz+kbeLi4jBkyBA4OTnBx8cH4eHhuHbtmrQ+IiICPXr0gKurKzw8PDBs2DCcO3dOWn/hwgUoFAqsW7cOvXv3hoODA9q0aYOoqKhy5Zyeno5Ro0ahfv36cHBwQGhoKH766SeruJKSEkyePFnKY86cORaTvJctW4agoCDodDr4+PjgX//6l7TOaDRi6tSp8Pb2hk6nQ48ePRAdHX3bnObNm4e2bdtatH388cdo2LChtH7VqlX47bffoFAooFAosGvXLgBAUlISnnjiCbi5ucHDwwMPPfQQLly4UK6+AIAVK1YgODgYOp0OLVq0wLJly6R1N/r6l19+Qa9evaDT6fDDDz9Io0uLFi2Cv78/mjVrBgA4duwY+vTpA3t7e3h4eGDSpEnIzc2V9ne77YiIbAELnYoQAijKq9BHWZIPPwczFMX5UBTnw2TMrfA+cA/zelatWgVPT08cPHgQU6ZMwfPPP4/HHnsM3bp1w+HDhzFw4ECEh4cjPz8fycnJCAsLQ9u2bXHo0CFERETg6tWrePzxx6X95eXlYcaMGYiOjsb27duhVCrx8MMPw1yqcHvjjTcwa9YsxMbGolmzZhg1ahRKSkrumm9hYSE6dOiAjRs34vjx45g0aRLCw8Nx4MABq/Oys7PDgQMH8Omnn+Kjjz7CN998AwA4dOgQpk6divnz5+PUqVOIiIjAgw8+KG37yiuvYO3atVi1ahUOHz6Mpk2bYuDAgcjIyKhw/wLArFmz8Pjjj2PQoEFITk5GcnIyunXrhvz8fPTu3RtOTk7Ys2cP9u3bBycnJwwaNKhcoyXLly/HG2+8gXfffRfx8fFYuHAh3nzzTaxatcoi7tVXX8XUqVMRHx+PgQMHAgC2b9+O+Ph4bN26FRs3bkR+fj4GDRoENzc3REdH4//+7/+wbds2TJ482WJfpbcjIrIZog4zGAwCgDAYDFbrCgoKRFxcnCgoKLjZaMwVYq5L9X+MuRU6r7CwMNGjRw9puaSkRDg6Oorw8HCpLTk5WQAQUVFR4s033xQDBgyw2MelS5cEAHHq1Kkyj5GamioAiGPHjgkhhEhISBAAxDfffCPFnDhxQgAQ8fHxFcr/hiFDhoiZM2danFdwcLAwm81S26uvviqCg4OFEEKsXbtWuLi4iOzsbKt95ebmCrVaLVavXi21FRUVCX9/f7FkyRIhhBA7d+4UAERmZqYQQoi5c+eKNm3aWOzno48+EoGBgdLyuHHjxEMPPWQR8+2334rmzZtb5Gk0GoW9vb34888/73reAQEB4scff7RoW7BggejatasQ4mZff/zxxxYx48aNEz4+PsJoNEptX3/9tXBzcxO5uTd/hzZt2iSUSqVISUm57XZlKfPvBBGRDO70/V0aR3RsVOvWraWfVSoVPDw8EBoaKrX5+PgAAFJTUxETE4OdO3fCyclJ+rRo0QIApMtT586dw+jRo9G4cWO4uLigUaNGAIDExMTbHtfPz086xt2YTCa8++67aN26NTw8PODk5IQtW7ZY7b9Lly4WD1/s2rUrzpw5A5PJhP79+yMwMBCNGzdGeHg4Vq9ejfz8fCn/4uJidO/eXdpWrVajU6dOiI+Pv2t+FRETE4OzZ8/C2dlZ6k93d3cUFhZaXO4rS1paGi5duoQJEyZY/Hm88847Vtt27NjRavvQ0FBoNBppOT4+Hm3atIGjo6PU1r17d5jNZpw6deq22xER2Qo7uROoVdQOwOwr97TptVwjkg2FcLVXI8Dd4e4blD5uBanVaotlhUJh0XajWDCbzTCbzRg+fDjee+89q/3cKFaGDx+OgIAALF++HP7+/jCbzQgJCbG6FHO7Y9zNBx98gI8++ggff/wxQkND4ejoiOnTp1doYqyzszMOHz6MXbt2YcuWLXjrrbcwb948REdHS/N4Sj+hWghx26dWK5VKq4c8ljXptzSz2YwOHTpg9erVVuu8vLzuui1w/fJV586dLdapVCqL5VuLl9u13en8bm0va19ERLaAhU5FKBSA5t6+EFRaNYRaicwSwBM62GtUd9+omrRv3x5r165Fw4YNYWdn/SuRnp6O+Ph4fPXVV+jZsycAYN++fZWaw969e/HQQw/hqaeeAnD9C//MmTMIDg62iNu/f7/VclBQkFQE2NnZoV+/fujXrx/mzp0LV1dX7NixAwMHDoRGo8G+ffswevRoANeLlkOHDt322TxeXl5ISUmxKBZiY2MtYjQaDUwmy/eYtW/fHj///DO8vb3h4uJSoX7w8fFBvXr1cP78eYwZM6ZC25alZcuWWLVqFfLy8qRi5q+//oJSqeSkYyKqE3jpqprobnmT+eXMmvWE5BdffBEZGRkYNWoUDh48iPPnz2PLli14+umnYTKZpDuHvv76a5w9exY7duzAjBkzKjWHpk2bYuvWrYiMjER8fDyeffZZpKSkWMVdunQJM2bMwKlTp/DTTz/hs88+w7Rp0wAAGzduxKefforY2FhcvHgR3333HcxmM5o3bw5HR0c8//zzePnllxEREYG4uDhMnDgR+fn5mDBhQpk59erVC2lpaViyZAnOnTuHzz//3OJONQBo2LAhjh49ilOnTuHatWsoLi7GmDFj4OnpiYceegh79+5FQkICdu/ejWnTpuHy5ct37Yt58+Zh0aJF+OSTT3D69GkcO3YMK1aswIcffljhfh0zZgx0Oh3GjRuH48ePY+fOnZgyZQrCw8Oly5dERLasQoXOokWL8MADD8DZ2Rne3t4YOXKkxXV+4Pqtqjdutb3x6dKli0WM0WjElClT4OnpCUdHR4wYMcLqCyAzMxPh4eHQ6/XQ6/UIDw+3emJtYmIihg8fDkdHR3h6emLq1Kk19hkgOvXNrjbVsKcj+/v746+//oLJZMLAgQMREhKCadOmQa/XQ6lUQqlUYs2aNYiJiUFISAheeuklvP/++5Waw5tvvon27dtj4MCB6NWrF3x9fct8EN/YsWNRUFCATp064cUXX8SUKVMwadIkAICrqyvWrVuHPn36IDg4GF9++SV++ukntGrVCgCwePFiPProowgPD0f79u1x9uxZ/Pnnn3Bzcyszp+DgYCxbtgyff/452rRpg4MHD2LWrFkWMRMnTkTz5s3RsWNHeHl54a+//oKDgwP27NmDBg0a4JFHHkFwcDCefvppFBQUlGuE55lnnsE333yDlStXIjQ0FGFhYVi5cqU0L6oiHBwc8OeffyIjIwMPPPAA/vWvf6Fv375YunRphfdFRFQbKUTpSQh3MGjQIDz55JN44IEHUFJSgjfeeAPHjh1DXFycNCw+fvx4XL16FStWrJC202g0cHd3l5aff/55/P7771i5ciU8PDwwc+ZMZGRkICYmRroEMXjwYFy+fBlff/01AGDSpElo2LAhfv/9dwDXJ6+2bdsWXl5e+OCDD5Ceno5x48bhkUcewWeffVau88nOzoZer4fBYLD6AiosLERCQgIaNWoEnU5X3i66o2u5RlzJKoCDxg5NvZ0qZZ9E1aUq/k4QEd2LO31/W7mf27tu3GK8e/duqa2s221vlZWVJdRqtVizZo3UlpSUJJRKpYiIiBBCCBEXFycAiP3790sxUVFRAoA4efKkEEKIzZs3C6VSKZKSkqSYn376SWi12nLdbibEPdxefp9yC4vF35cyRXxy+fIjqkl4ezkR1RTVdnu5wWAAAIvRGuD6yxG9vb3RrFkzTJw40eL24piYGBQXF2PAgAFSm7+/P0JCQhAZGQkAiIqKgl6vt7jrpEuXLtDr9RYxISEh8Pf3l2IGDhwIo9GImJiY+zmtKmP3z6vMS0w169JVdRg8eLDF7dK3fhYuXCh3etXqdv3g5OSEvXv3yp0eEZFNuee7roQQmDFjBnr06IGQkBCpffDgwXjssccQGBiIhIQEvPnmm+jTpw9iYmKg1WqRkpICjUZjNS/Cx8dHmnyakpICb29vq2N6e3tbxJSeTOnm5gaNRlPmJFbg+twgo9EoLWdnZ9/byd8jO+X1utIsBExmAZWy7Nt+bdE333yDgoKCMteVLpRtXek7t25Vr1696kuEiKgOuOdCZ/LkyTh69KjVbcZPPPGE9HNISAg6duyIwMBAbNq0CY888sht9ydKPe+jrGd/3EvMrRYtWoS333779idVxZQKQKlQ/FPomKFS1pxbzKsav8Bvatq0qdwpEBHVGfd06WrKlCnYsGEDdu7cifr1698x1s/PD4GBgThz5gwAwNfXF0VFRcjMzLSIS01NlUZofH19cfXqVat9paWlWcSUHrnJzMxEcXHxbW+bff3112EwGKTPpUuX7nquohLvkFIoFLD7ZxTHUHD39z8R1SSV+XeBiKi6VKjQEUJg8uTJWLduHXbs2FGu213T09Nx6dIl6Qm7HTp0gFqtxtatW6WY5ORkHD9+HN26dQNw/bH+BoMBBw8elGIOHDgAg8FgEXP8+HEkJydLMVu2bIFWq0WHDh3KzEWr1cLFxcXiczs3nvB74xUClaXIdP3Jt8mGsi/jENVUN/4ulH7qNhFRTVah28tfeOEF/Pjjj/jtt9/QvHlzqV2v18Pe3h65ubmYN28eHn30Ufj5+eHChQuYPXs2EhMTER8fD2dnZwDXby/fuHEjVq5cCXd3d8yaNQvp6elWt5dfuXIFX331FYDrt5cHBgZa3V7u4+OD999/HxkZGRg/fjxGjhxZKbeXA9cLsKysLHh7e8PBweG2l8Qq4lTKzXlBzX0r9tRcIjkIIZCfn4/U1FS4urpK/9NCRCSXitxeXqFC53Zf9CtWrMD48eNRUFCAkSNH4siRI8jKyoKfnx969+6NBQsWICAgQIovLCzEyy+/jB9//BEFBQXo27cvli1bZhGTkZGBqVOnYsOGDQCAESNGYOnSpXB1dZViEhMT8cILL2DHjh2wt7fH6NGj8Z///AdarbZc53O3jhJCICUlxepBhfcjp7BYumxVz9UelVA7EVULV1dX+Pr6VkrBT0R0P6qs0LE15e0ok8lUrpc5loex2IQhn16/hfjXF7vDWcfLAFTzqdVqq5eKEhHJpSKFDl/qWQ4qlarS/pHX6YCreWaUmAVOpRnRI8i5UvZLRERE1vhSTxmUmK8Poj37/SGZMyEiIrJtLHRklFdkkjsFIiIim8ZCRwYr/v0AAMBBo+KzSYiIiKoQCx0ZdGviAYUCyC8y4Wq28e4bEBER0T1hoSMDrZ0Kreu7AgD+OJ5852AiIiK6Zyx0ZDKw1fXXVBy6mHmXSCIiIrpXLHRkEuKvBwDEXaneN6gTERHVJSx0ZNLK//oDjhKu5SHXyBd8EhERVQUWOjLxcNLC10UHAIhP5qgOERFRVWChI6MbozonkgwyZ0JERGSbWOjIqFW96/N0jnOeDhERUZVgoSOjln7XR3ROpeTInAkREZFtYqEjo/pu9gCAZEOhzJkQERHZJhY6MvL5ZzJyep4RxSazzNkQERHZHhY6MvJw1ECtUkAIIC2Hr4IgIiKqbCx0ZKRUKqRRnWO884qIiKjSsdCRWb/g66+C2HLiqsyZEBER2R4WOjIL9nMGAGTmF8mcCRERke1hoSMzF50aALDndBqSsgpkzoaIiMi2sNCRmYv99UKnxCzw9IpombMhIiKyLSx0ZKb/p9ABgFNX+eBAIiKiysRCR2Y3Ll3dYDILmTIhIiKyPSx0ZOZib2exnFtYIlMmREREtoeFjsycS43ovL3xBL7ec06mbIiIiGwLCx2ZqZQKHJzdV1pedzgJCzef5B1YRERElYCFTg3g7aJDoIeDRdtfZ67JlA0REZHtYKFTQ2TlF1ssZ/ABgkRERPeNhU4N8WSnAIvlwmKTTJkQERHZDhY6NcTrg4Nx+p3BeLp7IwBAYbFZ5oyIiIhqPxY6NYjGTgmd+vofibGEIzpERET3i4VODaNTqwBwRIeIiKgysNCpYaQRHc7RISIium8sdGqYGyM6644kIfIsbzEnIiK6Hyx0ahit3c0/khd+PCxjJkRERLUfC50a5saIDmD9bB0iIiKqGBY6NYzWTmWxnFPIYoeIiOhesdCpYUo/KJDvvCIiIrp3LHRqmNKFToqhUKZMiIiIaj8WOjXM0NZ+aOHrLC0fvWzg6yCIiIjuEQudGsZZp0bE9AcxunMDAMCHW09jxi+x8iZFRERUS7HQqaG6NfGQft58LAUlJj4pmYiIqKJY6NRQQ0P9MHtIC2l5+NK/YDILGTMiIiKqfVjo1FAKhQKTHmyCOUODAQDxydk4n5Yrc1ZERES1CwudGu6Zno2lycknU3JkzoaIiKh2YaFTC7QNcAUAnGKhQ0REVCEsdGqB5hzRISIiuicsdGqBG4XOiSsGmDkhmYiIqNxY6NQCbQNc4ay1Q7KhEB9uPc0HCBIREZUTC51awEFjhyceCAAALN15Fm/+elzmjIiIiGqHChU6ixYtwgMPPABnZ2d4e3tj5MiROHXqlEWMEALz5s2Dv78/7O3t0atXL5w4ccIixmg0YsqUKfD09ISjoyNGjBiBy5cvW8RkZmYiPDwcer0eer0e4eHhyMrKsohJTEzE8OHD4ejoCE9PT0ydOhVFRUUVOaVaI6y5l/Tz/8VcvkMkERER3VChQmf37t148cUXsX//fmzduhUlJSUYMGAA8vLypJglS5bgww8/xNKlSxEdHQ1fX1/0798fOTk3J9JOnz4d69evx5o1a7Bv3z7k5uZi2LBhMJluXpIZPXo0YmNjERERgYiICMTGxiI8PFxabzKZMHToUOTl5WHfvn1Ys2YN1q5di5kzZ95Pf9RYnk5ai2UhOFeHiIjorsR9SE1NFQDE7t27hRBCmM1m4evrKxYvXizFFBYWCr1eL7788kshhBBZWVlCrVaLNWvWSDFJSUlCqVSKiIgIIYQQcXFxAoDYv3+/FBMVFSUAiJMnTwohhNi8ebNQKpUiKSlJivnpp5+EVqsVBoOhXPkbDAYBoNzxckrLKRSBr26UPntOp8qdEhERkSwq8v19X3N0DAYDAMDd3R0AkJCQgJSUFAwYMECK0Wq1CAsLQ2RkJAAgJiYGxcXFFjH+/v4ICQmRYqKioqDX69G5c2cppkuXLtDr9RYxISEh8Pf3l2IGDhwIo9GImJiY+zmtGsnNQWOxHP7tQZkyISIiqj3s7nVDIQRmzJiBHj16ICQkBACQkpICAPDx8bGI9fHxwcWLF6UYjUYDNzc3q5gb26ekpMDb29vqmN7e3hYxpY/j5uYGjUYjxZRmNBphNBql5ezs7HKfr9xUSoXcKRAREdU69zyiM3nyZBw9ehQ//fST1TqFwvJLWQhh1VZa6Ziy4u8l5laLFi2SJjfr9XoEBATcMaeaZutLD1osJxsKZMqEiIiodrinQmfKlCnYsGEDdu7cifr160vtvr6+AGA1opKamiqNvvj6+qKoqAiZmZl3jLl69arVcdPS0ixiSh8nMzMTxcXFViM9N7z++uswGAzS59KlSxU5bdkF+Tjjf891lZa7LtqBXGOJjBkRERHVbBUqdIQQmDx5MtatW4cdO3agUaNGFusbNWoEX19fbN26VWorKirC7t270a1bNwBAhw4doFarLWKSk5Nx/PhxKaZr164wGAw4ePDmPJQDBw7AYDBYxBw/fhzJyclSzJYtW6DVatGhQ4cy89dqtXBxcbH41DYdG7pbLJ9L5RvNiYiIbqdCc3RefPFF/Pjjj/jtt9/g7Owsjajo9XrY29tDoVBg+vTpWLhwIYKCghAUFISFCxfCwcEBo0ePlmInTJiAmTNnwsPDA+7u7pg1axZCQ0PRr18/AEBwcDAGDRqEiRMn4quvvgIATJo0CcOGDUPz5s0BAAMGDEDLli0RHh6O999/HxkZGZg1axYmTpxYKwuYinixdxN8vvMcACAjzzafG0RERFQpKnI7F4AyPytWrJBizGazmDt3rvD19RVarVY8+OCD4tixYxb7KSgoEJMnTxbu7u7C3t5eDBs2TCQmJlrEpKenizFjxghnZ2fh7OwsxowZIzIzMy1iLl68KIYOHSrs7e2Fu7u7mDx5sigsLCz3+dSm28tvZTabRYcFW0XgqxvFmoMX5U6HiIioWlXk+1shRN198lx2djb0ej0MBkOtGwV65X9/45dDlzGzfzNM6RskdzpERETVpiLf33zXVS3lp7cHAHyw9TRiLmbInA0REVHNxEKnlmrq7ST9/OgXUTJmQkREVHOx0Kmlmvk4y50CERFRjcdCp5aq52ZvsZzH5+kQERFZYaFTSzlqVBbLKdmFMmVCRERUc7HQqaVKv+bi0+1nZMqEiIio5mKhYyN+i72CnSdTUYefFkBERGSFhU4t1r+l5Tu9/r0yGnvOXJMpGyIiopqHhU4ttnR0O2x56UEMa+0ntf2w/6KMGREREdUsLHRqMa2dCs18nBHsd/OpkGqVAqdScpCWY5QxMyIiopqBhY4NuHVEZ1t8KgZ+vAfh3x6QMSMiIqKagYWODQj0cMSPEzsDAIpKzACAkyk5KCw2yZkWERGR7Fjo2IhuTTzRwtfyacnn0nJlyoaIiKhmYKFjQzoEulksX8rIlykTIiKimoGFjg1p38Cy0MnML5YpEyIiopqBhY4NaRPgarGcmV8kTyJEREQ1BAsdG9LEyxHjuzWUlrM4okNERHUcCx0bolAoMG9EK7w8sDkAIDOPIzpERFS3sdCxQW4OGgBARl4R4q5kI4uXsIiIqI6ykzsBqnwNPR0AANtPpmL7yVQEuNtj7yt9ZM6KiIio+nFExwaF1tNbLF/KKECesUSmbIiIiOTDQscGOevUVg8PPHrZIFM2RERE8mGhY6O+Du9osXwhPU+mTIiIiOTDQsdG1Xezt1j+9UgSTGYhUzZERETyYKFjo5RKhcXygYQMNJm9GbPXH4MQLHiIiKhuYKFjw2YNaGbV9uOBROw7e02GbIiIiKofCx0bNrlPELbNeNCqPcVQKEM2RERE1Y+Fjo1r6OFo1aZQKMqIJCIisj0sdGycnUqJP6b1tGjLKeQ7sIiIqG5goVMHBPu5YGRbf2n57d/jMPOXv2XMiIiIqHqw0KkjHu1Q32J57eHLSMsxypQNERFR9WChU0f0DPLCkkdbW7QdScyUKRsiIqLqwUKnDnn8gQDsfrmXtJyex7eaExGRbWOhU8cEejjisX8uY/1xPEXmbIiIiKoWC506yNVBDQDYczoNIz//S+ZsiIiIqg4LnTro1ktWsZeyYCwxyZgNERFR1WGhUwe1rqe3WE7P5VwdIiKyTSx06qBRnRvgoVueq8NCh4iIbBULnTpIa6fCJ0+2Q0s/FwDA+BUHEXn2GkxmvtWciIhsCwudOszTWQvg+pyd0d8cwHdRF+RNiIiIqJKx0KnDPB01FssfbDktUyZERERVg4VOHRb8z6WrG3KNJTieZJApGyIiosrHQqcOG9stEE90DEBjL0epbdhn+5DBJyYTEZGNYKFTh2ntVHjvX62xbEx7i/ZPtvESFhER2QYWOoQmXk4Wy3vPXsOFa3kyZUNERFR5WOgQ1ColJvduKi2fT8tDr//s4tvNiYio1mOhQwCAmQOaIWHRELTwdZbafou9ImNGRERE94+FDgEAFAoFFAoFwpp7SW16e7WMGREREd0/Fjpk4dbixl6jkjETIiKi+8dChyz0bHpzRIfP1CEiotquwoXOnj17MHz4cPj7+0OhUODXX3+1WD9+/HjpMsiNT5cuXSxijEYjpkyZAk9PTzg6OmLEiBG4fPmyRUxmZibCw8Oh1+uh1+sRHh6OrKwsi5jExEQMHz4cjo6O8PT0xNSpU1FUxGfA3I/Q+nq0DXAFAGw8mozUnEJ5EyIiIroPFS508vLy0KZNGyxduvS2MYMGDUJycrL02bx5s8X66dOnY/369VizZg327duH3NxcDBs2DCaTSYoZPXo0YmNjERERgYiICMTGxiI8PFxabzKZMHToUOTl5WHfvn1Ys2YN1q5di5kzZ1b0lKiUzo3cpZ/jrmTLmAkREdH9savoBoMHD8bgwYPvGKPVauHr61vmOoPBgG+//Rbff/89+vXrBwD44YcfEBAQgG3btmHgwIGIj49HREQE9u/fj86dOwMAli9fjq5du+LUqVNo3rw5tmzZgri4OFy6dAn+/v4AgA8++ADjx4/Hu+++CxcXlzKPT3eXmmOUfo5Lzkav5t4yZkNERHTvqmSOzq5du+Dt7Y1mzZph4sSJSE1NldbFxMSguLgYAwYMkNr8/f0REhKCyMhIAEBUVBT0er1U5ABAly5doNfrLWJCQkKkIgcABg4cCKPRiJiYmKo4rTqjlf/NInFJxCkUlZhlzIaIiOjeVXqhM3jwYKxevRo7duzABx98gOjoaPTp0wdG4/VRgpSUFGg0Gri5uVls5+Pjg5SUFCnG29t6FMHb29sixsfHx2K9m5sbNBqNFFOa0WhEdna2xYesPdUlEA633HEVc5EPDiQiotqp0gudJ554AkOHDkVISAiGDx+OP/74A6dPn8amTZvuuJ0QAgqFQlq+9ef7ibnVokWLpMnNer0eAQEB5T2tOkWnViHqtb7S8v8duoRTKTkyZkRERHRvqvz2cj8/PwQGBuLMmTMAAF9fXxQVFSEz03KUIDU1VRqh8fX1xdWrV632lZaWZhFTeuQmMzMTxcXFViM9N7z++uswGAzS59KlS/d9frZK76DGvOEtAQDrjiRh4Md7+FZzIiKqdaq80ElPT8elS5fg5+cHAOjQoQPUajW2bt0qxSQnJ+P48ePo1q0bAKBr164wGAw4ePCgFHPgwAEYDAaLmOPHjyM5OVmK2bJlC7RaLTp06FBmLlqtFi4uLhYfur2ODd0tlo9ezpInESIiontU4buucnNzcfbsWWk5ISEBsbGxcHd3h7u7O+bNm4dHH30Ufn5+uHDhAmbPng1PT088/PDDAAC9Xo8JEyZg5syZ8PDwgLu7O2bNmoXQ0FDpLqzg4GAMGjQIEydOxFdffQUAmDRpEoYNG4bmzZsDAAYMGICWLVsiPDwc77//PjIyMjBr1ixMnDiRBUwlaeXvgvpu9ricWQAA+HznWTRwd4CA9RvPiYiIaiKFEEJUZINdu3ahd+/eVu3jxo3DF198gZEjR+LIkSPIysqCn58fevfujQULFljMhyksLMTLL7+MH3/8EQUFBejbty+WLVtmEZORkYGpU6diw4YNAIARI0Zg6dKlcHV1lWISExPxwgsvYMeOHbC3t8fo0aPxn//8B1qttlznkp2dDb1eD4PBwOLoNo4nGfDl7nPYeDTZov3kgkHQqfmKCCIiqn4V+f6ucKFjS1jolN/Y/x7EntNp0vKel3ujgYeDjBkREVFdVZHvb77rispl/ohWFssrIy/gi13nYDbX2TqZiIhqARY6VC4NPR0xo38zafm/fyXgvYiT2Hgs+Q5bERERyYuFDpXb1L5B6NTI8k6syLPXZMqGiIjo7ljoUIWE1tNbLMcl8+nSRERUc7HQoQrxcra8o+3oZQP2n0+XKRsiIqI7Y6FDFWJfxi3l/92XIEMmREREd8dChypEp7b+ldkSdxVNZm9G5DnO1yEiopqFhQ5VyJBQPzRwd8DjHetjwUM3bzk3mQVGLz8gY2ZERETWKvwKCKrbnHVq7H65FxQKBf6+lCV3OkRERHfEER2qMIVCAQBoE+CKR9vXlzkbIiKi22OhQ/dlWGs/i+WEa3kyZUJERGSNhQ7dF72D2mL5851nEXn2GnIKi2XKiIiI6CYWOnRf3Bw0Fsv/i7mM0d8cQPi3B2XKiIiI6CYWOnRf3EqN6NwQeykLhcWmas6GiIjIEgsdui8uurILHQDYGne1GjMhIiKyxkKH7otSqcA7I0PwUr9mVuum/HQE30ddqP6kiIiI/sHn6NB9e6pLIAAgr6gEf529BmedHfafzwAAvPnbCTz+QAC0dtavjiAiIqpqHNGhSjN7SDA2Te0JP729RXtyVqFMGRERUV3HQocq3ayBzS2Wk7IKZMqEiIjqOhY6VOnquVqO6JxKyZEpEyIiqutY6FCVmNy7qfTz/I1xOHQhQ8ZsiIiormKhQ1ViWr8g9GjqKS2PXxENIYSMGRERUV3EQoeqhFqlRPdbCp1cYwkuZ3KuDhERVS8WOlRlegZ5WiwfSODlKyIiql4sdKjKhNTTY/0L3RBSzwUAMOv//sb3+y/KnBUREdUlLHSoSrVr4IaOge7S8pu/HsfP0YkyZkRERHUJCx2qcqH19BbL3+xNkCkTIiKqa1joUJUb0MrHYvlMai5yCotlyoaIiOoSFjpU5Zx1aiQsGoJDc/pJbaHztqCw2CRjVkREVBew0KFqoVAo4OmkxejODaS2CauiZcyIiIjqAhY6VK1eHnDzPVh/nU3nxGQiIqpSLHSoWrk5ajC0tZ+0/OraY2j42iZk5BXJmBUREdkqFjpU7UY90MCqLfLcNRkyISIiW8dCh6pdjyBPPBvW2KLt9XXHsCrygjwJERGRzWKhQ7J4bVAL/PhMZ7Suf/0ZOzmFJZi74QRf/ElERJWKhQ7JQqFQoFtTT4Q187Jov5ptlCkjIiKyRSx0SFYejhqL5cGf7JEpEyIiskUsdEhWvVt4Wyxn5hcjz1iCFEOhTBkREZEtYaFDsgr0cEQDdweLtlZz/0SXRdux+3SaTFkREZGtYKFDsvt+Qqcy2yevPlzNmRARka1hoUOyC/RwxKuDWli16zQqGbIhIiJbwkKHaoTnezXBuYVDsPb5blJbWo4RizbHy5gVERHVdix0qMZQKRXoEOiGL8a0l9q+2nMe6bm85ZyIiO4NCx2qcQa28rVYPnU1R6ZMiIiotmOhQzWOUqlA50bu0vLvfyfjwPl0xF3JljErIiKqjRSiDj9zPzs7G3q9HgaDAS4uLnKnQ7coLDbh851n8dmOsxbtFxYPlSkjIiKqKSry/c0RHaqRdGoVwrsEWrUXFptkyIaIiGorFjpUY3m76NAzyNOibfOxZOQXlciUERER1TYsdKhGMxabLZZn/PI33vvjpEzZEBFRbcNCh2q04W39rdpWRV3EQj5fh4iIyqHChc6ePXswfPhw+Pv7Q6FQ4Ndff7VYL4TAvHnz4O/vD3t7e/Tq1QsnTpywiDEajZgyZQo8PT3h6OiIESNG4PLlyxYxmZmZCA8Ph16vh16vR3h4OLKysixiEhMTMXz4cDg6OsLT0xNTp05FUVFRRU+JarBRDwTgy6faW7V/vec86vA8eiIiKqcKFzp5eXlo06YNli5dWub6JUuW4MMPP8TSpUsRHR0NX19f9O/fHzk5N5+FMn36dKxfvx5r1qzBvn37kJubi2HDhsFkujnRdPTo0YiNjUVERAQiIiIQGxuL8PBwab3JZMLQoUORl5eHffv2Yc2aNVi7di1mzpxZ0VOiGsxOpcSgEL8y12XksaglIqK7EPcBgFi/fr20bDabha+vr1i8eLHUVlhYKPR6vfjyyy+FEEJkZWUJtVot1qxZI8UkJSUJpVIpIiIihBBCxMXFCQBi//79UkxUVJQAIE6ePCmEEGLz5s1CqVSKpKQkKeann34SWq1WGAyGcuVvMBgEgHLHk3z2nE4V//riLxH46kbpM2f9MRH46kbxzsYTwmQyy50iERFVk4p8f1fqHJ2EhASkpKRgwIABUptWq0VYWBgiIyMBADExMSguLraI8ff3R0hIiBQTFRUFvV6Pzp07SzFdunSBXq+3iAkJCYG//805HAMHDoTRaERMTEyZ+RmNRmRnZ1t8qHboGeSFNZO6WrR9v/8iAGD53gR8vO20HGkREVENV6mFTkpKCgDAx8fHot3Hx0dal5KSAo1GAzc3tzvGeHt7W+3f29vbIqb0cdzc3KDRaKSY0hYtWiTN+dHr9QgICLiHsyS5qJQKbJ8ZhicfsP5zWxl5ofoTIiKiGq9K7rpSKBQWy0IIq7bSSseUFX8vMbd6/fXXYTAYpM+lS5fumBPVPE28nDBvRCurdk5LJiKislRqoePre/1ljKVHVFJTU6XRF19fXxQVFSEzM/OOMVevXrXaf1pamkVM6eNkZmaiuLjYaqTnBq1WCxcXF4sP1T46tQofP9EWDhqV3KkQEVENV6mFTqNGjeDr64utW7dKbUVFRdi9eze6desGAOjQoQPUarVFTHJyMo4fPy7FdO3aFQaDAQcPHpRiDhw4AIPBYBFz/PhxJCcnSzFbtmyBVqtFhw4dKvO0qAYa2a4eZg5oLi3nFJag26LtiL2UJV9SRERU49hVdIPc3FycPXvzRYsJCQmIjY2Fu7s7GjRogOnTp2PhwoUICgpCUFAQFi5cCAcHB4wePRoAoNfrMWHCBMycORMeHh5wd3fHrFmzEBoain79+gEAgoODMWjQIEycOBFfffUVAGDSpEkYNmwYmje//uU2YMAAtGzZEuHh4Xj//feRkZGBWbNmYeLEiRypqSNEqefoXDEUYuTnfyFh0ZC7XiolIqK6ocIjOocOHUK7du3Qrl07AMCMGTPQrl07vPXWWwCAV155BdOnT8cLL7yAjh07IikpCVu2bIGzs7O0j48++ggjR47E448/ju7du8PBwQG///47VKqblyJWr16N0NBQDBgwAAMGDEDr1q3x/fffS+tVKhU2bdoEnU6H7t274/HHH8fIkSPxn//85547g2qXQSG+ZbbvPXOtmjMhIqKaSiFK/29xHVKR17xTzZSWY8Qzq6Lx92WDRfvReQPgolPLlBUREVWlinx/811XVKt5OWvxv+e74dQ7g7Dn5d5S+8JNfBcWERGx0CEboFYpobVToYGHAwb/czkr4kQKoi9kIJOviSAiqtNY6JBNeffhUABAVn4xHvsyCoM/2QuTuc5enSUiqvNY6JBNcbW3nJeTkl2IBRvjEJ/M130QEdVFLHTIpiiV1reVr4y8gFn/97cM2RARkdxY6FCdcOIKR3SIiOoiFjpkc1RljOoAQNj7O3E2NaeasyEiIjmx0CGbEzGtJ+YMDbZqv5iej34f7kGKoVCGrIiISA4sdMjmBPk445mejdE2wLXM9X0+2AUhhNUrJIiIyPaw0CGb9emT7TC9X5BVe36RCY1e34we7+1ETmGxDJkREVF1YaFDNquBhwOm92uGAS19ylyflFWAQxcyqzkrIiKqTix0yOZ9PbYjEhYNQc8gT6t1Arx8RURky1joUJ2gUCjwzbiO2DbjQXg4aqT2+GTehUVEZMtY6FCdobVToam3M/56rQ/6tPAGALz/5ynM+fWYzJkREVFVsZM7AaLqplOrkHHLyz5/2J8IV3sN/Fx1eKJjAOxUrP+JiGwFCx2qk9JyjBbLS3eeBQDkGUsw6cEmcqRERERVgP/rSnXSiLb+AIDmPs4W7ZHn0uVIh4iIqggLHaqTpvUNwidPtsWaSV0s2k+l5ODPEylIuJaHfWeuyZQdERFVFl66ojpJp1bhobb1AAAejhqk/zNnJ9lQiGe/j5Hids3qhYaejrLkSERE948jOlTnLRvT/rbrEtLzqjETIiKqbCx0qM7r3NgDh+b0K3NddgFfEUFEVJux0CEC4OmkLbP9+6iL1ZwJERFVJhY6RP/4eVIXvD64BXa/3AtO2uvT1w5dzMTr646hxGSWOTsiIroXLHSI/tG5sQeeDWuCQA9HtPJ3kdp/OpiI349ekTEzIiK6Vyx0iMowe0iwxfK2+FScuZqDh5buw0YWPUREtYZCCFFnX9+cnZ0NvV4Pg8EAFxeXu29AdcrpqzkY8NGeMtddWDy0mrMhIqIbKvL9zREdotto5uNscQnrVo99GYkx3+xHQZGpmrMiIqKKYKFDdAcPt6tXZnv0hUz8dTYd0RcyqjkjIiKqCBY6RHfwVJdA6eeH2vpjaKifxfqLGfnVnRIREVUAXwFBdAc6tQrx8wdh56lU9AzyxE8HE7HpWLK0PpFPTiYiqtE4okN0F/YaFYaE+sFZp8aAlr4W65bvTUDMxUyZMiMiorthoUNUAQ09HbFhcnd8P6GT1PboF5H4aOtpPlSQiKgGYqFDVEGt67uiZ5AXwm+Zv/PJ9jP4z5bTMmZFRERlYaFDdI8WjAyxWP5y9zl8uJXFDhFRTcJCh+g+OGst5/N/uv0MOr27Dc+sisZFTlQmIpIdCx2i+7BqQifo7dWY3LspvJyvvwE9NceIbfGpCHt/FxKusdghIpITCx2i+9C+gRuOvNkfswY2x6hODazW/3E8uYytiIiourDQIbpPSqUCAPBYh/ro0tjdYl1yVqEcKRER0T9Y6BBVkgB3B6yZ1BWeThqp7fv9F9HwtU34LTYJxhK+F4uIqLqx0CGqZOFdGlq1TVsTi4Wb4qs/GSKiOo6FDlElm9YvCGffHYzFj4RatK+KuojIs9dkyoqIqG5ioUNUBexUSjzZqQHeezQUDdwdpPbR3xzAmoOJMmZGRFS3sNAhqkJPPNAAe17pjTYBrlLba+uOIfIcR3aIiKoDCx2iatCzqafF8ujlB5CUVSBTNkREdQcLHaJqMKVvUzzU1t+irfviHdgWdxXfR12A2SxkyoyIyLbZ3T2EiO6X1k6F9x5tjd9ir1i0P/PdIQCAySwwvnsjOVIjIrJpHNEhqiY6tQpPPhAAL2cttHaWf/Xm/R6HTUf5FGUiosqmEELU2THz7Oxs6PV6GAwGuLi4yJ0O1SFms0DYf3biUoblPJ2ds3qhkaejTFkREdUOFfn+5ogOkQyUSgU+erwt/nl7hOTpldHosnA79p5JkycxIiIbwxEdjuiQjEpMZqiUCizbdQ7v/3nKYt2B2X3h46KTKTMioppL1hGdefPmQaFQWHx8fX2l9UIIzJs3D/7+/rC3t0evXr1w4sQJi30YjUZMmTIFnp6ecHR0xIgRI3D58mWLmMzMTISHh0Ov10Ov1yM8PBxZWVmVfTpEVcpOpYRCocCEHo3QxMvyklXnhduRms2XghIR3Y8quXTVqlUrJCcnS59jx45J65YsWYIPP/wQS5cuRXR0NHx9fdG/f3/k5ORIMdOnT8f69euxZs0a7Nu3D7m5uRg2bBhMppsvRRw9ejRiY2MRERGBiIgIxMbGIjw8vCpOh6jK6dQqbJraE9P6Blm07z7NS1hERPdFVLK5c+eKNm3alLnObDYLX19fsXjxYqmtsLBQ6PV68eWXXwohhMjKyhJqtVqsWbNGiklKShJKpVJEREQIIYSIi4sTAMT+/fulmKioKAFAnDx5sty5GgwGAUAYDIaKnCJRlXthdYwIfHWjCHx1o1j5V4JITM+TOyUiohqjIt/fVTKic+bMGfj7+6NRo0Z48skncf78eQBAQkICUlJSMGDAAClWq9UiLCwMkZGRAICYmBgUFxdbxPj7+yMkJESKiYqKgl6vR+fOnaWYLl26QK/XSzFlMRqNyM7OtvgQ1UTDW/tJP8/dcAI9l+zkk5SJiO5BpRc6nTt3xnfffYc///wTy5cvR0pKCrp164b09HSkpKQAAHx8fCy28fHxkdalpKRAo9HAzc3tjjHe3t5Wx/b29pZiyrJo0SJpTo9er0dAQMB9nStRVWnfwM2qbf3hy2VEEhHRnVR6oTN48GA8+uijCA0NRb9+/bBp0yYAwKpVq6QYhcLynlohhFVbaaVjyoq/235ef/11GAwG6XPp0qVynRNRdfN20eHlgc3xTI+bT0v+z5bTaPP2Fuw6lSpjZkREtUuVP0fH0dERoaGhOHPmjHT3VelRl9TUVGmUx9fXF0VFRcjMzLxjzNWrV62OlZaWZjVadCutVgsXFxeLD1FN9WLvppgzrCXi5w+Cq4MaAGAoKMb4FdEY8NFubI+/ihNXDDJnSURUs1V5oWM0GhEfHw8/Pz80atQIvr6+2Lp1q7S+qKgIu3fvRrdu3QAAHTp0gFqttohJTk7G8ePHpZiuXbvCYDDg4MGDUsyBAwdgMBikGCJbYa9R4f1/tUEzHyep7fTVXExYdQhDP92Hid8dQp6xRMYMiYhqrkp/YOCsWbMwfPhwNGjQAKmpqXjnnXewe/duHDt2DIGBgXjvvfewaNEirFixAkFBQVi4cCF27dqFU6dOwdnZGQDw/PPPY+PGjVi5ciXc3d0xa9YspKenIyYmBiqVCsD1S2RXrlzBV199BQCYNGkSAgMD8fvvv5c7Vz4wkGqb5XvO493N8VbtLf1csGlqj7teAiYisgUV+f6u9LeXX758GaNGjcK1a9fg5eWFLl26YP/+/QgMDAQAvPLKKygoKMALL7yAzMxMdO7cGVu2bJGKHAD46KOPYGdnh8cffxwFBQXo27cvVq5cKRU5ALB69WpMnTpVujtrxIgRWLp0aWWfDlGNMqFHI3g4aXA2NRfLdp2T2uOSs7Hh7yt4qG09GbMjIqp5+AoIjuhQLXXiigFDP91n0dbYyxEbp/SAg6bS/x+GiKjG4Es9ieqAVv56PNq+vkXb+bQ8PLhkJ18dQUT0DxY6RLXYpAcbw06pQLDfzf+juZZbhE4Lt6PvB7vw9MpoTlQmojqNl6546YpquezCYjhr7aBQKLD+yGW89PPfVjFzhgZjQo9GnKxMRDaBl66I6hAXnVoqYB5uVx+jOlk/8fudTfGIOp9e3akREcmOIzoc0SEbU1hsQlJWAfafT8cb649brBvfrSFeH9ICWjvVbbYmIqr5OKJDVIfp1Co08XLC6E4N0Ku5l8W6lZEXMOXHIygoMuHjbadxLi1XpiyJiKoHCx0iG6VQKDCgpa9V+5a4qwh+KwIfbzuD8SsOlrElEZHt4MM2iGzYEw8EwFhiwsrIC7iYnm+1/lJGAQwFxdDbq2XIjoio6nFEh8iGqZQK/Lt7I8wb3uq2MW3e3oLle85XY1ZERNWHk5E5GZnqiD+OJWNr/FXsOJmKgiITjCXmMuMWjAxBeJfAas6OiKj8KvL9zUKHhQ7VUYM/2Yv45Owy1515dzDUKg74ElHNxLuuiOiufnuxO/oF+5S5LuiNP/DD/ovVnBERUeXjiA5HdIhgKCjGsM/24lJGgUX78Db+eKRdPfRu4S1TZkRE1jiiQ0QVordXY8/LvTFnaLBF++9/X8G/V0Yju7AYQgisO3wZlzKs794iIqqpeHs5EQG4/tydCT0awSwETqXkYu3hy9K61vO2SD83cHfAnld6y5EiEVGF8dIVL10RlelyZj56vLezzHXPhjVGvtGEWQOaQ+/AZ/AQUfXipSsium/13RwQ+1b/Mtd9tfs8vt9/EW//fgIlprJvUyciqgk4osMRHaI7ik/OxrHLBpy7louvdls/WNBZa4dXBrfAYx3qQ6fmy0KJqOpxRIeIKk2wnwsefyAArw8ORvsGrgCAJx8IkNbnGEvw5q/H8dLPsTh6OQv/XnEQref9iWOXDTJlTER0E0d0OKJDVG5FJWYUFJvgorND10U7kJJdeNvY1vX12DC5RzVmR0R1RUW+v3nXFRGVm8ZOCY3d9YHg9S92Q36RCV/uOof/i7lsFXv0sgFpOUZ4OWurO00iIgkLHSK6J356ewDAkn+1RlZBMbbGXbWKeeDdbQCAZ3o0whMPBCDIx7lacyQi4qUrXroiqhSJ6fkYv/IgxnQORBMvRzy9MhrmUv+6BHo4YP5DIQjydoK/q708iRJRrceXepYTCx2iqnPgfDqW703AtnjrkR4PRw2iXu8rXQYjIqoIFjrlxEKHqOrN23ACKyMvlLkurJkX+rf0QceGbmjhy7+DRFQ+LHTKiYUOUdUTQiAluxAphkIcSzLgrd9OlBn37sMhGNM5sJqzI6LaiIVOObHQIap+/4u5jNnrjqHoDk9UHt7GHx893gZ2Kl7aIiJrLHTKiYUOkXxSswvx7V8JcHfQYNEfJ8uM+XlSF3Ru7FHNmRFRTcdCp5xY6BDVDOuPXMZLP/9t1a5QAJGv9YGDxg4lJjPsNSo4aOwghIAQgFKpkCFbIpIbHxhIRLXKw+3q41RKLlYfuIiZ/Zth3u9xAAAhgK6LdkhxgR4OWDamPZ78aj96NvPEsjEd5EqZiGoJjuhwRIeoRhFC4Pv9F7HxaDLScoxIuJZ329htMx5EU28+hJCoruGlq3JioUNU8yVcy8P6w5fx6Y6zZa5/vGN9DGvtjwcaumPS94eQayzBd093grNOXc2ZElF1YaFTTix0iGqXE1cMWPzHSew9c+2Occ/0aIQ5w1pWU1ZEVN1Y6JQTCx2i2uubveex5cRVFBSbcCzJUGZMmwBXeDlp0NTbGdP7BUGnVlVzlkRUFVjolBMLHaLaL9dYgpC5f0rL9VztkZRVYBU3unMDDGjpg65NPGDIL8bxKwb0aeFTnakSUSVhoVNOLHSIbEOJyYzjV7Lh4aiBVq3E0E/3IcDNHocTs+643YKRIRjdqQGKTWaO9hDVIix0yomFDpFtuvWftc3HUvDB1lM4n3b7u7cAoJW/C0xmAa2dEs/0bIwBrXygVir5rB6iGoiFTjmx0CGqG0xmgc93nsWhi5nYczqtQtsObe2HpaPaQaFgwUNUU/CBgUREt1ApFZjaN0haNuQX4/X1R5GUVYi/L2XdcdtNR5MR6O6AEW39cSWrAO0buCG/yASFAnDU2sGFt7ET1Wgc0eGIDlGdVmIy49fYK2jk6YAOge7IM5Zg+NJ9d73UdcPLA5vjkfb14Oui46gPUTXhpatyYqFDRGUxmwUaz958T9vOf6gVRnVqgIJiE0d7iKoIC51yYqFDRLdzKSMfhoJiNPZyxI8HEpGRV4Tmvs6Y8cvfMJkFWtfXI89YgnN3GPlZ8q/WyMwrwvm0PLg5atAh0A2t/F0QdS4dg0J84ajl7AGie8FCp5xY6BBRRRlLTIhOyES3Jh5IyirAiKX74OOig5ez9q5PbC5tbNdAnE/LQ6/mXpjQoxEUCgUy8orgaq/m3V5Ed8BCp5xY6BDR/TKbBRQKSPNzPt1+Bh9uPS2tVyiuv4W9IlrX1+OxDvXRu4U3fFx0EOL6hGohBOxUyspMn6hWYqFTTix0iKiqmM0CJ65ko7mvMzR2SgghcCzJgBKzwLUcIyZ9H3NP+x3VKQAPBnlh16k09AjyhINGhcz8YvQL9oa9RoVruUXw13NiNNk2FjrlxEKHiOSScC0Pnk4aJFzLw/t/nkJRiRlHErNQZDJXyv49HDXwcdGhoacDHgzyQnNfZ3g6aVHfzR5XDIUshqhWY6FTTix0iKimupZrRLHJjG3xqVgVeQHJWQXQ26vhpLPD2dRcmCvhX25nnR26NPZAanYhjCVmjGxXD2dTc6URqBd6NUVGXhGSDYUIra9HPVd7ANefPM0iieTEQqecWOgQUW1kMgsUFJsQczETapUCwb4uOHU1B2YhkJVfDBedGuev5WJV5IU73hV2vxw0Krjo1FAogGRDIVRKBXxddCgymeGoUSHYzwXNfZ2hU6vgp9fBTqlEflEJGns54szVXHQIdENGXhF89TqsO5yEke3qIcDNHiVmgRKzQOY/61QKBcxCoNgkYBICjhoVzP/MW7obs1lIE7tZoF1XVf1wa19XNRY65cRCh4hsXX5RCS6m50OtUsBBY4fTV3NgLDEj4ngKikxmtAtwRUZeETb8fQWXM63f+l5TKBWQRrE0dkoUlZihVikQ4OYAvYMap1NyUFhihoNGBQWANgGuiE/OwbVcIwCgiZcjruUWoaGnIxzUKhy5lAk/vT3aN3CDnVIBkxDILSzByZRsXEjPRz1XezTzccLOU2lQKIBm3s5wdVDDSWuHem720NurkZVfjAvpeSgxCVzNKYST1g7ezlq42KvhqLFDfpEJhoJiOGlVUCgUcNCoUFRihp1KCRedHS5nFWDT0WQMaOmDpKwC+Ol18NXrkJ5bhJ2nUlFYfPMyZoC7PdrUd0VOYQnUKiVyCovh46KDQgEUm8zYc/oaco0l8Nfr8K+OATiRZEDCtTwE+TjBT28PtUoBHxcd4q5kI+JEChQAmvo4w8tJAzulEocuZkCjUiK0vh6Zedcfq1BsElh7+DIA4ImOAXCxt8PBhAy4OmigUiqgUirQNsAVxSYzrmYX4qeDl9DQwwHtA92QlFmAYpMZ6XlF+Hx0e4TU01fq7wMLnXJioUNEdFNajhEOGhW0dkooFApcysiHs84OAsCVrAIUlZhRVGKGTqPC+bQ8OGlVyDOacCE9D5/tOAsA6NvCG4aCYhy6mInBIb7QqVUwmQVSsgtxMT0PV7ON0vE0dkoUm8wVviuNapdBrXzxZXiHSt1nnXrX1bJly/D+++8jOTkZrVq1wscff4yePXvKnRYRUa3j5ay1WG7o6Sj97Olkua59AzeL5ZkDmpf7OIXFJujUKgDXL8NdySqAt4sWhy9m4Wp2IcxCoJW/Hhq767fSJ2UWwElnh9zCEuQXlUBjp0RBkQlnU3MR5OMEswDirmQjPa8IXZt4IKewGBfT8yHE9UspGblFyCksQaCnA7ILSuDmoEb7Bm64nJmPvCITikrMSM8zoqjEDB8XHbbFp0KnVqJfsA9OpuRArVSgvps9sgqKobdXQwjAUFAMlVIBF50dIs+lQ6lUYGioH1RKBZINBcjIu37MohIzQurpUWwyo6DIBPM/2+rU10elIs+lw8VeDU8nDRw0Kvjp7WEsMeFcah7cHTUoMplxJjUHVw3G66MnZjOS/hl5axPgimBfZ7g6aHAmNQc/HbwEd0cNQuvpsft0GkLquWBgS19cyzXCWGJGQbEJJSaB+ORsaOyU0KlVSMsxomsTD2w6mozmvs4Ia+aFItP1Y/i56pBdUIJzqbnwc9XBQWOHgwnpOJeWh6Ghfmjk6YiEa3nQqpW4nFGAE1cMeLh9PZxPy4NapcSVrAIEejjgqS6B5f8lrAK1ekTn559/Rnh4OJYtW4bu3bvjq6++wjfffIO4uDg0aNDgrttX2YhO7E/An7MBpQpQ2v3z+ednhcpy+XYxCuU/H8X1/ypvbbvxUd1cf9uYMj5SnOKW/ZQVoyjjeLfG/PNf3Bp3y89Su+I27WXFK+6wH6Xl+rset9Sxy5snERHVaHXm0lXnzp3Rvn17fPHFF1JbcHAwRo4ciUWLFt11+yordKK/BTbNqLz9UfWqtIKsggXWXY+LO+xHYfkzcEsxqLA8lkWbooztcZuY8mxf1nHLub20n/LkWFYM7n6MKtse5TvH221v8ft324Wbed7XulLrq2JdhfOphO1sgo2en9YZcHCv1F3WiUtXRUVFiImJwWuvvWbRPmDAAERGRpa5jdFohNF48/pwdnZ21SQX8ggQ2B0wlwDCdP2/5jL+K6278TED5mJAmC0/ZtP1R6tKbaYyYszWbVKcKLWv0jGijOPdGiOsj2kR88/2ENZtUrsoo610rLjLPm604y77+af9Xkn7ICKi+9bh38Dwj2U7fK0tdK5duwaTyQQfHx+Ldh8fH6SkpJS5zaJFi/D2229XfXL2btc/JK9bC6i7FkYoR4FVRQWZ1Ha/eQrLn6X/olTOooyY222PUssV2R5lxNxleymm9HHvlGNZMRU5x9J9VdE+Kt1XFdze4nf2tgs387uvdaXWV8W6u+Zzr9uVPmZNUANzqon9pFLLevhaW+jcUPpZAHd6PsDrr7+OGTNuXlLKzs5GQEBAleZHMlIoAIVK7iyIiEhGtbbQ8fT0hEqlshq9SU1NtRrluUGr1UKr1Za5joiIiGxPrX0NrkajQYcOHbB161aL9q1bt6Jbt24yZUVEREQ1Sa0d0QGAGTNmIDw8HB07dkTXrl3x9ddfIzExEc8995zcqREREVENUKsLnSeeeALp6emYP38+kpOTERISgs2bNyMwMFDu1IiIiKgGqNXP0blffAUEERFR7VOR7+9aO0eHiIiI6G5Y6BAREZHNYqFDRERENouFDhEREdksFjpERERks1joEBERkc1ioUNEREQ2i4UOERER2SwWOkRERGSzavUrIO7XjYdCZ2dny5wJERERldeN7+3yvNyhThc6OTk5AICAgACZMyEiIqKKysnJgV6vv2NMnX7XldlsxpUrV+Ds7AyFQlGp+87OzkZAQAAuXbrE92hVAvZn5WJ/Vi72Z+Vjn1YuW+tPIQRycnLg7+8PpfLOs3Dq9IiOUqlE/fr1q/QYLi4uNvFLVVOwPysX+7NysT8rH/u0ctlSf95tJOcGTkYmIiIim8VCh4iIiGwWC50qotVqMXfuXGi1WrlTsQnsz8rF/qxc7M/Kxz6tXHW5P+v0ZGQiIiKybRzRISIiIpvFQoeIiIhsFgsdIiIislksdIiIiMhmsdCpAsuWLUOjRo2g0+nQoUMH7N27V+6UaqRFixbhgQcegLOzM7y9vTFy5EicOnXKIkYIgXnz5sHf3x/29vbo1asXTpw4YRFjNBoxZcoUeHp6wtHRESNGjMDly5er81RqpEWLFkGhUGD69OlSG/uzYpKSkvDUU0/Bw8MDDg4OaNu2LWJiYqT17M/yKykpwZw5c9CoUSPY29ujcePGmD9/PsxmsxTD/ryzPXv2YPjw4fD394dCocCvv/5qsb6y+i8zMxPh4eHQ6/XQ6/UIDw9HVlZWFZ9dFRJUqdasWSPUarVYvny5iIuLE9OmTROOjo7i4sWLcqdW4wwcOFCsWLFCHD9+XMTGxoqhQ4eKBg0aiNzcXClm8eLFwtnZWaxdu1YcO3ZMPPHEE8LPz09kZ2dLMc8995yoV6+e2Lp1qzh8+LDo3bu3aNOmjSgpKZHjtGqEgwcPioYNG4rWrVuLadOmSe3sz/LLyMgQgYGBYvz48eLAgQMiISFBbNu2TZw9e1aKYX+W3zvvvCM8PDzExo0bRUJCgvi///s/4eTkJD7++GMphv15Z5s3bxZvvPGGWLt2rQAg1q9fb7G+svpv0KBBIiQkRERGRorIyEgREhIihg0bVl2nWelY6FSyTp06ieeee86irUWLFuK1116TKaPaIzU1VQAQu3fvFkIIYTabha+vr1i8eLEUU1hYKPR6vfjyyy+FEEJkZWUJtVot1qxZI8UkJSUJpVIpIiIiqvcEaoicnBwRFBQktm7dKsLCwqRCh/1ZMa+++qro0aPHbdezPytm6NCh4umnn7Zoe+SRR8RTTz0lhGB/VlTpQqey+i8uLk4AEPv375dioqKiBABx8uTJKj6rqsFLV5WoqKgIMTExGDBggEX7gAEDEBkZKVNWtYfBYAAAuLu7AwASEhKQkpJi0Z9arRZhYWFSf8bExKC4uNgixt/fHyEhIXW2z1988UUMHToU/fr1s2hnf1bMhg0b0LFjRzz22GPw9vZGu3btsHz5cmk9+7NievToge3bt+P06dMAgL///hv79u3DkCFDALA/71dl9V9UVBT0ej06d+4sxXTp0gV6vb7W9nGdfqlnZbt27RpMJhN8fHws2n18fJCSkiJTVrWDEAIzZsxAjx49EBISAgBSn5XVnxcvXpRiNBoN3NzcrGLqYp+vWbMGhw8fRnR0tNU69mfFnD9/Hl988QVmzJiB2bNn4+DBg5g6dSq0Wi3Gjh3L/qygV199FQaDAS1atIBKpYLJZMK7776LUaNGAeDv5/2qrP5LSUmBt7e31f69vb1rbR+z0KkCCoXCYlkIYdVGliZPnoyjR49i3759VuvupT/rYp9funQJ06ZNw5YtW6DT6W4bx/4sH7PZjI4dO2LhwoUAgHbt2uHEiRP44osvMHbsWCmO/Vk+P//8M3744Qf8+OOPaNWqFWJjYzF9+nT4+/tj3LhxUhz78/5URv+VFV+b+5iXriqRp6cnVCqVVdWbmppqVWXTTVOmTMGGDRuwc+dO1K9fX2r39fUFgDv2p6+vL4qKipCZmXnbmLoiJiYGqamp6NChA+zs7GBnZ4fdu3fj008/hZ2dndQf7M/y8fPzQ8uWLS3agoODkZiYCIC/nxX18ssv47XXXsOTTz6J0NBQhIeH46WXXsKiRYsAsD/vV2X1n6+vL65evWq1/7S0tFrbxyx0KpFGo0GHDh2wdetWi/atW7eiW7duMmVVcwkhMHnyZKxbtw47duxAo0aNLNY3atQIvr6+Fv1ZVFSE3bt3S/3ZoUMHqNVqi5jk5GQcP368zvV53759cezYMcTGxkqfjh07YsyYMYiNjUXjxo3ZnxXQvXt3q8cdnD59GoGBgQD4+1lR+fn5UCotv3JUKpV0ezn78/5UVv917doVBoMBBw8elGIOHDgAg8FQe/tYjhnQtuzG7eXffvutiIuLE9OnTxeOjo7iwoULcqdW4zz//PNCr9eLXbt2ieTkZOmTn58vxSxevFjo9Xqxbt06cezYMTFq1Kgyb5esX7++2LZtmzh8+LDo06dPnbnd9G5uvetKCPZnRRw8eFDY2dmJd999V5w5c0asXr1aODg4iB9++EGKYX+W37hx40S9evWk28vXrVsnPD09xSuvvCLFsD/vLCcnRxw5ckQcOXJEABAffvihOHLkiPT4ksrqv0GDBonWrVuLqKgoERUVJUJDQ3l7OVn6/PPPRWBgoNBoNKJ9+/bS7dJkCUCZnxUrVkgxZrNZzJ07V/j6+gqtVisefPBBcezYMYv9FBQUiMmTJwt3d3dhb28vhg0bJhITE6v5bGqm0oUO+7Nifv/9dxESEiK0Wq1o0aKF+Prrry3Wsz/LLzs7W0ybNk00aNBA6HQ60bhxY/HGG28Io9EoxbA/72znzp1l/ps5btw4IUTl9V96eroYM2aMcHZ2Fs7OzmLMmDEiMzOzms6y8imEEEKesSQiIiKiqsU5OkRERGSzWOgQERGRzWKhQ0RERDaLhQ4RERHZLBY6REREZLNY6BAREZHNYqFDRERENouFDhHRLXbt2gWFQoGsrCy5UyGiSsBCh4iIiGwWCx0iIiKyWSx0iKhGEUJgyZIlaNy4Mezt7dGmTRv873//A3DzstKmTZvQpk0b6HQ6dO7cGceOHbPYx9q1a9GqVStotVo0bNgQH3zwgcV6o9GIV155BQEBAdBqtQgKCsK3335rERMTE4OOHTvCwcEB3bp1s3qTORHVDix0iKhGmTNnDlasWIEvvvgCJ06cwEsvvYSnnnoKu3fvlmJefvll/Oc//0F0dDS8vb0xYsQIFBcXA7heoDz++ON48skncezYMcybNw9vvvkmVq5cKW0/duxYrFmzBp9++ini4+Px5ZdfwsnJySKPN954Ax988AEOHToEOzs7PP3009Vy/kRUufhSTyKqMfLy8uDp6YkdO3aga9euUvszzzyD/Px8TJo0Cb1798aaNWvwxBNPAAAyMjJQv359rFy5Eo8//jjGjBmDtLQ0bNmyRdr+lVdewaZNm3DixAmcPn0azZs3x9atW9GvXz+rHHbt2oXevXtj27Zt6Nu3LwBg8+bNGDp0KAoKCqDT6aq4F4ioMnFEh4hqjLi4OBQWFqJ///5wcnKSPt999x3OnTsnxd1aBLm7u6N58+aIj48HAMTHx6N79+4W++3evTvOnDkDk8mE2NhYqFQqhIWF3TGX1q1bSz/7+fkBAFJTU+/7HImoetnJnQAR0Q1msxkAsGnTJtSrV89inVartSh2SlMoFACuz/G58fMNtw5c29vblysXtVptte8b+RFR7cERHSKqMVq2bAmtVovExEQ0bdrU4hMQECDF7d+/X/o5MzMTp0+fRosWLaR97Nu3z2K/kZGRaNasGVQqFUJDQ2E2my3m/BCR7eKIDhHVGM7Ozpg1axZeeuklmM1m9OjRA9nZ2YiMjISTkxMCAwMBAPPnz4eHhwd8fHzwxhtvwNPTEyNHjgQAzJw5Ew888AAWLFiAJ554AlFRUVi6dCmWLVsGAGjYsCHGjRuHp59+Gp9++inatGmDixcvIjU1FY8//rhcp05EVYSFDhHVKAsWLIC3tzcWLVqE8+fPw9XVFe3bt8fs2bOlS0eLFy/GtGnTcObMGbRp0wYbNmyARqMBALRv3x6//PIL3nrrLSxYsAB+fn6YP38+xo8fLx3jiy++wOzZs/HCCy8gPT0dDRo0wOzZs+U4XSKqYrzriohqjRt3RGVmZsLV1VXudIioFuAcHSIiIrJZLHSIiIjIZvHSFREREdksjugQERGRzWKhQ0RERDaLhQ4RERHZLBY6REREZLNY6BAREZHNYqFDRERENouFDhEREdksFjpERERks1joEBERkc36f9aPfzWKQJotAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.title('Training accuracy and loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Loss', 'mean_absolute_error'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ce865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7bd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
